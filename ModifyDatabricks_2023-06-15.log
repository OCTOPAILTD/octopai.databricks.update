/Formula1-Project-Solutions (1)/Section-16-17-18/utils/1.prepare_for_incremental_load
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/9.create_processed_database
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/0.ingest_all_files
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/7.ingest_lap_times_file
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/8.ingest_qualifying_file
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/6.ingest_pit_stops_file
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/4.ingest_drivers_file
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/1.ingest_circuits_file
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/2.ingest_races_file
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/3.ingest_constructors_file
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/5.ingest_results_file
/Formula1-Project-Solutions (1)/Section-16-17-18/raw/1.create_raw_tables
/Formula1-Project-Solutions (1)/Section-16-17-18/analysis/2.find_dominant_teams
/Formula1-Project-Solutions (1)/Section-16-17-18/analysis/3.viz_dominant_drivers
/Formula1-Project-Solutions (1)/Section-16-17-18/analysis/4.viz_dominant_teams
/Formula1-Project-Solutions (1)/Section-16-17-18/analysis/1.find_dominant_drivers
/Formula1-Project-Solutions (1)/Section-12/ingestion/1.ingest_circuits_file
/Formula1-Project-Solutions (1)/Section-12/ingestion/7.ingest_lap_times_file
/Formula1-Project-Solutions (1)/Section-12/ingestion/4.ingest_drivers_file
/Formula1-Project-Solutions (1)/Section-12/ingestion/5.ingest_results_file
/Formula1-Project-Solutions (1)/Section-12/ingestion/8.ingest_qualifying_file
/Formula1-Project-Solutions (1)/Section-12/ingestion/0.ingest_all_files
/Formula1-Project-Solutions (1)/Section-12/ingestion/2.ingest_races_file
/Formula1-Project-Solutions (1)/Section-12/ingestion/3.ingest_constructors_file
/Formula1-Project-Solutions (1)/Section-12/ingestion/6.ingest_pit_stops_file
/Formula1-Project-Solutions (1)/Section-20/formula1/set-up/mount_adls_storage
/Formula1-Project-Solutions (1)/Section-20/formula1/analysis/4.viz_dominant_teams
/Formula1-Project-Solutions (1)/Section-20/formula1/analysis/3.viz_dominant_drivers
/Formula1-Project-Solutions (1)/Section-20/formula1/analysis/2.find_dominant_teams
/Formula1-Project-Solutions (1)/Section-20/formula1/analysis/1.find_dominant_drivers
/Formula1-Project-Solutions (1)/Section-20/formula1/raw/1.create_raw_tables
/Formula1-Project-Solutions (1)/Section-20/formula1/utils/1.prepare_for_incremental_load
/Formula1-Project-Solutions (1)/Section-20/formula1/demo/4.sql_temp_view_demo
/Formula1-Project-Solutions (1)/Section-20/formula1/demo/9.sql_joins_demo
/Formula1-Project-Solutions (1)/Section-20/formula1/demo/6.sql_objects_demo
/Formula1-Project-Solutions (1)/Section-20/formula1/demo/5.sql_temp_view_demo
/Formula1-Project-Solutions (1)/Section-20/formula1/demo/3.aggregation_demo
/Formula1-Project-Solutions (1)/Section-20/formula1/demo/7.sql_basics_demo
/Formula1-Project-Solutions (1)/Section-20/formula1/demo/2.join_demo
/Formula1-Project-Solutions (1)/Section-20/formula1/demo/8.sql_functions_demo
/Formula1-Project-Solutions (1)/Section-20/formula1/demo/10.delta_lake_demo
/Formula1-Project-Solutions (1)/Section-20/formula1/demo/1.filter_demo
/Formula1-Project-Solutions (1)/Section-20/formula1/includes/common_functions
/Formula1-Project-Solutions (1)/Section-20/formula1/includes/configuration
/Formula1-Project-Solutions (1)/Section-20/formula1/trans/1.race_results
/Formula1-Project-Solutions (1)/Section-20/formula1/trans/4.calculated_race_results
/Formula1-Project-Solutions (1)/Section-20/formula1/trans/3.constructor_standings
/Formula1-Project-Solutions (1)/Section-20/formula1/trans/0.create_presentation_database
/Formula1-Project-Solutions (1)/Section-20/formula1/trans/2.driver_standings
/Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/7.ingest_lap_times_file
/Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/6.ingest_pit_stops_file
/Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/3.ingest_constructors_file
/Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/4.ingest_drivers_file
/Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/1.ingest_circuits_file
/Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/9.create_processed_database
/Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/2.ingest_races_file
/Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/0.ingest_all_files
/Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/5.ingest_results_file
/Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/8.ingest_qualifying_file
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/analysis/3.viz_dominant_drivers
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/analysis/2.find_dominant_teams
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/analysis/4.viz_dominant_teams
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/analysis/1.find_dominant_drivers
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/set-up/mount_adls_storage
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/0.ingest_all_files
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/7.ingest_lap_times_file
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/9.create_processed_database
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/4.ingest_drivers_file
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/5.ingest_results_file
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/8.ingest_qualifying_file
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/3.ingest_constructors_file
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/2.ingest_races_file
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/6.ingest_pit_stops_file
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/1.ingest_circuits_file
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/trans/3.constructor_standings
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/trans/2.driver_standings
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/trans/1.race_results
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/trans/4.calculated_race_results
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/trans/0.create_presentation_database
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/4.sql_temp_view_demo
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/8.sql_functions_demo
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/10.delta_lake_demo
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/9.sql_joins_demo
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/1.filter_demo
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/5.sql_temp_view_demo
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/6.sql_objects_demo
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/2.join_demo
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/3.aggregation_demo
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/7.sql_basics_demo
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/includes/common_functions
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/includes/configuration
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/utils/1.prepare_for_incremental_load
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/raw/1.create_raw_tables
/Formula1-Project-Solutions (1)/Section-14/trans/2.driver_standings
/Formula1-Project-Solutions (1)/Section-14/trans/1.race_results
/Formula1-Project-Solutions (1)/Section-14/trans/3.constructor_standings
/Formula1-Project-Solutions (1)/Section-19/trans/1.race_results
/Formula1-Project-Solutions (1)/Section-19/trans/4.calculated_race_results
/Formula1-Project-Solutions (1)/Section-19/trans/3.constructor_standings
/Formula1-Project-Solutions (1)/Section-19/trans/0.create_presentation_database
/Formula1-Project-Solutions (1)/Section-19/trans/2.driver_standings
/Formula1-Project-Solutions (1)/Section-19/includes/common_functions
/Formula1-Project-Solutions (1)/Section-19/includes/configuration
/Formula1-Project-Solutions (1)/Section-19/ingestion/9.create_processed_database
/Formula1-Project-Solutions (1)/Section-19/ingestion/3.ingest_constructors_file
/Formula1-Project-Solutions (1)/Section-19/ingestion/4.ingest_drivers_file
/Formula1-Project-Solutions (1)/Section-19/ingestion/6.ingest_pit_stops_file
/Formula1-Project-Solutions (1)/Section-19/ingestion/2.ingest_races_file
/Formula1-Project-Solutions (1)/Section-19/ingestion/8.ingest_qualifying_file
/Formula1-Project-Solutions (1)/Section-19/ingestion/7.ingest_lap_times_file
/Formula1-Project-Solutions (1)/Section-19/ingestion/1.ingest_circuits_file
/Formula1-Project-Solutions (1)/Section-19/ingestion/0.ingest_all_files
/Formula1-Project-Solutions (1)/Section-19/ingestion/5.ingest_results_file
/Formula1-Project-Solutions (1)/Section-06/mount_adls_storage-lesson-6
/Formula1-Project-Solutions (1)/Section-06/mount_adls_storage-lesson-9
/Formula1-Project-Solutions (1)/Section-09-10-11/ingestion/7.ingest_lap_times_file
/Formula1-Project-Solutions (1)/Section-09-10-11/ingestion/5.ingest_results_file
/Formula1-Project-Solutions (1)/Section-09-10-11/ingestion/2.ingest_races_file
/Formula1-Project-Solutions (1)/Section-09-10-11/ingestion/3.ingest_constructors_file
/Formula1-Project-Solutions (1)/Section-09-10-11/ingestion/4.ingest_drivers_file
/Formula1-Project-Solutions (1)/Section-09-10-11/ingestion/1.ingest_circuits_file
/Formula1-Project-Solutions (1)/Section-09-10-11/ingestion/6.ingest_pit_stops_file
/Formula1-Project-Solutions (1)/Section-09-10-11/ingestion/8.ingest_qualifying_file
/Users/dora@octopai.com/Sql_PY (1)
/Users/zacayd@octopai.com/splineScaleExample
/Users/zacayd@octopai.com/ScalaCode
/Users/zacayd@octopai.com/SplineCode
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/utils/1.prepare_for_incremental_load
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/9.create_processed_database
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/0.ingest_all_files
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/7.ingest_lap_times_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/8.ingest_qualifying_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/6.ingest_pit_stops_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/4.ingest_drivers_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/1.ingest_circuits_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/2.ingest_races_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/3.ingest_constructors_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/5.ingest_results_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/raw/1.create_raw_tables
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/analysis/2.find_dominant_teams
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/analysis/3.viz_dominant_drivers
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/analysis/4.viz_dominant_teams
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/analysis/1.find_dominant_drivers
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-12/ingestion/1.ingest_circuits_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-12/ingestion/7.ingest_lap_times_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-12/ingestion/4.ingest_drivers_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-12/ingestion/5.ingest_results_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-12/ingestion/8.ingest_qualifying_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-12/ingestion/0.ingest_all_files
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-12/ingestion/2.ingest_races_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-12/ingestion/3.ingest_constructors_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-12/ingestion/6.ingest_pit_stops_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/set-up/mount_adls_storage
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/analysis/4.viz_dominant_teams
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/analysis/3.viz_dominant_drivers
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/analysis/2.find_dominant_teams
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/analysis/1.find_dominant_drivers
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/raw/1.create_raw_tables
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/utils/1.prepare_for_incremental_load
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/demo/4.sql_temp_view_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/demo/9.sql_joins_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/demo/6.sql_objects_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/demo/5.sql_temp_view_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/demo/3.aggregation_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/demo/7.sql_basics_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/demo/2.join_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/demo/8.sql_functions_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/demo/10.delta_lake_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/demo/1.filter_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/includes/common_functions
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/includes/configuration
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/trans/1.race_results
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/trans/4.calculated_race_results
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/trans/3.constructor_standings
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/trans/0.create_presentation_database
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/trans/2.driver_standings
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/ingestion/7.ingest_lap_times_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/ingestion/6.ingest_pit_stops_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/ingestion/3.ingest_constructors_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/ingestion/4.ingest_drivers_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/ingestion/1.ingest_circuits_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/ingestion/9.create_processed_database
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/ingestion/2.ingest_races_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/ingestion/0.ingest_all_files
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/ingestion/5.ingest_results_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/ingestion/8.ingest_qualifying_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/analysis/3.viz_dominant_drivers
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/analysis/2.find_dominant_teams
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/analysis/4.viz_dominant_teams
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/analysis/1.find_dominant_drivers
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/set-up/mount_adls_storage
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/0.ingest_all_files
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/7.ingest_lap_times_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/9.create_processed_database
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/4.ingest_drivers_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/5.ingest_results_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/8.ingest_qualifying_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/3.ingest_constructors_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/2.ingest_races_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/6.ingest_pit_stops_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/1.ingest_circuits_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/trans/3.constructor_standings
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/trans/2.driver_standings
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/trans/1.race_results
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/trans/4.calculated_race_results
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/trans/0.create_presentation_database
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/demo/4.sql_temp_view_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/demo/8.sql_functions_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/demo/10.delta_lake_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/demo/9.sql_joins_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/demo/1.filter_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/demo/5.sql_temp_view_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/demo/6.sql_objects_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/demo/2.join_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/demo/3.aggregation_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/demo/7.sql_basics_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/includes/common_functions
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/includes/configuration
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/utils/1.prepare_for_incremental_load
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/raw/1.create_raw_tables
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-14/trans/2.driver_standings
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-14/trans/1.race_results
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-14/trans/3.constructor_standings
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/trans/1.race_results
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/trans/4.calculated_race_results
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/trans/3.constructor_standings
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/trans/0.create_presentation_database
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/trans/2.driver_standings
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/includes/common_functions
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/includes/configuration
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/ingestion/9.create_processed_database
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/ingestion/3.ingest_constructors_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/ingestion/4.ingest_drivers_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/ingestion/6.ingest_pit_stops_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/ingestion/2.ingest_races_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/ingestion/8.ingest_qualifying_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/ingestion/7.ingest_lap_times_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/ingestion/1.ingest_circuits_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/ingestion/0.ingest_all_files
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/ingestion/5.ingest_results_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-06/mount_adls_storage-lesson-6
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-06/mount_adls_storage-lesson-9
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-09-10-11/ingestion/7.ingest_lap_times_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-09-10-11/ingestion/5.ingest_results_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-09-10-11/ingestion/2.ingest_races_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-09-10-11/ingestion/3.ingest_constructors_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-09-10-11/ingestion/4.ingest_drivers_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-09-10-11/ingestion/1.ingest_circuits_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-09-10-11/ingestion/6.ingest_pit_stops_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-09-10-11/ingestion/8.ingest_qualifying_file
/Users/zacayd@octopai.com/pythonz
/Users/zacayd@octopai.com/Sandvine_BillingRecon
/Users/zacayd@octopai.com/SqlExample
/Users/zacayd@octopai.com/Zacay
/Users/zacayd@octopai.com/Scala
/Users/zacayd@octopai.com/Scala2
/Users/zacayd@octopai.com/NoteBookTest
/Users/zacayd@octopai.com/2022-10-31 - DBFS Example
/Users/zacayd@octopai.com/Scala1
/Users/zacayd@octopai.com/pythony
/Users/zacayd@octopai.com/py2
/Users/zacayd@octopai.com/TEST
/Users/zacayd@octopai.com/ScalaHarverster
/Users/zacayd@octopai.com/MyTest
/Users/zacayd@octopai.com/Azure Blob Storage
/Users/zacayd@octopai.com/MySQL
/Users/zacayd@octopai.com/ExampleDLT
/Users/zacayd@octopai.com/ExampleDLT_SQL
/Users/zacayd@octopai.com/Untitled Notebook 2023-06-12 15:44:30
/Users/zacayd@octopai.com/MyLogs
/Users/zacayd@octopai.com/Helper
/Users/zacayd@octopai.com/Digicel_SandvineBilling
/Users/zacayd@octopai.com/Digicel
/Users/zacayd@octopai.com/Scalal
/Users/zacayd@octopai.com/2022-10-25 - DBFS Example
/Users/zacayd@octopai.com/pythonX
/Users/zacayd@octopai.com/Sql_PY
/Users/zacayd@octopai.com/ScalaPython
/Shared/Untitled Notebook 2023-05-23 09:28:27
/Shared/DL_BULKSMS_JAM
/Shared/AAP_CLIENT
/Shared/Sandvine_BillingRecon
/Shared/SELFCARE_USAGE
/Shared/ShakeIT_WonReward
/Shared/ODS_Digicel_App
/Shared/ODS_Digicel_App_User
/Shared/ODS_Selfcare_Incremental
/Shared/ODS_ShakeITAttempt
/Shared/Data-Delivery/EDW/NB_CargaTbContratoVarejo
/Shared/Querying the Delta Live Tables event log
/Shared/DL_BULKSMS_JAM_TEST
/Formula1-Project-Solutions/Section-16-17-18/utils/1.prepare_for_incremental_load
/Formula1-Project-Solutions/Section-16-17-18/analysis/3.viz_dominant_drivers
/Formula1-Project-Solutions/Section-16-17-18/analysis/4.viz_dominant_teams
/Formula1-Project-Solutions/Section-16-17-18/analysis/2.find_dominant_teams
/Formula1-Project-Solutions/Section-16-17-18/analysis/1.find_dominant_drivers
/Formula1-Project-Solutions/Section-16-17-18/ingestion/6.ingest_pit_stops_file
/Formula1-Project-Solutions/Section-16-17-18/ingestion/3.ingest_constructors_file
/Formula1-Project-Solutions/Section-16-17-18/ingestion/2.ingest_races_file
/Formula1-Project-Solutions/Section-16-17-18/ingestion/9.create_processed_database
/Formula1-Project-Solutions/Section-16-17-18/ingestion/8.ingest_qualifying_file
/Formula1-Project-Solutions/Section-16-17-18/ingestion/4.ingest_drivers_file
/Formula1-Project-Solutions/Section-16-17-18/ingestion/5.ingest_results_file
/Formula1-Project-Solutions/Section-16-17-18/ingestion/7.ingest_lap_times_file
/Formula1-Project-Solutions/Section-16-17-18/ingestion/1.ingest_circuits_file
/Formula1-Project-Solutions/Section-16-17-18/ingestion/0.ingest_all_files
/Formula1-Project-Solutions/Section-16-17-18/raw/1.create_raw_tables
/Formula1-Project-Solutions/Section-14/trans/3.constructor_standings
/Formula1-Project-Solutions/Section-14/trans/2.driver_standings
/Formula1-Project-Solutions/Section-14/trans/1.race_results
/Formula1-Project-Solutions/Section-12/ingestion/2.ingest_races_file
/Formula1-Project-Solutions/Section-12/ingestion/5.ingest_results_file
/Formula1-Project-Solutions/Section-12/ingestion/8.ingest_qualifying_file
/Formula1-Project-Solutions/Section-12/ingestion/1.ingest_circuits_file
/Formula1-Project-Solutions/Section-12/ingestion/0.ingest_all_files
/Formula1-Project-Solutions/Section-12/ingestion/6.ingest_pit_stops_file
/Formula1-Project-Solutions/Section-12/ingestion/7.ingest_lap_times_file
/Formula1-Project-Solutions/Section-12/ingestion/3.ingest_constructors_file
/Formula1-Project-Solutions/Section-12/ingestion/4.ingest_drivers_file
/Formula1-Project-Solutions/Section-06/mount_adls_storage-lesson-6
/Formula1-Project-Solutions/Section-06/mount_adls_storage-lesson-9
/Formula1-Project-Solutions/Section-09-10-11/ingestion/3.ingest_constructors_file
/Formula1-Project-Solutions/Section-09-10-11/ingestion/5.ingest_results_file
/Formula1-Project-Solutions/Section-09-10-11/ingestion/4.ingest_drivers_file
/Formula1-Project-Solutions/Section-09-10-11/ingestion/6.ingest_pit_stops_file
/Formula1-Project-Solutions/Section-09-10-11/ingestion/7.ingest_lap_times_file
/Formula1-Project-Solutions/Section-09-10-11/ingestion/2.ingest_races_file
/Formula1-Project-Solutions/Section-09-10-11/ingestion/1.ingest_circuits_file
/Formula1-Project-Solutions/Section-09-10-11/ingestion/8.ingest_qualifying_file
/Formula1-Project-Solutions/Section-19/ingestion/3.ingest_constructors_file
/Formula1-Project-Solutions/Section-19/ingestion/6.ingest_pit_stops_file
/Formula1-Project-Solutions/Section-19/ingestion/5.ingest_results_file
/Formula1-Project-Solutions/Section-19/ingestion/9.create_processed_database
/Formula1-Project-Solutions/Section-19/ingestion/8.ingest_qualifying_file
/Formula1-Project-Solutions/Section-19/ingestion/4.ingest_drivers_file
/Formula1-Project-Solutions/Section-19/ingestion/0.ingest_all_files
/Formula1-Project-Solutions/Section-19/ingestion/7.ingest_lap_times_file
/Formula1-Project-Solutions/Section-19/ingestion/1.ingest_circuits_file
/Formula1-Project-Solutions/Section-19/ingestion/2.ingest_races_file
/Formula1-Project-Solutions/Section-19/trans/4.calculated_race_results
/Formula1-Project-Solutions/Section-19/trans/0.create_presentation_database
/Formula1-Project-Solutions/Section-19/trans/3.constructor_standings
/Formula1-Project-Solutions/Section-19/trans/1.race_results
/Formula1-Project-Solutions/Section-19/trans/2.driver_standings
/Formula1-Project-Solutions/Section-19/includes/common_functions
/Formula1-Project-Solutions/Section-19/includes/configuration
/Formula1-Project-Solutions/Section-20/formula1/set-up/mount_adls_storage
/Formula1-Project-Solutions/Section-20/formula1/ingestion/7.ingest_lap_times_file
/Formula1-Project-Solutions/Section-20/formula1/ingestion/3.ingest_constructors_file
/Formula1-Project-Solutions/Section-20/formula1/ingestion/5.ingest_results_file
/Formula1-Project-Solutions/Section-20/formula1/ingestion/2.ingest_races_file
/Formula1-Project-Solutions/Section-20/formula1/ingestion/1.ingest_circuits_file
/Formula1-Project-Solutions/Section-20/formula1/ingestion/4.ingest_drivers_file
/Formula1-Project-Solutions/Section-20/formula1/ingestion/6.ingest_pit_stops_file
/Formula1-Project-Solutions/Section-20/formula1/ingestion/9.create_processed_database
/Formula1-Project-Solutions/Section-20/formula1/ingestion/0.ingest_all_files
/Formula1-Project-Solutions/Section-20/formula1/ingestion/8.ingest_qualifying_file
/Formula1-Project-Solutions/Section-20/formula1/utils/1.prepare_for_incremental_load
/Formula1-Project-Solutions/Section-20/formula1/trans/3.constructor_standings
/Formula1-Project-Solutions/Section-20/formula1/trans/4.calculated_race_results
/Formula1-Project-Solutions/Section-20/formula1/trans/1.race_results
/Formula1-Project-Solutions/Section-20/formula1/trans/0.create_presentation_database
/Formula1-Project-Solutions/Section-20/formula1/trans/2.driver_standings
/Formula1-Project-Solutions/Section-20/formula1/analysis/3.viz_dominant_drivers
/Formula1-Project-Solutions/Section-20/formula1/analysis/1.find_dominant_drivers
/Formula1-Project-Solutions/Section-20/formula1/analysis/2.find_dominant_teams
/Formula1-Project-Solutions/Section-20/formula1/analysis/4.viz_dominant_teams
/Formula1-Project-Solutions/Section-20/formula1/raw/1.create_raw_tables
/Formula1-Project-Solutions/Section-20/formula1/demo/8.sql_functions_demo
/Formula1-Project-Solutions/Section-20/formula1/demo/5.sql_temp_view_demo
/Formula1-Project-Solutions/Section-20/formula1/demo/6.sql_objects_demo
/Formula1-Project-Solutions/Section-20/formula1/demo/2.join_demo
/Formula1-Project-Solutions/Section-20/formula1/demo/9.sql_joins_demo
/Formula1-Project-Solutions/Section-20/formula1/demo/4.sql_temp_view_demo
/Formula1-Project-Solutions/Section-20/formula1/demo/3.aggregation_demo
/Formula1-Project-Solutions/Section-20/formula1/demo/10.delta_lake_demo
/Formula1-Project-Solutions/Section-20/formula1/demo/7.sql_basics_demo
/Formula1-Project-Solutions/Section-20/formula1/demo/1.filter_demo
/Formula1-Project-Solutions/Section-20/formula1/includes/configuration
/Formula1-Project-Solutions/Section-20/formula1/includes/common_functions
/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/7.ingest_lap_times_file
/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/2.ingest_races_file
/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/5.ingest_results_file
/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/9.create_processed_database
/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/3.ingest_constructors_file
/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/1.ingest_circuits_file
/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/0.ingest_all_files
/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/4.ingest_drivers_file
/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/8.ingest_qualifying_file
/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/6.ingest_pit_stops_file
/Formula1-Project-Solutions/Z-End of Course/formula1/set-up/mount_adls_storage
/Formula1-Project-Solutions/Z-End of Course/formula1/demo/6.sql_objects_demo
/Formula1-Project-Solutions/Z-End of Course/formula1/demo/7.sql_basics_demo
/Formula1-Project-Solutions/Z-End of Course/formula1/demo/8.sql_functions_demo
/Formula1-Project-Solutions/Z-End of Course/formula1/demo/4.sql_temp_view_demo
/Formula1-Project-Solutions/Z-End of Course/formula1/demo/3.aggregation_demo
/Formula1-Project-Solutions/Z-End of Course/formula1/demo/1.filter_demo
/Formula1-Project-Solutions/Z-End of Course/formula1/demo/2.join_demo
/Formula1-Project-Solutions/Z-End of Course/formula1/demo/5.sql_temp_view_demo
/Formula1-Project-Solutions/Z-End of Course/formula1/demo/9.sql_joins_demo
/Formula1-Project-Solutions/Z-End of Course/formula1/demo/10.delta_lake_demo
/Formula1-Project-Solutions/Z-End of Course/formula1/includes/common_functions
/Formula1-Project-Solutions/Z-End of Course/formula1/includes/configuration
/Formula1-Project-Solutions/Z-End of Course/formula1/utils/1.prepare_for_incremental_load
/Formula1-Project-Solutions/Z-End of Course/formula1/raw/1.create_raw_tables
/Formula1-Project-Solutions/Z-End of Course/formula1/trans/0.create_presentation_database
/Formula1-Project-Solutions/Z-End of Course/formula1/trans/2.driver_standings
/Formula1-Project-Solutions/Z-End of Course/formula1/trans/1.race_results
/Formula1-Project-Solutions/Z-End of Course/formula1/trans/3.constructor_standings
/Formula1-Project-Solutions/Z-End of Course/formula1/trans/4.calculated_race_results
/Formula1-Project-Solutions/Z-End of Course/formula1/analysis/3.viz_dominant_drivers
/Formula1-Project-Solutions/Z-End of Course/formula1/analysis/1.find_dominant_drivers
/Formula1-Project-Solutions/Z-End of Course/formula1/analysis/4.viz_dominant_teams
/Formula1-Project-Solutions/Z-End of Course/formula1/analysis/2.find_dominant_teams
/Formula1-Project-Solutions/Querying the Delta Live Tables event log
/AAP_USER
/ShakeIT_Attempt
/ODS_Selfcare_Incremental
/ODS_ShakeITWonReward
/ODS_ShakeITWonReward (1)
Successfully wrote content to notebooks.json.
json file was created:notebooks.json
number of notebooks:420
print("seee")

# COMMAND ----------

print("see1e")
/Formula1-Project-Solutions (1)/Section-16-17-18/utils/1.prepare_for_incremental_load
'-- Databricks notebook source
%python
sc._jvm.za.co.absa.spline.harvester.SparkLineageInitializer.enableLineageTracking(spark._jsparkSession)

-- COMMAND ----------

-- MAGIC %scala
-- MAGIC import scala.util.parsing.json.JSON
-- MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
-- MAGIC import za.co.absa.spline.agent.AgentConfig
-- MAGIC import za.co.absa.spline.harvester.postprocessing.AbstractPostProcessingFilter
-- MAGIC import za.co.absa.spline.harvester.postprocessing.PostProcessingFilter
-- MAGIC import org.apache.commons.configuration.Configuration
-- MAGIC import za.co.absa.spline.harvester.conf.StandardSplineConfigurationStack
-- MAGIC import za.co.absa.spline.harvester.HarvestingContext
-- MAGIC import za.co.absa.spline.producer.model.ExecutionPlan
-- MAGIC import za.co.absa.spline.producer.model.ExecutionEvent
-- MAGIC import za.co.absa.spline.producer.model.ReadOperation
-- MAGIC import za.co.absa.spline.producer.model.WriteOperation
-- MAGIC import za.co.absa.spline.producer.model.DataOperation
-- MAGIC import za.co.absa.spline.harvester.ExtraMetadataImplicits._
-- MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
-- MAGIC
-- MAGIC val notebookInformationJson = dbutils.notebook.getContext.toJson
-- MAGIC val outerMap = JSON.parseFull(notebookInformationJson).getOrElse(0).asInstanceOf[Map[String,String]]
-- MAGIC val tagMap = outerMap("tags").asInstanceOf[Map[String,String]]
-- MAGIC val extraContextMap = outerMap("extraContext").asInstanceOf[Map[String,String]]
-- MAGIC val notebookPath = extraContextMap("notebook_path").split("/")
-- MAGIC val workspaceUrl=tagMap("browserHostName")
-- MAGIC
-- MAGIC val workspaceName=dbutils.notebook().getContext().notebookPath.get
-- MAGIC val notebookURL = tagMap("browserHostName")+"/?o="+tagMap("orgId")+tagMap("browserHash")
-- MAGIC val user = tagMap("user")
-- MAGIC val name = notebookPath(notebookPath.size-1)
-- MAGIC val notebookInfo = Map("notebookURL" -> notebookURL,
-- MAGIC "user" -> user,
-- MAGIC "workspaceName" ->workspaceName,
-- MAGIC "workspaceUrl" -> workspaceUrl,
-- MAGIC "name" -> name,
-- MAGIC "mounts" -> dbutils.fs.ls("/FileStore/tables").map(_.path),
-- MAGIC "timestamp" -> System.currentTimeMillis)
-- MAGIC val notebookInfoJson = scala.util.parsing.json.JSONObject(notebookInfo)
-- MAGIC
-- MAGIC
-- MAGIC class CustomFilter extends PostProcessingFilter {
-- MAGIC   def this(conf: Configuration) = this()
-- MAGIC
-- MAGIC   override def processExecutionEvent(event: ExecutionEvent, ctx: HarvestingContext): ExecutionEvent =
-- MAGIC     event.withAddedExtra(Map("foo" -> "bar"))
-- MAGIC
-- MAGIC   override def processExecutionPlan(plan: ExecutionPlan, ctx: HarvestingContext ): ExecutionPlan =
-- MAGIC     plan.withAddedExtra(Map( "notebookInfo" -> notebookInfoJson))
-- MAGIC
-- MAGIC   override def processReadOperation(op: ReadOperation, ctx: HarvestingContext ): ReadOperation =
-- MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
-- MAGIC
-- MAGIC   override def processWriteOperation(op: WriteOperation, ctx: HarvestingContext): WriteOperation =
-- MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
-- MAGIC
-- MAGIC   override def processDataOperation(op: DataOperation, ctx: HarvestingContext  ): DataOperation =
-- MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
-- MAGIC }
-- MAGIC
-- MAGIC
-- MAGIC
-- MAGIC val myInstance = new CustomFilter()
-- MAGIC
-- MAGIC
-- MAGIC spark.enableLineageTracking(
-- MAGIC   AgentConfig.builder()
-- MAGIC     .postProcessingFilter(myInstance)
-- MAGIC     .build()
-- MAGIC )

-- COMMAND ----------

CREATE DATABASE IF NOT EXISTS f1_processed
LOCATION "/mnt/formula1dl/processed"

-- COMMAND ----------

DESC DATABASE f1_processed;

-- COMMAND ----------


/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/9.create_processed_database
# MAGIC %scala
# MAGIC import scala.util.parsing.json.JSON
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC import za.co.absa.spline.agent.AgentConfig
# MAGIC import za.co.absa.spline.harvester.postprocessing.AbstractPostProcessingFilter
# MAGIC import za.co.absa.spline.harvester.postprocessing.PostProcessingFilter
# MAGIC import org.apache.commons.configuration.Configuration
# MAGIC import za.co.absa.spline.harvester.conf.StandardSplineConfigurationStack
# MAGIC import za.co.absa.spline.harvester.HarvestingContext
# MAGIC import za.co.absa.spline.producer.model.ExecutionPlan
# MAGIC import za.co.absa.spline.producer.model.ExecutionEvent
# MAGIC import za.co.absa.spline.producer.model.ReadOperation
# MAGIC import za.co.absa.spline.producer.model.WriteOperation
# MAGIC import za.co.absa.spline.producer.model.DataOperation
# MAGIC import za.co.absa.spline.harvester.ExtraMetadataImplicits._
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC
# MAGIC val notebookInformationJson = dbutils.notebook.getContext.toJson
# MAGIC val outerMap = JSON.parseFull(notebookInformationJson).getOrElse(0).asInstanceOf[Map[String,String]]
# MAGIC val tagMap = outerMap("tags").asInstanceOf[Map[String,String]]
# MAGIC val extraContextMap = outerMap("extraContext").asInstanceOf[Map[String,String]]
# MAGIC val notebookPath = extraContextMap("notebook_path").split("/")
# MAGIC val workspaceUrl=tagMap("browserHostName")
# MAGIC
# MAGIC val workspaceName=dbutils.notebook().getContext().notebookPath.get
# MAGIC val notebookURL = tagMap("browserHostName")+"/?o="+tagMap("orgId")+tagMap("browserHash")
# MAGIC val user = tagMap("user")
# MAGIC val name = notebookPath(notebookPath.size-1)
# MAGIC val notebookInfo = Map("notebookURL" -> notebookURL,
# MAGIC "user" -> user,
# MAGIC "workspaceName" ->workspaceName,
# MAGIC "workspaceUrl" -> workspaceUrl,
# MAGIC "name" -> name,
# MAGIC "mounts" -> dbutils.fs.ls("/FileStore/tables").map(_.path),
# MAGIC "timestamp" -> System.currentTimeMillis)
# MAGIC val notebookInfoJson = scala.util.parsing.json.JSONObject(notebookInfo)
# MAGIC
# MAGIC
# MAGIC class CustomFilter extends PostProcessingFilter {
# MAGIC   def this(conf: Configuration) = this()
# MAGIC
# MAGIC   override def processExecutionEvent(event: ExecutionEvent, ctx: HarvestingContext): ExecutionEvent =
# MAGIC     event.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processExecutionPlan(plan: ExecutionPlan, ctx: HarvestingContext ): ExecutionPlan =
# MAGIC     plan.withAddedExtra(Map( "notebookInfo" -> notebookInfoJson))
# MAGIC
# MAGIC   override def processReadOperation(op: ReadOperation, ctx: HarvestingContext ): ReadOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processWriteOperation(op: WriteOperation, ctx: HarvestingContext): WriteOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processDataOperation(op: DataOperation, ctx: HarvestingContext  ): DataOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC }
# MAGIC
# MAGIC
# MAGIC
# MAGIC val myInstance = new CustomFilter()
# MAGIC
# MAGIC
# MAGIC spark.enableLineageTracking(
# MAGIC   AgentConfig.builder()
# MAGIC     .postProcessingFilter(myInstance)
# MAGIC     .build()
# MAGIC )

# COMMAND ----------

sc._jvm.za.co.absa.spline.harvester.SparkLineageInitializer.enableLineageTracking(spark._jsparkSession)

# COMMAND ----------

# MAGIC %scala
# MAGIC import scala.util.parsing.json.JSON
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC import za.co.absa.spline.agent.AgentConfig
# MAGIC import za.co.absa.spline.harvester.postprocessing.AbstractPostProcessingFilter
# MAGIC import za.co.absa.spline.harvester.postprocessing.PostProcessingFilter
# MAGIC import org.apache.commons.configuration.Configuration
# MAGIC import za.co.absa.spline.harvester.conf.StandardSplineConfigurationStack
# MAGIC import za.co.absa.spline.harvester.HarvestingContext
# MAGIC import za.co.absa.spline.producer.model.ExecutionPlan
# MAGIC import za.co.absa.spline.producer.model.ExecutionEvent
# MAGIC import za.co.absa.spline.producer.model.ReadOperation
# MAGIC import za.co.absa.spline.producer.model.WriteOperation
# MAGIC import za.co.absa.spline.producer.model.DataOperation
# MAGIC import za.co.absa.spline.harvester.ExtraMetadataImplicits._
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC
# MAGIC val notebookInformationJson = dbutils.notebook.getContext.toJson
# MAGIC val outerMap = JSON.parseFull(notebookInformationJson).getOrElse(0).asInstanceOf[Map[String,String]]
# MAGIC val tagMap = outerMap("tags").asInstanceOf[Map[String,String]]
# MAGIC val extraContextMap = outerMap("extraContext").asInstanceOf[Map[String,String]]
# MAGIC val notebookPath = extraContextMap("notebook_path").split("/")
# MAGIC val workspaceUrl=tagMap("browserHostName")
# MAGIC
# MAGIC val workspaceName=dbutils.notebook().getContext().notebookPath.get
# MAGIC val notebookURL = tagMap("browserHostName")+"/?o="+tagMap("orgId")+tagMap("browserHash")
# MAGIC val user = tagMap("user")
# MAGIC val name = notebookPath(notebookPath.size-1)
# MAGIC val notebookInfo = Map("notebookURL" -> notebookURL,
# MAGIC "user" -> user,
# MAGIC "workspaceName" ->workspaceName,
# MAGIC "workspaceUrl" -> workspaceUrl,
# MAGIC "name" -> name,
# MAGIC "mounts" -> dbutils.fs.ls("/FileStore/tables").map(_.path),
# MAGIC "timestamp" -> System.currentTimeMillis)
# MAGIC val notebookInfoJson = scala.util.parsing.json.JSONObject(notebookInfo)
# MAGIC
# MAGIC
# MAGIC class CustomFilter extends PostProcessingFilter {
# MAGIC   def this(conf: Configuration) = this()
# MAGIC
# MAGIC   override def processExecutionEvent(event: ExecutionEvent, ctx: HarvestingContext): ExecutionEvent =
# MAGIC     event.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processExecutionPlan(plan: ExecutionPlan, ctx: HarvestingContext ): ExecutionPlan =
# MAGIC     plan.withAddedExtra(Map( "notebookInfo" -> notebookInfoJson))
# MAGIC
# MAGIC   override def processReadOperation(op: ReadOperation, ctx: HarvestingContext ): ReadOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processWriteOperation(op: WriteOperation, ctx: HarvestingContext): WriteOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processDataOperation(op: DataOperation, ctx: HarvestingContext  ): DataOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC }
# MAGIC
# MAGIC
# MAGIC
# MAGIC val myInstance = new CustomFilter()
# MAGIC
# MAGIC
# MAGIC spark.enableLineageTracking(
# MAGIC   AgentConfig.builder()
# MAGIC     .postProcessingFilter(myInstance)
# MAGIC     .build()
# MAGIC )

# COMMAND ----------



# COMMAND ----------



# COMMAND ----------

# MAGIC %scala
# MAGIC import scala.util.parsing.json.JSON
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC import za.co.absa.spline.agent.AgentConfig
# MAGIC import za.co.absa.spline.harvester.postprocessing.AbstractPostProcessingFilter
# MAGIC import za.co.absa.spline.harvester.postprocessing.PostProcessingFilter
# MAGIC import org.apache.commons.configuration.Configuration
# MAGIC import za.co.absa.spline.harvester.conf.StandardSplineConfigurationStack
# MAGIC import za.co.absa.spline.harvester.HarvestingContext
# MAGIC import za.co.absa.spline.producer.model.ExecutionPlan
# MAGIC import za.co.absa.spline.producer.model.ExecutionEvent
# MAGIC import za.co.absa.spline.producer.model.ReadOperation
# MAGIC import za.co.absa.spline.producer.model.WriteOperation
# MAGIC import za.co.absa.spline.producer.model.DataOperation
# MAGIC import za.co.absa.spline.harvester.ExtraMetadataImplicits._
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC
# MAGIC val notebookInformationJson = dbutils.notebook.getContext.toJson
# MAGIC val outerMap = JSON.parseFull(notebookInformationJson).getOrElse(0).asInstanceOf[Map[String,String]]
# MAGIC val tagMap = outerMap("tags").asInstanceOf[Map[String,String]]
# MAGIC val extraContextMap = outerMap("extraContext").asInstanceOf[Map[String,String]]
# MAGIC val notebookPath = extraContextMap("notebook_path").split("/")
# MAGIC val workspaceUrl=tagMap("browserHostName")
# MAGIC
# MAGIC val workspaceName=dbutils.notebook().getContext().notebookPath.get
# MAGIC val notebookURL = tagMap("browserHostName")+"/?o="+tagMap("orgId")+tagMap("browserHash")
# MAGIC val user = tagMap("user")
# MAGIC val name = notebookPath(notebookPath.size-1)
# MAGIC val notebookInfo = Map("notebookURL" -> notebookURL,
# MAGIC "user" -> user,
# MAGIC "workspaceName" ->workspaceName,
# MAGIC "workspaceUrl" -> workspaceUrl,
# MAGIC "name" -> name,
# MAGIC "mounts" -> dbutils.fs.ls("/FileStore/tables").map(_.path),
# MAGIC "timestamp" -> System.currentTimeMillis)
# MAGIC val notebookInfoJson = scala.util.parsing.json.JSONObject(notebookInfo)
# MAGIC
# MAGIC
# MAGIC class CustomFilter extends PostProcessingFilter {
# MAGIC   def this(conf: Configuration) = this()
# MAGIC
# MAGIC   override def processExecutionEvent(event: ExecutionEvent, ctx: HarvestingContext): ExecutionEvent =
# MAGIC     event.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processExecutionPlan(plan: ExecutionPlan, ctx: HarvestingContext ): ExecutionPlan =
# MAGIC     plan.withAddedExtra(Map( "notebookInfo" -> notebookInfoJson))
# MAGIC
# MAGIC   override def processReadOperation(op: ReadOperation, ctx: HarvestingContext ): ReadOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processWriteOperation(op: WriteOperation, ctx: HarvestingContext): WriteOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processDataOperation(op: DataOperation, ctx: HarvestingContext  ): DataOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC }
# MAGIC
# MAGIC
# MAGIC
# MAGIC val myInstance = new CustomFilter()
# MAGIC
# MAGIC
# MAGIC spark.enableLineageTracking(
# MAGIC   AgentConfig.builder()
# MAGIC     .postProcessingFilter(myInstance)
# MAGIC     .build()
# MAGIC )

# COMMAND ----------

v_result = dbutils.notebook.run("1.ingest_circuits_file", 0, {"p_data_source": "Ergast API"})

# COMMAND ----------

v_result

# COMMAND ----------

v_result = dbutils.notebook.run("2.ingest_races_file", 0, {"p_data_source": "Ergast API"})

# COMMAND ----------

v_result

# COMMAND ----------

v_result = dbutils.notebook.run("3.ingest_constructors_file", 0, {"p_data_source": "Ergast API"})

# COMMAND ----------

v_result

# COMMAND ----------

v_result = dbutils.notebook.run("4.ingest_drivers_file", 0, {"p_data_source": "Ergast API"})

# COMMAND ----------

v_result

# COMMAND ----------

v_result = dbutils.notebook.run("5.ingest_results_file", 0, {"p_data_source": "Ergast API"})

# COMMAND ----------

v_result

# COMMAND ----------

v_result = dbutils.notebook.run("6.ingest_pit_stops_file", 0, {"p_data_source": "Ergast API"})

# COMMAND ----------

v_result

# COMMAND ----------

v_result = dbutils.notebook.run("7.ingest_lap_times_file", 0, {"p_data_source": "Ergast API"})

# COMMAND ----------

v_result

# COMMAND ----------

v_result = dbutils.notebook.run("8.ingest_qualifying_file", 0, {"p_data_source": "Ergast API"})

# COMMAND ----------

v_result
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/0.ingest_all_files
sc._jvm.za.co.absa.spline.harvester.SparkLineageInitializer.enableLineageTracking(spark._jsparkSession)

# COMMAND ----------

# MAGIC %scala
# MAGIC import scala.util.parsing.json.JSON
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC import za.co.absa.spline.agent.AgentConfig
# MAGIC import za.co.absa.spline.harvester.postprocessing.AbstractPostProcessingFilter
# MAGIC import za.co.absa.spline.harvester.postprocessing.PostProcessingFilter
# MAGIC import org.apache.commons.configuration.Configuration
# MAGIC import za.co.absa.spline.harvester.conf.StandardSplineConfigurationStack
# MAGIC import za.co.absa.spline.harvester.HarvestingContext
# MAGIC import za.co.absa.spline.producer.model.ExecutionPlan
# MAGIC import za.co.absa.spline.producer.model.ExecutionEvent
# MAGIC import za.co.absa.spline.producer.model.ReadOperation
# MAGIC import za.co.absa.spline.producer.model.WriteOperation
# MAGIC import za.co.absa.spline.producer.model.DataOperation
# MAGIC import za.co.absa.spline.harvester.ExtraMetadataImplicits._
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC
# MAGIC val notebookInformationJson = dbutils.notebook.getContext.toJson
# MAGIC val outerMap = JSON.parseFull(notebookInformationJson).getOrElse(0).asInstanceOf[Map[String,String]]
# MAGIC val tagMap = outerMap("tags").asInstanceOf[Map[String,String]]
# MAGIC val extraContextMap = outerMap("extraContext").asInstanceOf[Map[String,String]]
# MAGIC val notebookPath = extraContextMap("notebook_path").split("/")
# MAGIC val workspaceUrl=tagMap("browserHostName")
# MAGIC
# MAGIC val workspaceName=dbutils.notebook().getContext().notebookPath.get
# MAGIC val notebookURL = tagMap("browserHostName")+"/?o="+tagMap("orgId")+tagMap("browserHash")
# MAGIC val user = tagMap("user")
# MAGIC val name = notebookPath(notebookPath.size-1)
# MAGIC val notebookInfo = Map("notebookURL" -> notebookURL,
# MAGIC "user" -> user,
# MAGIC "workspaceName" ->workspaceName,
# MAGIC "workspaceUrl" -> workspaceUrl,
# MAGIC "name" -> name,
# MAGIC "mounts" -> dbutils.fs.ls("/FileStore/tables").map(_.path),
# MAGIC "timestamp" -> System.currentTimeMillis)
# MAGIC val notebookInfoJson = scala.util.parsing.json.JSONObject(notebookInfo)
# MAGIC
# MAGIC
# MAGIC class CustomFilter extends PostProcessingFilter {
# MAGIC   def this(conf: Configuration) = this()
# MAGIC
# MAGIC   override def processExecutionEvent(event: ExecutionEvent, ctx: HarvestingContext): ExecutionEvent =
# MAGIC     event.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processExecutionPlan(plan: ExecutionPlan, ctx: HarvestingContext ): ExecutionPlan =
# MAGIC     plan.withAddedExtra(Map( "notebookInfo" -> notebookInfoJson))
# MAGIC
# MAGIC   override def processReadOperation(op: ReadOperation, ctx: HarvestingContext ): ReadOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processWriteOperation(op: WriteOperation, ctx: HarvestingContext): WriteOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processDataOperation(op: DataOperation, ctx: HarvestingContext  ): DataOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC }
# MAGIC
# MAGIC
# MAGIC
# MAGIC val myInstance = new CustomFilter()
# MAGIC
# MAGIC
# MAGIC spark.enableLineageTracking(
# MAGIC   AgentConfig.builder()
# MAGIC     .postProcessingFilter(myInstance)
# MAGIC     .build()
# MAGIC )

# COMMAND ----------

# MAGIC %md
# MAGIC ### Ingest lap_times folder

# COMMAND ----------

dbutils.widgets.text("p_data_source", "")
v_data_source = dbutils.widgets.get("p_data_source")

# COMMAND ----------

# MAGIC %run "../includes/configuration"

# COMMAND ----------

# MAGIC %run "../includes/common_functions"

# COMMAND ----------

# MAGIC %md
# MAGIC ##### Step 1 - Read the CSV file using the spark dataframe reader API

# COMMAND ----------

from pyspark.sql.types import StructType, StructField, IntegerType, StringType

# COMMAND ----------

lap_times_schema = StructType(fields=[StructField("raceId", IntegerType(), False),
                                      StructField("driverId", IntegerType(), True),
                                      StructField("lap", IntegerType(), True),
                                      StructField("position", IntegerType(), True),
                                      StructField("time", StringType(), True),
                                      StructField("milliseconds", IntegerType(), True)
                                     ])

# COMMAND ----------

lap_times_df = spark.read \
.schema(lap_times_schema) \
.csv(f"{raw_folder_path}/lap_times")

# COMMAND ----------

# MAGIC %md
# MAGIC ##### Step 2 - Rename columns and add new columns
# MAGIC 1. Rename driverId and raceId
# MAGIC 1. Add ingestion_date with current timestamp

# COMMAND ----------

lap_times_with_ingestion_date_df = add_ingestion_date(lap_times_df)

# COMMAND ----------

from pyspark.sql.functions import lit

# COMMAND ----------

final_df = lap_times_with_ingestion_date_df.withColumnRenamed("driverId", "driver_id") \
.withColumnRenamed("raceId", "race_id") \
.withColumn("ingestion_date", current_timestamp()) \
.withColumn("data_source", lit(v_data_source))

# COMMAND ----------

# MAGIC %md
# MAGIC ##### Step 3 - Write to output to processed container in parquet format

# COMMAND ----------

final_df.write.mode("overwrite").format("parquet").saveAsTable("f1_processed.lap_times")

# COMMAND ----------

dbutils.notebook.exit("Success")
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/7.ingest_lap_times_file
sc._jvm.za.co.absa.spline.harvester.SparkLineageInitializer.enableLineageTracking(spark._jsparkSession)

# COMMAND ----------

# MAGIC %scala
# MAGIC import scala.util.parsing.json.JSON
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC import za.co.absa.spline.agent.AgentConfig
# MAGIC import za.co.absa.spline.harvester.postprocessing.AbstractPostProcessingFilter
# MAGIC import za.co.absa.spline.harvester.postprocessing.PostProcessingFilter
# MAGIC import org.apache.commons.configuration.Configuration
# MAGIC import za.co.absa.spline.harvester.conf.StandardSplineConfigurationStack
# MAGIC import za.co.absa.spline.harvester.HarvestingContext
# MAGIC import za.co.absa.spline.producer.model.ExecutionPlan
# MAGIC import za.co.absa.spline.producer.model.ExecutionEvent
# MAGIC import za.co.absa.spline.producer.model.ReadOperation
# MAGIC import za.co.absa.spline.producer.model.WriteOperation
# MAGIC import za.co.absa.spline.producer.model.DataOperation
# MAGIC import za.co.absa.spline.harvester.ExtraMetadataImplicits._
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC
# MAGIC val notebookInformationJson = dbutils.notebook.getContext.toJson
# MAGIC val outerMap = JSON.parseFull(notebookInformationJson).getOrElse(0).asInstanceOf[Map[String,String]]
# MAGIC val tagMap = outerMap("tags").asInstanceOf[Map[String,String]]
# MAGIC val extraContextMap = outerMap("extraContext").asInstanceOf[Map[String,String]]
# MAGIC val notebookPath = extraContextMap("notebook_path").split("/")
# MAGIC val workspaceUrl=tagMap("browserHostName")
# MAGIC
# MAGIC val workspaceName=dbutils.notebook().getContext().notebookPath.get
# MAGIC val notebookURL = tagMap("browserHostName")+"/?o="+tagMap("orgId")+tagMap("browserHash")
# MAGIC val user = tagMap("user")
# MAGIC val name = notebookPath(notebookPath.size-1)
# MAGIC val notebookInfo = Map("notebookURL" -> notebookURL,
# MAGIC "user" -> user,
# MAGIC "workspaceName" ->workspaceName,
# MAGIC "workspaceUrl" -> workspaceUrl,
# MAGIC "name" -> name,
# MAGIC "mounts" -> dbutils.fs.ls("/FileStore/tables").map(_.path),
# MAGIC "timestamp" -> System.currentTimeMillis)
# MAGIC val notebookInfoJson = scala.util.parsing.json.JSONObject(notebookInfo)
# MAGIC
# MAGIC
# MAGIC class CustomFilter extends PostProcessingFilter {
# MAGIC   def this(conf: Configuration) = this()
# MAGIC
# MAGIC   override def processExecutionEvent(event: ExecutionEvent, ctx: HarvestingContext): ExecutionEvent =
# MAGIC     event.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processExecutionPlan(plan: ExecutionPlan, ctx: HarvestingContext ): ExecutionPlan =
# MAGIC     plan.withAddedExtra(Map( "notebookInfo" -> notebookInfoJson))
# MAGIC
# MAGIC   override def processReadOperation(op: ReadOperation, ctx: HarvestingContext ): ReadOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processWriteOperation(op: WriteOperation, ctx: HarvestingContext): WriteOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processDataOperation(op: DataOperation, ctx: HarvestingContext  ): DataOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC }
# MAGIC
# MAGIC
# MAGIC
# MAGIC val myInstance = new CustomFilter()
# MAGIC
# MAGIC
# MAGIC spark.enableLineageTracking(
# MAGIC   AgentConfig.builder()
# MAGIC     .postProcessingFilter(myInstance)
# MAGIC     .build()
# MAGIC )

# COMMAND ----------

# MAGIC %md
# MAGIC ### Ingest qualifying json files

# COMMAND ----------

dbutils.widgets.text("p_data_source", "")
v_data_source = dbutils.widgets.get("p_data_source")

# COMMAND ----------

# MAGIC %run "../includes/configuration"

# COMMAND ----------

# MAGIC %run "../includes/common_functions"

# COMMAND ----------

# MAGIC %md
# MAGIC ##### Step 1 - Read the JSON file using the spark dataframe reader API

# COMMAND ----------

from pyspark.sql.types import StructType, StructField, IntegerType, StringType

# COMMAND ----------

qualifying_schema = StructType(fields=[StructField("qualifyId", IntegerType(), False),
                                      StructField("raceId", IntegerType(), True),
                                      StructField("driverId", IntegerType(), True),
                                      StructField("constructorId", IntegerType(), True),
                                      StructField("number", IntegerType(), True),
                                      StructField("position", IntegerType(), True),
                                      StructField("q1", StringType(), True),
                                      StructField("q2", StringType(), True),
                                      StructField("q3", StringType(), True),
                                     ])

# COMMAND ----------

qualifying_df = spark.read \
.schema(qualifying_schema) \
.option("multiLine", True) \
.json(f"{raw_folder_path}/qualifying")

# COMMAND ----------

# MAGIC %md
# MAGIC ##### Step 2 - Rename columns and add new columns
# MAGIC 1. Rename qualifyingId, driverId, constructorId and raceId
# MAGIC 1. Add ingestion_date with current timestamp

# COMMAND ----------

qualifying_with_ingestion_date_df = add_ingestion_date(qualifying_df)

# COMMAND ----------

from pyspark.sql.functions import lit

# COMMAND ----------

final_df = qualifying_with_ingestion_date_df.withColumnRenamed("qualifyId", "qualify_id") \
.withColumnRenamed("driverId", "driver_id") \
.withColumnRenamed("raceId", "race_id") \
.withColumnRenamed("constructorId", "constructor_id") \
.withColumn("ingestion_date", current_timestamp()) \
.withColumn("data_source", lit(v_data_source))

# COMMAND ----------

# MAGIC %md
# MAGIC ##### Step 3 - Write to output to processed container in parquet format

# COMMAND ----------

final_df.write.mode("overwrite").format("parquet").saveAsTable("f1_processed.qualifying")

# COMMAND ----------

dbutils.notebook.exit("Success")
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/8.ingest_qualifying_file
sc._jvm.za.co.absa.spline.harvester.SparkLineageInitializer.enableLineageTracking(spark._jsparkSession)

# COMMAND ----------

# MAGIC %scala
# MAGIC import scala.util.parsing.json.JSON
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC import za.co.absa.spline.agent.AgentConfig
# MAGIC import za.co.absa.spline.harvester.postprocessing.AbstractPostProcessingFilter
# MAGIC import za.co.absa.spline.harvester.postprocessing.PostProcessingFilter
# MAGIC import org.apache.commons.configuration.Configuration
# MAGIC import za.co.absa.spline.harvester.conf.StandardSplineConfigurationStack
# MAGIC import za.co.absa.spline.harvester.HarvestingContext
# MAGIC import za.co.absa.spline.producer.model.ExecutionPlan
# MAGIC import za.co.absa.spline.producer.model.ExecutionEvent
# MAGIC import za.co.absa.spline.producer.model.ReadOperation
# MAGIC import za.co.absa.spline.producer.model.WriteOperation
# MAGIC import za.co.absa.spline.producer.model.DataOperation
# MAGIC import za.co.absa.spline.harvester.ExtraMetadataImplicits._
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC
# MAGIC val notebookInformationJson = dbutils.notebook.getContext.toJson
# MAGIC val outerMap = JSON.parseFull(notebookInformationJson).getOrElse(0).asInstanceOf[Map[String,String]]
# MAGIC val tagMap = outerMap("tags").asInstanceOf[Map[String,String]]
# MAGIC val extraContextMap = outerMap("extraContext").asInstanceOf[Map[String,String]]
# MAGIC val notebookPath = extraContextMap("notebook_path").split("/")
# MAGIC val workspaceUrl=tagMap("browserHostName")
# MAGIC
# MAGIC val workspaceName=dbutils.notebook().getContext().notebookPath.get
# MAGIC val notebookURL = tagMap("browserHostName")+"/?o="+tagMap("orgId")+tagMap("browserHash")
# MAGIC val user = tagMap("user")
# MAGIC val name = notebookPath(notebookPath.size-1)
# MAGIC val notebookInfo = Map("notebookURL" -> notebookURL,
# MAGIC "user" -> user,
# MAGIC "workspaceName" ->workspaceName,
# MAGIC "workspaceUrl" -> workspaceUrl,
# MAGIC "name" -> name,
# MAGIC "mounts" -> dbutils.fs.ls("/FileStore/tables").map(_.path),
# MAGIC "timestamp" -> System.currentTimeMillis)
# MAGIC val notebookInfoJson = scala.util.parsing.json.JSONObject(notebookInfo)
# MAGIC
# MAGIC
# MAGIC class CustomFilter extends PostProcessingFilter {
# MAGIC   def this(conf: Configuration) = this()
# MAGIC
# MAGIC   override def processExecutionEvent(event: ExecutionEvent, ctx: HarvestingContext): ExecutionEvent =
# MAGIC     event.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processExecutionPlan(plan: ExecutionPlan, ctx: HarvestingContext ): ExecutionPlan =
# MAGIC     plan.withAddedExtra(Map( "notebookInfo" -> notebookInfoJson))
# MAGIC
# MAGIC   override def processReadOperation(op: ReadOperation, ctx: HarvestingContext ): ReadOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processWriteOperation(op: WriteOperation, ctx: HarvestingContext): WriteOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processDataOperation(op: DataOperation, ctx: HarvestingContext  ): DataOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC }
# MAGIC
# MAGIC
# MAGIC
# MAGIC val myInstance = new CustomFilter()
# MAGIC
# MAGIC
# MAGIC spark.enableLineageTracking(
# MAGIC   AgentConfig.builder()
# MAGIC     .postProcessingFilter(myInstance)
# MAGIC     .build()
# MAGIC )

# COMMAND ----------

# MAGIC %md
# MAGIC ### Ingest pit_stops.json file

# COMMAND ----------

dbutils.widgets.text("p_data_source", "")
v_data_source = dbutils.widgets.get("p_data_source")

# COMMAND ----------

# MAGIC %run "../includes/configuration"

# COMMAND ----------

# MAGIC %run "../includes/common_functions"

# COMMAND ----------

# MAGIC %md
# MAGIC ##### Step 1 - Read the JSON file using the spark dataframe reader API

# COMMAND ----------

from pyspark.sql.types import StructType, StructField, IntegerType, StringType

# COMMAND ----------

pit_stops_schema = StructType(fields=[StructField("raceId", IntegerType(), False),
                                      StructField("driverId", IntegerType(), True),
                                      StructField("stop", StringType(), True),
                                      StructField("lap", IntegerType(), True),
                                      StructField("time", StringType(), True),
                                      StructField("duration", StringType(), True),
                                      StructField("milliseconds", IntegerType(), True)
                                     ])

# COMMAND ----------

pit_stops_df = spark.read \
.schema(pit_stops_schema) \
.option("multiLine", True) \
.json(f"{raw_folder_path}/pit_stops.json")

# COMMAND ----------

# MAGIC %md
# MAGIC ##### Step 2 - Rename columns and add new columns
# MAGIC 1. Rename driverId and raceId
# MAGIC 1. Add ingestion_date with current timestamp

# COMMAND ----------

pit_stops_with_ingestion_date_df = add_ingestion_date(pit_stops_df)

# COMMAND ----------

from pyspark.sql.functions import lit

# COMMAND ----------

final_df = pit_stops_with_ingestion_date_df.withColumnRenamed("driverId", "driver_id") \
.withColumnRenamed("raceId", "race_id") \
.withColumn("ingestion_date", current_timestamp()) \
.withColumn("data_source", lit(v_data_source))

# COMMAND ----------

# MAGIC %md
# MAGIC ##### Step 3 - Write to output to processed container in parquet format

# COMMAND ----------

final_df.write.mode("overwrite").format("parquet").saveAsTable("f1_processed.pit_stops")

# COMMAND ----------

dbutils.notebook.exit("Success")
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/6.ingest_pit_stops_file
sc._jvm.za.co.absa.spline.harvester.SparkLineageInitializer.enableLineageTracking(spark._jsparkSession)

# COMMAND ----------

# MAGIC %scala
# MAGIC import scala.util.parsing.json.JSON
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC import za.co.absa.spline.agent.AgentConfig
# MAGIC import za.co.absa.spline.harvester.postprocessing.AbstractPostProcessingFilter
# MAGIC import za.co.absa.spline.harvester.postprocessing.PostProcessingFilter
# MAGIC import org.apache.commons.configuration.Configuration
# MAGIC import za.co.absa.spline.harvester.conf.StandardSplineConfigurationStack
# MAGIC import za.co.absa.spline.harvester.HarvestingContext
# MAGIC import za.co.absa.spline.producer.model.ExecutionPlan
# MAGIC import za.co.absa.spline.producer.model.ExecutionEvent
# MAGIC import za.co.absa.spline.producer.model.ReadOperation
# MAGIC import za.co.absa.spline.producer.model.WriteOperation
# MAGIC import za.co.absa.spline.producer.model.DataOperation
# MAGIC import za.co.absa.spline.harvester.ExtraMetadataImplicits._
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC
# MAGIC val notebookInformationJson = dbutils.notebook.getContext.toJson
# MAGIC val outerMap = JSON.parseFull(notebookInformationJson).getOrElse(0).asInstanceOf[Map[String,String]]
# MAGIC val tagMap = outerMap("tags").asInstanceOf[Map[String,String]]
# MAGIC val extraContextMap = outerMap("extraContext").asInstanceOf[Map[String,String]]
# MAGIC val notebookPath = extraContextMap("notebook_path").split("/")
# MAGIC val workspaceUrl=tagMap("browserHostName")
# MAGIC
# MAGIC val workspaceName=dbutils.notebook().getContext().notebookPath.get
# MAGIC val notebookURL = tagMap("browserHostName")+"/?o="+tagMap("orgId")+tagMap("browserHash")
# MAGIC val user = tagMap("user")
# MAGIC val name = notebookPath(notebookPath.size-1)
# MAGIC val notebookInfo = Map("notebookURL" -> notebookURL,
# MAGIC "user" -> user,
# MAGIC "workspaceName" ->workspaceName,
# MAGIC "workspaceUrl" -> workspaceUrl,
# MAGIC "name" -> name,
# MAGIC "mounts" -> dbutils.fs.ls("/FileStore/tables").map(_.path),
# MAGIC "timestamp" -> System.currentTimeMillis)
# MAGIC val notebookInfoJson = scala.util.parsing.json.JSONObject(notebookInfo)
# MAGIC
# MAGIC
# MAGIC class CustomFilter extends PostProcessingFilter {
# MAGIC   def this(conf: Configuration) = this()
# MAGIC
# MAGIC   override def processExecutionEvent(event: ExecutionEvent, ctx: HarvestingContext): ExecutionEvent =
# MAGIC     event.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processExecutionPlan(plan: ExecutionPlan, ctx: HarvestingContext ): ExecutionPlan =
# MAGIC     plan.withAddedExtra(Map( "notebookInfo" -> notebookInfoJson))
# MAGIC
# MAGIC   override def processReadOperation(op: ReadOperation, ctx: HarvestingContext ): ReadOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processWriteOperation(op: WriteOperation, ctx: HarvestingContext): WriteOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processDataOperation(op: DataOperation, ctx: HarvestingContext  ): DataOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC }
# MAGIC
# MAGIC
# MAGIC
# MAGIC val myInstance = new CustomFilter()
# MAGIC
# MAGIC
# MAGIC spark.enableLineageTracking(
# MAGIC   AgentConfig.builder()
# MAGIC     .postProcessingFilter(myInstance)
# MAGIC     .build()
# MAGIC )

# COMMAND ----------

# MAGIC %md
# MAGIC ### Ingest drivers.json file

# COMMAND ----------

dbutils.widgets.text("p_data_source", "")
v_data_source = dbutils.widgets.get("p_data_source")

# COMMAND ----------

# MAGIC %run "../includes/configuration"

# COMMAND ----------

# MAGIC %run "../includes/common_functions"

# COMMAND ----------

# MAGIC %md
# MAGIC ##### Step 1 - Read the JSON file using the spark dataframe reader API

# COMMAND ----------

from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType

# COMMAND ----------

name_schema = StructType(fields=[StructField("forename", StringType(), True),
                                 StructField("surname", StringType(), True)
  
])

# COMMAND ----------

drivers_schema = StructType(fields=[StructField("driverId", IntegerType(), False),
                                    StructField("driverRef", StringType(), True),
                                    StructField("number", IntegerType(), True),
                                    StructField("code", StringType(), True),
                                    StructField("name", name_schema),
                                    StructField("dob", DateType(), True),
                                    StructField("nationality", StringType(), True),
                                    StructField("url", StringType(), True)  
])

# COMMAND ----------

drivers_df = spark.read \
.schema(drivers_schema) \
.json(f"{raw_folder_path}/drivers.json")

# COMMAND ----------

# MAGIC %md
# MAGIC ##### Step 2 - Rename columns and add new columns
# MAGIC 1. driverId renamed to driver_id  
# MAGIC 1. driverRef renamed to driver_ref  
# MAGIC 1. ingestion date added
# MAGIC 1. name added with concatenation of forename and surname

# COMMAND ----------

from pyspark.sql.functions import col, concat, lit

# COMMAND ----------

drivers_with_ingestion_date_df = add_ingestion_date(drivers_df)

# COMMAND ----------

drivers_with_columns_df = drivers_with_ingestion_date_df.withColumnRenamed("driverId", "driver_id") \
                                    .withColumnRenamed("driverRef", "driver_ref") \
                                    .withColumn("name", concat(col("name.forename"), lit(" "), col("name.surname"))) \
                                    .withColumn("data_source", lit(v_data_source))

# COMMAND ----------

# MAGIC %md
# MAGIC ##### Step 3 - Drop the unwanted columns
# MAGIC 1. name.forename
# MAGIC 1. name.surname
# MAGIC 1. url

# COMMAND ----------

drivers_final_df = drivers_with_columns_df.drop(col("url"))

# COMMAND ----------

# MAGIC %md
# MAGIC ##### Step 4 - Write to output to processed container in parquet format

# COMMAND ----------

drivers_final_df.write.mode("overwrite").format("parquet").saveAsTable("f1_processed.drivers")

# COMMAND ----------

dbutils.notebook.exit("Success")
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/4.ingest_drivers_file
# MAGIC %scala
# MAGIC import scala.util.parsing.json.JSON
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC import za.co.absa.spline.agent.AgentConfig
# MAGIC import za.co.absa.spline.harvester.postprocessing.AbstractPostProcessingFilter
# MAGIC import za.co.absa.spline.harvester.postprocessing.PostProcessingFilter
# MAGIC import org.apache.commons.configuration.Configuration
# MAGIC import za.co.absa.spline.harvester.conf.StandardSplineConfigurationStack
# MAGIC import za.co.absa.spline.harvester.HarvestingContext
# MAGIC import za.co.absa.spline.producer.model.ExecutionPlan
# MAGIC import za.co.absa.spline.producer.model.ExecutionEvent
# MAGIC import za.co.absa.spline.producer.model.ReadOperation
# MAGIC import za.co.absa.spline.producer.model.WriteOperation
# MAGIC import za.co.absa.spline.producer.model.DataOperation
# MAGIC import za.co.absa.spline.harvester.ExtraMetadataImplicits._
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC
# MAGIC val notebookInformationJson = dbutils.notebook.getContext.toJson
# MAGIC val outerMap = JSON.parseFull(notebookInformationJson).getOrElse(0).asInstanceOf[Map[String,String]]
# MAGIC val tagMap = outerMap("tags").asInstanceOf[Map[String,String]]
# MAGIC val extraContextMap = outerMap("extraContext").asInstanceOf[Map[String,String]]
# MAGIC val notebookPath = extraContextMap("notebook_path").split("/")
# MAGIC val workspaceUrl=tagMap("browserHostName")
# MAGIC
# MAGIC val workspaceName=dbutils.notebook().getContext().notebookPath.get
# MAGIC val notebookURL = tagMap("browserHostName")+"/?o="+tagMap("orgId")+tagMap("browserHash")
# MAGIC val user = tagMap("user")
# MAGIC val name = notebookPath(notebookPath.size-1)
# MAGIC val notebookInfo = Map("notebookURL" -> notebookURL,
# MAGIC "user" -> user,
# MAGIC "workspaceName" ->workspaceName,
# MAGIC "workspaceUrl" -> workspaceUrl,
# MAGIC "name" -> name,
# MAGIC "mounts" -> dbutils.fs.ls("/FileStore/tables").map(_.path),
# MAGIC "timestamp" -> System.currentTimeMillis)
# MAGIC val notebookInfoJson = scala.util.parsing.json.JSONObject(notebookInfo)
# MAGIC
# MAGIC
# MAGIC class CustomFilter extends PostProcessingFilter {
# MAGIC   def this(conf: Configuration) = this()
# MAGIC
# MAGIC   override def processExecutionEvent(event: ExecutionEvent, ctx: HarvestingContext): ExecutionEvent =
# MAGIC     event.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processExecutionPlan(plan: ExecutionPlan, ctx: HarvestingContext ): ExecutionPlan =
# MAGIC     plan.withAddedExtra(Map( "notebookInfo" -> notebookInfoJson))
# MAGIC
# MAGIC   override def processReadOperation(op: ReadOperation, ctx: HarvestingContext ): ReadOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processWriteOperation(op: WriteOperation, ctx: HarvestingContext): WriteOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processDataOperation(op: DataOperation, ctx: HarvestingContext  ): DataOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC }
# MAGIC
# MAGIC
# MAGIC
# MAGIC val myInstance = new CustomFilter()
# MAGIC
# MAGIC
# MAGIC spark.enableLineageTracking(
# MAGIC   AgentConfig.builder()
# MAGIC     .postProcessingFilter(myInstance)
# MAGIC     .build()
# MAGIC )

# COMMAND ----------

sc._jvm.za.co.absa.spline.harvester.SparkLineageInitializer.enableLineageTracking(spark._jsparkSession)

# COMMAND ----------



# COMMAND ----------

# MAGIC %scala
# MAGIC import scala.util.parsing.json.JSON
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC import za.co.absa.spline.agent.AgentConfig
# MAGIC import za.co.absa.spline.harvester.postprocessing.AbstractPostProcessingFilter
# MAGIC import za.co.absa.spline.harvester.postprocessing.PostProcessingFilter
# MAGIC import org.apache.commons.configuration.Configuration
# MAGIC import za.co.absa.spline.harvester.conf.StandardSplineConfigurationStack
# MAGIC import za.co.absa.spline.harvester.HarvestingContext
# MAGIC import za.co.absa.spline.producer.model.ExecutionPlan
# MAGIC import za.co.absa.spline.producer.model.ExecutionEvent
# MAGIC import za.co.absa.spline.producer.model.ReadOperation
# MAGIC import za.co.absa.spline.producer.model.WriteOperation
# MAGIC import za.co.absa.spline.producer.model.DataOperation
# MAGIC import za.co.absa.spline.harvester.ExtraMetadataImplicits._
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC
# MAGIC val notebookInformationJson = dbutils.notebook.getContext.toJson
# MAGIC val outerMap = JSON.parseFull(notebookInformationJson).getOrElse(0).asInstanceOf[Map[String,String]]
# MAGIC val tagMap = outerMap("tags").asInstanceOf[Map[String,String]]
# MAGIC val extraContextMap = outerMap("extraContext").asInstanceOf[Map[String,String]]
# MAGIC val notebookPath = extraContextMap("notebook_path").split("/")
# MAGIC val workspaceUrl=tagMap("browserHostName")
# MAGIC
# MAGIC val workspaceName=dbutils.notebook().getContext().notebookPath.get
# MAGIC val notebookURL = tagMap("browserHostName")+"/?o="+tagMap("orgId")+tagMap("browserHash")
# MAGIC val user = tagMap("user")
# MAGIC val name = notebookPath(notebookPath.size-1)
# MAGIC val notebookInfo = Map("notebookURL" -> notebookURL,
# MAGIC "user" -> user,
# MAGIC "workspaceName" ->workspaceName,
# MAGIC "workspaceUrl" -> workspaceUrl,
# MAGIC "name" -> name,
# MAGIC "mounts" -> dbutils.fs.ls("/FileStore/tables").map(_.path),
# MAGIC "timestamp" -> System.currentTimeMillis)
# MAGIC val notebookInfoJson = scala.util.parsing.json.JSONObject(notebookInfo)
# MAGIC
# MAGIC
# MAGIC class CustomFilter extends PostProcessingFilter {
# MAGIC   def this(conf: Configuration) = this()
# MAGIC
# MAGIC   override def processExecutionEvent(event: ExecutionEvent, ctx: HarvestingContext): ExecutionEvent =
# MAGIC     event.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processExecutionPlan(plan: ExecutionPlan, ctx: HarvestingContext ): ExecutionPlan =
# MAGIC     plan.withAddedExtra(Map( "notebookInfo" -> notebookInfoJson))
# MAGIC
# MAGIC   override def processReadOperation(op: ReadOperation, ctx: HarvestingContext ): ReadOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processWriteOperation(op: WriteOperation, ctx: HarvestingContext): WriteOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processDataOperation(op: DataOperation, ctx: HarvestingContext  ): DataOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC }
# MAGIC
# MAGIC
# MAGIC
# MAGIC val myInstance = new CustomFilter()
# MAGIC
# MAGIC
# MAGIC spark.enableLineageTracking(
# MAGIC   AgentConfig.builder()
# MAGIC     .postProcessingFilter(myInstance)
# MAGIC     .build()
# MAGIC )

# COMMAND ----------

# MAGIC %md
# MAGIC ### Ingest circuits.csv file

# COMMAND ----------

dbutils.widgets.text("p_data_source", "")
v_data_source = dbutils.widgets.get("p_data_source")

# COMMAND ----------

# MAGIC %run "../includes/configuration"

# COMMAND ----------

# MAGIC %run "../includes/common_functions"

# COMMAND ----------

# MAGIC %md
# MAGIC ##### Step 1 - Read the CSV file using the spark dataframe reader

# COMMAND ----------

from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType

# COMMAND ----------

circuits_schema = StructType(fields=[StructField("circuitId", IntegerType(), False),
                                     StructField("circuitRef", StringType(), True),
                                     StructField("name", StringType(), True),
                                     StructField("location", StringType(), True),
                                     StructField("country", StringType(), True),
                                     StructField("lat", DoubleType(), True),
                                     StructField("lng", DoubleType(), True),
                                     StructField("alt", IntegerType(), True),
                                     StructField("url", StringType(), True)
])

# COMMAND ----------

circuits_df = spark.read \
.option("header", True) \
.schema(circuits_schema) \
.csv(f"{raw_folder_path}/circuits.csv")

# COMMAND ----------

# MAGIC %md
# MAGIC ##### Step 2 - Select only the required columns

# COMMAND ----------

from pyspark.sql.functions import col

# COMMAND ----------

circuits_selected_df = circuits_df.select(col("circuitId"), col("circuitRef"), col("name"), col("location"), col("country"), col("lat"), col("lng"), col("alt"))

# COMMAND ----------

# MAGIC %md
# MAGIC ##### Step 3 - Rename the columns as required

# COMMAND ----------

from pyspark.sql.functions import lit

# COMMAND ----------

circuits_renamed_df = circuits_selected_df.withColumnRenamed("circuitId", "circuit_id") \
.withColumnRenamed("circuitRef", "circuit_ref") \
.withColumnRenamed("lat", "latitude") \
.withColumnRenamed("lng", "longitude") \
.withColumnRenamed("alt", "altitude") \
.withColumn("data_source", lit(v_data_source))

# COMMAND ----------

# MAGIC %md 
# MAGIC ##### Step 4 - Add ingestion date to the dataframe

# COMMAND ----------

circuits_final_df = add_ingestion_date(circuits_renamed_df)

# COMMAND ----------

# MAGIC %md
# MAGIC ##### Step 5 - Write data to datalake as parquet

# COMMAND ----------

circuits_final_df.write.mode("overwrite").format("parquet").saveAsTable("f1_processed.circuits")

# COMMAND ----------

display(spark.read.parquet(f"{processed_folder_path}/circuits"))

# COMMAND ----------

# MAGIC %sql
# MAGIC SELECT * FROM f1_processed.circuits;

# COMMAND ----------

dbutils.notebook.exit("Success")
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/1.ingest_circuits_file
# MAGIC %scala
# MAGIC import scala.util.parsing.json.JSON
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC import za.co.absa.spline.agent.AgentConfig
# MAGIC import za.co.absa.spline.harvester.postprocessing.AbstractPostProcessingFilter
# MAGIC import za.co.absa.spline.harvester.postprocessing.PostProcessingFilter
# MAGIC import org.apache.commons.configuration.Configuration
# MAGIC import za.co.absa.spline.harvester.conf.StandardSplineConfigurationStack
# MAGIC import za.co.absa.spline.harvester.HarvestingContext
# MAGIC import za.co.absa.spline.producer.model.ExecutionPlan
# MAGIC import za.co.absa.spline.producer.model.ExecutionEvent
# MAGIC import za.co.absa.spline.producer.model.ReadOperation
# MAGIC import za.co.absa.spline.producer.model.WriteOperation
# MAGIC import za.co.absa.spline.producer.model.DataOperation
# MAGIC import za.co.absa.spline.harvester.ExtraMetadataImplicits._
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC
# MAGIC val notebookInformationJson = dbutils.notebook.getContext.toJson
# MAGIC val outerMap = JSON.parseFull(notebookInformationJson).getOrElse(0).asInstanceOf[Map[String,String]]
# MAGIC val tagMap = outerMap("tags").asInstanceOf[Map[String,String]]
# MAGIC val extraContextMap = outerMap("extraContext").asInstanceOf[Map[String,String]]
# MAGIC val notebookPath = extraContextMap("notebook_path").split("/")
# MAGIC val workspaceUrl=tagMap("browserHostName")
# MAGIC
# MAGIC val workspaceName=dbutils.notebook().getContext().notebookPath.get
# MAGIC val notebookURL = tagMap("browserHostName")+"/?o="+tagMap("orgId")+tagMap("browserHash")
# MAGIC val user = tagMap("user")
# MAGIC val name = notebookPath(notebookPath.size-1)
# MAGIC val notebookInfo = Map("notebookURL" -> notebookURL,
# MAGIC "user" -> user,
# MAGIC "workspaceName" ->workspaceName,
# MAGIC "workspaceUrl" -> workspaceUrl,
# MAGIC "name" -> name,
# MAGIC "mounts" -> dbutils.fs.ls("/FileStore/tables").map(_.path),
# MAGIC "timestamp" -> System.currentTimeMillis)
# MAGIC val notebookInfoJson = scala.util.parsing.json.JSONObject(notebookInfo)
# MAGIC
# MAGIC
# MAGIC class CustomFilter extends PostProcessingFilter {
# MAGIC   def this(conf: Configuration) = this()
# MAGIC
# MAGIC   override def processExecutionEvent(event: ExecutionEvent, ctx: HarvestingContext): ExecutionEvent =
# MAGIC     event.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processExecutionPlan(plan: ExecutionPlan, ctx: HarvestingContext ): ExecutionPlan =
# MAGIC     plan.withAddedExtra(Map( "notebookInfo" -> notebookInfoJson))
# MAGIC
# MAGIC   override def processReadOperation(op: ReadOperation, ctx: HarvestingContext ): ReadOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processWriteOperation(op: WriteOperation, ctx: HarvestingContext): WriteOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processDataOperation(op: DataOperation, ctx: HarvestingContext  ): DataOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC }
# MAGIC
# MAGIC
# MAGIC
# MAGIC val myInstance = new CustomFilter()
# MAGIC
# MAGIC
# MAGIC spark.enableLineageTracking(
# MAGIC   AgentConfig.builder()
# MAGIC     .postProcessingFilter(myInstance)
# MAGIC     .build()
# MAGIC )

# COMMAND ----------

sc._jvm.za.co.absa.spline.harvester.SparkLineageInitializer.enableLineageTracking(spark._jsparkSession)

# COMMAND ----------

# MAGIC %scala
# MAGIC import scala.util.parsing.json.JSON
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC import za.co.absa.spline.agent.AgentConfig
# MAGIC import za.co.absa.spline.harvester.postprocessing.AbstractPostProcessingFilter
# MAGIC import za.co.absa.spline.harvester.postprocessing.PostProcessingFilter
# MAGIC import org.apache.commons.configuration.Configuration
# MAGIC import za.co.absa.spline.harvester.conf.StandardSplineConfigurationStack
# MAGIC import za.co.absa.spline.harvester.HarvestingContext
# MAGIC import za.co.absa.spline.producer.model.ExecutionPlan
# MAGIC import za.co.absa.spline.producer.model.ExecutionEvent
# MAGIC import za.co.absa.spline.producer.model.ReadOperation
# MAGIC import za.co.absa.spline.producer.model.WriteOperation
# MAGIC import za.co.absa.spline.producer.model.DataOperation
# MAGIC import za.co.absa.spline.harvester.ExtraMetadataImplicits._
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC
# MAGIC val notebookInformationJson = dbutils.notebook.getContext.toJson
# MAGIC val outerMap = JSON.parseFull(notebookInformationJson).getOrElse(0).asInstanceOf[Map[String,String]]
# MAGIC val tagMap = outerMap("tags").asInstanceOf[Map[String,String]]
# MAGIC val extraContextMap = outerMap("extraContext").asInstanceOf[Map[String,String]]
# MAGIC val notebookPath = extraContextMap("notebook_path").split("/")
# MAGIC val workspaceUrl=tagMap("browserHostName")
# MAGIC
# MAGIC val workspaceName=dbutils.notebook().getContext().notebookPath.get
# MAGIC val notebookURL = tagMap("browserHostName")+"/?o="+tagMap("orgId")+tagMap("browserHash")
# MAGIC val user = tagMap("user")
# MAGIC val name = notebookPath(notebookPath.size-1)
# MAGIC val notebookInfo = Map("notebookURL" -> notebookURL,
# MAGIC "user" -> user,
# MAGIC "workspaceName" ->workspaceName,
# MAGIC "workspaceUrl" -> workspaceUrl,
# MAGIC "name" -> name,
# MAGIC "mounts" -> dbutils.fs.ls("/FileStore/tables").map(_.path),
# MAGIC "timestamp" -> System.currentTimeMillis)
# MAGIC val notebookInfoJson = scala.util.parsing.json.JSONObject(notebookInfo)
# MAGIC
# MAGIC
# MAGIC class CustomFilter extends PostProcessingFilter {
# MAGIC   def this(conf: Configuration) = this()
# MAGIC
# MAGIC   override def processExecutionEvent(event: ExecutionEvent, ctx: HarvestingContext): ExecutionEvent =
# MAGIC     event.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processExecutionPlan(plan: ExecutionPlan, ctx: HarvestingContext ): ExecutionPlan =
# MAGIC     plan.withAddedExtra(Map( "notebookInfo" -> notebookInfoJson))
# MAGIC
# MAGIC   override def processReadOperation(op: ReadOperation, ctx: HarvestingContext ): ReadOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processWriteOperation(op: WriteOperation, ctx: HarvestingContext): WriteOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processDataOperation(op: DataOperation, ctx: HarvestingContext  ): DataOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC }
# MAGIC
# MAGIC
# MAGIC
# MAGIC val myInstance = new CustomFilter()
# MAGIC
# MAGIC
# MAGIC spark.enableLineageTracking(
# MAGIC   AgentConfig.builder()
# MAGIC     .postProcessingFilter(myInstance)
# MAGIC     .build()
# MAGIC )

# COMMAND ----------



# COMMAND ----------



# COMMAND ----------

# MAGIC %scala
# MAGIC import scala.util.parsing.json.JSON
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC import za.co.absa.spline.agent.AgentConfig
# MAGIC import za.co.absa.spline.harvester.postprocessing.AbstractPostProcessingFilter
# MAGIC import za.co.absa.spline.harvester.postprocessing.PostProcessingFilter
# MAGIC import org.apache.commons.configuration.Configuration
# MAGIC import za.co.absa.spline.harvester.conf.StandardSplineConfigurationStack
# MAGIC import za.co.absa.spline.harvester.HarvestingContext
# MAGIC import za.co.absa.spline.producer.model.ExecutionPlan
# MAGIC import za.co.absa.spline.producer.model.ExecutionEvent
# MAGIC import za.co.absa.spline.producer.model.ReadOperation
# MAGIC import za.co.absa.spline.producer.model.WriteOperation
# MAGIC import za.co.absa.spline.producer.model.DataOperation
# MAGIC import za.co.absa.spline.harvester.ExtraMetadataImplicits._
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC
# MAGIC val notebookInformationJson = dbutils.notebook.getContext.toJson
# MAGIC val outerMap = JSON.parseFull(notebookInformationJson).getOrElse(0).asInstanceOf[Map[String,String]]
# MAGIC val tagMap = outerMap("tags").asInstanceOf[Map[String,String]]
# MAGIC val extraContextMap = outerMap("extraContext").asInstanceOf[Map[String,String]]
# MAGIC val notebookPath = extraContextMap("notebook_path").split("/")
# MAGIC val workspaceUrl=tagMap("browserHostName")
# MAGIC
# MAGIC val workspaceName=dbutils.notebook().getContext().notebookPath.get
# MAGIC val notebookURL = tagMap("browserHostName")+"/?o="+tagMap("orgId")+tagMap("browserHash")
# MAGIC val user = tagMap("user")
# MAGIC val name = notebookPath(notebookPath.size-1)
# MAGIC val notebookInfo = Map("notebookURL" -> notebookURL,
# MAGIC "user" -> user,
# MAGIC "workspaceName" ->workspaceName,
# MAGIC "workspaceUrl" -> workspaceUrl,
# MAGIC "name" -> name,
# MAGIC "mounts" -> dbutils.fs.ls("/FileStore/tables").map(_.path),
# MAGIC "timestamp" -> System.currentTimeMillis)
# MAGIC val notebookInfoJson = scala.util.parsing.json.JSONObject(notebookInfo)
# MAGIC
# MAGIC
# MAGIC class CustomFilter extends PostProcessingFilter {
# MAGIC   def this(conf: Configuration) = this()
# MAGIC
# MAGIC   override def processExecutionEvent(event: ExecutionEvent, ctx: HarvestingContext): ExecutionEvent =
# MAGIC     event.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processExecutionPlan(plan: ExecutionPlan, ctx: HarvestingContext ): ExecutionPlan =
# MAGIC     plan.withAddedExtra(Map( "notebookInfo" -> notebookInfoJson))
# MAGIC
# MAGIC   override def processReadOperation(op: ReadOperation, ctx: HarvestingContext ): ReadOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processWriteOperation(op: WriteOperation, ctx: HarvestingContext): WriteOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processDataOperation(op: DataOperation, ctx: HarvestingContext  ): DataOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC }
# MAGIC
# MAGIC
# MAGIC
# MAGIC val myInstance = new CustomFilter()
# MAGIC
# MAGIC
# MAGIC spark.enableLineageTracking(
# MAGIC   AgentConfig.builder()
# MAGIC     .postProcessingFilter(myInstance)
# MAGIC     .build()
# MAGIC )

# COMMAND ----------

# MAGIC %md
# MAGIC ### Ingest races.csv file

# COMMAND ----------

dbutils.widgets.text("p_data_source", "")
v_data_source = dbutils.widgets.get("p_data_source")

# COMMAND ----------

# MAGIC %run "../includes/configuration"

# COMMAND ----------

# MAGIC %run "../includes/common_functions"

# COMMAND ----------

# MAGIC %md
# MAGIC ##### Step 1 - Read the CSV file using the spark dataframe reader API

# COMMAND ----------

from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType

# COMMAND ----------

races_schema = StructType(fields=[StructField("raceId", IntegerType(), False),
                                  StructField("year", IntegerType(), True),
                                  StructField("round", IntegerType(), True),
                                  StructField("circuitId", IntegerType(), True),
                                  StructField("name", StringType(), True),
                                  StructField("date", DateType(), True),
                                  StructField("time", StringType(), True),
                                  StructField("url", StringType(), True) 
])

# COMMAND ----------

races_df = spark.read \
.option("header", True) \
.schema(races_schema) \
.csv(f"{raw_folder_path}/races.csv")

# COMMAND ----------

# MAGIC %md
# MAGIC ##### Step 2 - Add ingestion date and race_timestamp to the dataframe

# COMMAND ----------

from pyspark.sql.functions import to_timestamp, concat, col, lit

# COMMAND ----------

races_with_timestamp_df = races_df.withColumn("race_timestamp", to_timestamp(concat(col('date'), lit(' '), col('time')), 'yyyy-MM-dd HH:mm:ss')) \
.withColumn("data_source", lit(v_data_source))

# COMMAND ----------

races_with_ingestion_date_df = add_ingestion_date(races_with_timestamp_df)

# COMMAND ----------

# MAGIC %md
# MAGIC ##### Step 3 - Select only the columns required & rename as required

# COMMAND ----------

races_selected_df = races_with_ingestion_date_df.select(col('raceId').alias('race_id'), col('year').alias('race_year'), 
                                                   col('round'), col('circuitId').alias('circuit_id'),col('name'), col('ingestion_date'), col('race_timestamp'))

# COMMAND ----------

# MAGIC %md
# MAGIC ##### Write the output to processed container in parquet format

# COMMAND ----------

races_selected_df.write.mode("overwrite").partitionBy('race_year').format("parquet").saveAsTable("f1_processed.races")

# COMMAND ----------

dbutils.notebook.exit("Success")
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/2.ingest_races_file
sc._jvm.za.co.absa.spline.harvester.SparkLineageInitializer.enableLineageTracking(spark._jsparkSession)

# COMMAND ----------

# MAGIC %scala
# MAGIC import scala.util.parsing.json.JSON
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC import za.co.absa.spline.agent.AgentConfig
# MAGIC import za.co.absa.spline.harvester.postprocessing.AbstractPostProcessingFilter
# MAGIC import za.co.absa.spline.harvester.postprocessing.PostProcessingFilter
# MAGIC import org.apache.commons.configuration.Configuration
# MAGIC import za.co.absa.spline.harvester.conf.StandardSplineConfigurationStack
# MAGIC import za.co.absa.spline.harvester.HarvestingContext
# MAGIC import za.co.absa.spline.producer.model.ExecutionPlan
# MAGIC import za.co.absa.spline.producer.model.ExecutionEvent
# MAGIC import za.co.absa.spline.producer.model.ReadOperation
# MAGIC import za.co.absa.spline.producer.model.WriteOperation
# MAGIC import za.co.absa.spline.producer.model.DataOperation
# MAGIC import za.co.absa.spline.harvester.ExtraMetadataImplicits._
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC
# MAGIC val notebookInformationJson = dbutils.notebook.getContext.toJson
# MAGIC val outerMap = JSON.parseFull(notebookInformationJson).getOrElse(0).asInstanceOf[Map[String,String]]
# MAGIC val tagMap = outerMap("tags").asInstanceOf[Map[String,String]]
# MAGIC val extraContextMap = outerMap("extraContext").asInstanceOf[Map[String,String]]
# MAGIC val notebookPath = extraContextMap("notebook_path").split("/")
# MAGIC val workspaceUrl=tagMap("browserHostName")
# MAGIC
# MAGIC val workspaceName=dbutils.notebook().getContext().notebookPath.get
# MAGIC val notebookURL = tagMap("browserHostName")+"/?o="+tagMap("orgId")+tagMap("browserHash")
# MAGIC val user = tagMap("user")
# MAGIC val name = notebookPath(notebookPath.size-1)
# MAGIC val notebookInfo = Map("notebookURL" -> notebookURL,
# MAGIC "user" -> user,
# MAGIC "workspaceName" ->workspaceName,
# MAGIC "workspaceUrl" -> workspaceUrl,
# MAGIC "name" -> name,
# MAGIC "mounts" -> dbutils.fs.ls("/FileStore/tables").map(_.path),
# MAGIC "timestamp" -> System.currentTimeMillis)
# MAGIC val notebookInfoJson = scala.util.parsing.json.JSONObject(notebookInfo)
# MAGIC
# MAGIC
# MAGIC class CustomFilter extends PostProcessingFilter {
# MAGIC   def this(conf: Configuration) = this()
# MAGIC
# MAGIC   override def processExecutionEvent(event: ExecutionEvent, ctx: HarvestingContext): ExecutionEvent =
# MAGIC     event.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processExecutionPlan(plan: ExecutionPlan, ctx: HarvestingContext ): ExecutionPlan =
# MAGIC     plan.withAddedExtra(Map( "notebookInfo" -> notebookInfoJson))
# MAGIC
# MAGIC   override def processReadOperation(op: ReadOperation, ctx: HarvestingContext ): ReadOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processWriteOperation(op: WriteOperation, ctx: HarvestingContext): WriteOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processDataOperation(op: DataOperation, ctx: HarvestingContext  ): DataOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC }
# MAGIC
# MAGIC
# MAGIC
# MAGIC val myInstance = new CustomFilter()
# MAGIC
# MAGIC
# MAGIC spark.enableLineageTracking(
# MAGIC   AgentConfig.builder()
# MAGIC     .postProcessingFilter(myInstance)
# MAGIC     .build()
# MAGIC )

# COMMAND ----------

# MAGIC %md
# MAGIC ### Ingest constructors.json file

# COMMAND ----------

dbutils.widgets.text("p_data_source", "")
v_data_source = dbutils.widgets.get("p_data_source")

# COMMAND ----------

# MAGIC %run "../includes/configuration"

# COMMAND ----------

# MAGIC %run "../includes/common_functions"

# COMMAND ----------

# MAGIC %md
# MAGIC ##### Step 1 - Read the JSON file using the spark dataframe reader

# COMMAND ----------

constructors_schema = "constructorId INT, constructorRef STRING, name STRING, nationality STRING, url STRING"

# COMMAND ----------

constructor_df = spark.read \
.schema(constructors_schema) \
.json(f"{raw_folder_path}/constructors.json")

# COMMAND ----------

# MAGIC %md
# MAGIC ##### Step 2 - Drop unwanted columns from the dataframe

# COMMAND ----------

from pyspark.sql.functions import col

# COMMAND ----------

constructor_dropped_df = constructor_df.drop(col('url'))

# COMMAND ----------

# MAGIC %md
# MAGIC ##### Step 3 - Rename columns and add ingestion date

# COMMAND ----------

from pyspark.sql.functions import lit

# COMMAND ----------

constructor_renamed_df = constructor_dropped_df.withColumnRenamed("constructorId", "constructor_id") \
                                             .withColumnRenamed("constructorRef", "constructor_ref") \
                                             .withColumn("data_source", lit(v_data_source))

# COMMAND ----------

constructor_final_df = add_ingestion_date(constructor_renamed_df)

# COMMAND ----------

# MAGIC %md
# MAGIC ##### Step 4 Write output to parquet file

# COMMAND ----------

constructor_final_df.write.mode("overwrite").format("parquet").saveAsTable("f1_processed.constructors")

# COMMAND ----------

dbutils.notebook.exit("Success")
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/3.ingest_constructors_file
sc._jvm.za.co.absa.spline.harvester.SparkLineageInitializer.enableLineageTracking(spark._jsparkSession)

# COMMAND ----------

# MAGIC %scala
# MAGIC import scala.util.parsing.json.JSON
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC import za.co.absa.spline.agent.AgentConfig
# MAGIC import za.co.absa.spline.harvester.postprocessing.AbstractPostProcessingFilter
# MAGIC import za.co.absa.spline.harvester.postprocessing.PostProcessingFilter
# MAGIC import org.apache.commons.configuration.Configuration
# MAGIC import za.co.absa.spline.harvester.conf.StandardSplineConfigurationStack
# MAGIC import za.co.absa.spline.harvester.HarvestingContext
# MAGIC import za.co.absa.spline.producer.model.ExecutionPlan
# MAGIC import za.co.absa.spline.producer.model.ExecutionEvent
# MAGIC import za.co.absa.spline.producer.model.ReadOperation
# MAGIC import za.co.absa.spline.producer.model.WriteOperation
# MAGIC import za.co.absa.spline.producer.model.DataOperation
# MAGIC import za.co.absa.spline.harvester.ExtraMetadataImplicits._
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC
# MAGIC val notebookInformationJson = dbutils.notebook.getContext.toJson
# MAGIC val outerMap = JSON.parseFull(notebookInformationJson).getOrElse(0).asInstanceOf[Map[String,String]]
# MAGIC val tagMap = outerMap("tags").asInstanceOf[Map[String,String]]
# MAGIC val extraContextMap = outerMap("extraContext").asInstanceOf[Map[String,String]]
# MAGIC val notebookPath = extraContextMap("notebook_path").split("/")
# MAGIC val workspaceUrl=tagMap("browserHostName")
# MAGIC
# MAGIC val workspaceName=dbutils.notebook().getContext().notebookPath.get
# MAGIC val notebookURL = tagMap("browserHostName")+"/?o="+tagMap("orgId")+tagMap("browserHash")
# MAGIC val user = tagMap("user")
# MAGIC val name = notebookPath(notebookPath.size-1)
# MAGIC val notebookInfo = Map("notebookURL" -> notebookURL,
# MAGIC "user" -> user,
# MAGIC "workspaceName" ->workspaceName,
# MAGIC "workspaceUrl" -> workspaceUrl,
# MAGIC "name" -> name,
# MAGIC "mounts" -> dbutils.fs.ls("/FileStore/tables").map(_.path),
# MAGIC "timestamp" -> System.currentTimeMillis)
# MAGIC val notebookInfoJson = scala.util.parsing.json.JSONObject(notebookInfo)
# MAGIC
# MAGIC
# MAGIC class CustomFilter extends PostProcessingFilter {
# MAGIC   def this(conf: Configuration) = this()
# MAGIC
# MAGIC   override def processExecutionEvent(event: ExecutionEvent, ctx: HarvestingContext): ExecutionEvent =
# MAGIC     event.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processExecutionPlan(plan: ExecutionPlan, ctx: HarvestingContext ): ExecutionPlan =
# MAGIC     plan.withAddedExtra(Map( "notebookInfo" -> notebookInfoJson))
# MAGIC
# MAGIC   override def processReadOperation(op: ReadOperation, ctx: HarvestingContext ): ReadOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processWriteOperation(op: WriteOperation, ctx: HarvestingContext): WriteOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processDataOperation(op: DataOperation, ctx: HarvestingContext  ): DataOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC }
# MAGIC
# MAGIC
# MAGIC
# MAGIC val myInstance = new CustomFilter()
# MAGIC
# MAGIC
# MAGIC spark.enableLineageTracking(
# MAGIC   AgentConfig.builder()
# MAGIC     .postProcessingFilter(myInstance)
# MAGIC     .build()
# MAGIC )

# COMMAND ----------

# MAGIC %md
# MAGIC ### Ingest results.json file

# COMMAND ----------

dbutils.widgets.text("p_data_source", "")
v_data_source = dbutils.widgets.get("p_data_source")

# COMMAND ----------

# MAGIC %run "../includes/configuration"

# COMMAND ----------

# MAGIC %run "../includes/common_functions"

# COMMAND ----------

# MAGIC %md
# MAGIC ##### Step 1 - Read the JSON file using the spark dataframe reader API

# COMMAND ----------

from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType

# COMMAND ----------

results_schema = StructType(fields=[StructField("resultId", IntegerType(), False),
                                    StructField("raceId", IntegerType(), True),
                                    StructField("driverId", IntegerType(), True),
                                    StructField("constructorId", IntegerType(), True),
                                    StructField("number", IntegerType(), True),
                                    StructField("grid", IntegerType(), True),
                                    StructField("position", IntegerType(), True),
                                    StructField("positionText", StringType(), True),
                                    StructField("positionOrder", IntegerType(), True),
                                    StructField("points", FloatType(), True),
                                    StructField("laps", IntegerType(), True),
                                    StructField("time", StringType(), True),
                                    StructField("milliseconds", IntegerType(), True),
                                    StructField("fastestLap", IntegerType(), True),
                                    StructField("rank", IntegerType(), True),
                                    StructField("fastestLapTime", StringType(), True),
                                    StructField("fastestLapSpeed", FloatType(), True),
                                    StructField("statusId", StringType(), True)])

# COMMAND ----------

results_df = spark.read \
.schema(results_schema) \
.json(f"{raw_folder_path}/results.json")

# COMMAND ----------

# MAGIC %md
# MAGIC ##### Step 2 - Rename columns and add new columns

# COMMAND ----------

from pyspark.sql.functions import lit

# COMMAND ----------

results_with_columns_df = results_df.withColumnRenamed("resultId", "result_id") \
                                    .withColumnRenamed("raceId", "race_id") \
                                    .withColumnRenamed("driverId", "driver_id") \
                                    .withColumnRenamed("constructorId", "constructor_id") \
                                    .withColumnRenamed("positionText", "position_text") \
                                    .withColumnRenamed("positionOrder", "position_order") \
                                    .withColumnRenamed("fastestLap", "fastest_lap") \
                                    .withColumnRenamed("fastestLapTime", "fastest_lap_time") \
                                    .withColumnRenamed("fastestLapSpeed", "fastest_lap_speed") \
                                    .withColumn("data_source", lit(v_data_source))

# COMMAND ----------

results_with_ingestion_date_df = add_ingestion_date(results_with_columns_df)

# COMMAND ----------

# MAGIC %md
# MAGIC ##### Step 3 - Drop the unwanted column

# COMMAND ----------

from pyspark.sql.functions import col

# COMMAND ----------

results_final_df = results_with_ingestion_date_df.drop(col("statusId"))

# COMMAND ----------

# MAGIC %md
# MAGIC ##### Step 4 - Write to output to processed container in parquet format

# COMMAND ----------

results_final_df.write.mode("overwrite").partitionBy('race_id').format("parquet").saveAsTable("f1_processed.results")

# COMMAND ----------

dbutils.notebook.exit("Success")
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/5.ingest_results_file
-- MAGIC %scala
-- MAGIC import scala.util.parsing.json.JSON
-- MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
-- MAGIC import za.co.absa.spline.agent.AgentConfig
-- MAGIC import za.co.absa.spline.harvester.postprocessing.AbstractPostProcessingFilter
-- MAGIC import za.co.absa.spline.harvester.postprocessing.PostProcessingFilter
-- MAGIC import org.apache.commons.configuration.Configuration
-- MAGIC import za.co.absa.spline.harvester.conf.StandardSplineConfigurationStack
-- MAGIC import za.co.absa.spline.harvester.HarvestingContext
-- MAGIC import za.co.absa.spline.producer.model.ExecutionPlan
-- MAGIC import za.co.absa.spline.producer.model.ExecutionEvent
-- MAGIC import za.co.absa.spline.producer.model.ReadOperation
-- MAGIC import za.co.absa.spline.producer.model.WriteOperation
-- MAGIC import za.co.absa.spline.producer.model.DataOperation
-- MAGIC import za.co.absa.spline.harvester.ExtraMetadataImplicits._
-- MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
-- MAGIC
-- MAGIC val notebookInformationJson = dbutils.notebook.getContext.toJson
-- MAGIC val outerMap = JSON.parseFull(notebookInformationJson).getOrElse(0).asInstanceOf[Map[String,String]]
-- MAGIC val tagMap = outerMap("tags").asInstanceOf[Map[String,String]]
-- MAGIC val extraContextMap = outerMap("extraContext").asInstanceOf[Map[String,String]]
-- MAGIC val notebookPath = extraContextMap("notebook_path").split("/")
-- MAGIC val workspaceUrl=tagMap("browserHostName")
-- MAGIC
-- MAGIC val workspaceName=dbutils.notebook().getContext().notebookPath.get
-- MAGIC val notebookURL = tagMap("browserHostName")+"/?o="+tagMap("orgId")+tagMap("browserHash")
-- MAGIC val user = tagMap("user")
-- MAGIC val name = notebookPath(notebookPath.size-1)
-- MAGIC val notebookInfo = Map("notebookURL" -> notebookURL,
-- MAGIC "user" -> user,
-- MAGIC "workspaceName" ->workspaceName,
-- MAGIC "workspaceUrl" -> workspaceUrl,
-- MAGIC "name" -> name,
-- MAGIC "mounts" -> dbutils.fs.ls("/FileStore/tables").map(_.path),
-- MAGIC "timestamp" -> System.currentTimeMillis)
-- MAGIC val notebookInfoJson = scala.util.parsing.json.JSONObject(notebookInfo)
-- MAGIC
-- MAGIC
-- MAGIC class CustomFilter extends PostProcessingFilter {
-- MAGIC   def this(conf: Configuration) = this()
-- MAGIC
-- MAGIC   override def processExecutionEvent(event: ExecutionEvent, ctx: HarvestingContext): ExecutionEvent =
-- MAGIC     event.withAddedExtra(Map("foo" -> "bar"))
-- MAGIC
-- MAGIC   override def processExecutionPlan(plan: ExecutionPlan, ctx: HarvestingContext ): ExecutionPlan =
-- MAGIC     plan.withAddedExtra(Map( "notebookInfo" -> notebookInfoJson))
-- MAGIC
-- MAGIC   override def processReadOperation(op: ReadOperation, ctx: HarvestingContext ): ReadOperation =
-- MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
-- MAGIC
-- MAGIC   override def processWriteOperation(op: WriteOperation, ctx: HarvestingContext): WriteOperation =
-- MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
-- MAGIC
-- MAGIC   override def processDataOperation(op: DataOperation, ctx: HarvestingContext  ): DataOperation =
-- MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
-- MAGIC }
-- MAGIC
-- MAGIC
-- MAGIC
-- MAGIC val myInstance = new CustomFilter()
-- MAGIC
-- MAGIC
-- MAGIC spark.enableLineageTracking(
-- MAGIC   AgentConfig.builder()
-- MAGIC     .postProcessingFilter(myInstance)
-- MAGIC     .build()
-- MAGIC )

-- COMMAND ----------

'-- Databricks notebook source
%python
sc._jvm.za.co.absa.spline.harvester.SparkLineageInitializer.enableLineageTracking(spark._jsparkSession)

-- COMMAND ----------

-- MAGIC %scala
-- MAGIC import scala.util.parsing.json.JSON
-- MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
-- MAGIC import za.co.absa.spline.agent.AgentConfig
-- MAGIC import za.co.absa.spline.harvester.postprocessing.AbstractPostProcessingFilter
-- MAGIC import za.co.absa.spline.harvester.postprocessing.PostProcessingFilter
-- MAGIC import org.apache.commons.configuration.Configuration
-- MAGIC import za.co.absa.spline.harvester.conf.StandardSplineConfigurationStack
-- MAGIC import za.co.absa.spline.harvester.HarvestingContext
-- MAGIC import za.co.absa.spline.producer.model.ExecutionPlan
-- MAGIC import za.co.absa.spline.producer.model.ExecutionEvent
-- MAGIC import za.co.absa.spline.producer.model.ReadOperation
-- MAGIC import za.co.absa.spline.producer.model.WriteOperation
-- MAGIC import za.co.absa.spline.producer.model.DataOperation
-- MAGIC import za.co.absa.spline.harvester.ExtraMetadataImplicits._
-- MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
-- MAGIC
-- MAGIC val notebookInformationJson = dbutils.notebook.getContext.toJson
-- MAGIC val outerMap = JSON.parseFull(notebookInformationJson).getOrElse(0).asInstanceOf[Map[String,String]]
-- MAGIC val tagMap = outerMap("tags").asInstanceOf[Map[String,String]]
-- MAGIC val extraContextMap = outerMap("extraContext").asInstanceOf[Map[String,String]]
-- MAGIC val notebookPath = extraContextMap("notebook_path").split("/")
-- MAGIC val workspaceUrl=tagMap("browserHostName")
-- MAGIC
-- MAGIC val workspaceName=dbutils.notebook().getContext().notebookPath.get
-- MAGIC val notebookURL = tagMap("browserHostName")+"/?o="+tagMap("orgId")+tagMap("browserHash")
-- MAGIC val user = tagMap("user")
-- MAGIC val name = notebookPath(notebookPath.size-1)
-- MAGIC val notebookInfo = Map("notebookURL" -> notebookURL,
-- MAGIC "user" -> user,
-- MAGIC "workspaceName" ->workspaceName,
-- MAGIC "workspaceUrl" -> workspaceUrl,
-- MAGIC "name" -> name,
-- MAGIC "mounts" -> dbutils.fs.ls("/FileStore/tables").map(_.path),
-- MAGIC "timestamp" -> System.currentTimeMillis)
-- MAGIC val notebookInfoJson = scala.util.parsing.json.JSONObject(notebookInfo)
-- MAGIC
-- MAGIC
-- MAGIC class CustomFilter extends PostProcessingFilter {
-- MAGIC   def this(conf: Configuration) = this()
-- MAGIC
-- MAGIC   override def processExecutionEvent(event: ExecutionEvent, ctx: HarvestingContext): ExecutionEvent =
-- MAGIC     event.withAddedExtra(Map("foo" -> "bar"))
-- MAGIC
-- MAGIC   override def processExecutionPlan(plan: ExecutionPlan, ctx: HarvestingContext ): ExecutionPlan =
-- MAGIC     plan.withAddedExtra(Map( "notebookInfo" -> notebookInfoJson))
-- MAGIC
-- MAGIC   override def processReadOperation(op: ReadOperation, ctx: HarvestingContext ): ReadOperation =
-- MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
-- MAGIC
-- MAGIC   override def processWriteOperation(op: WriteOperation, ctx: HarvestingContext): WriteOperation =
-- MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
-- MAGIC
-- MAGIC   override def processDataOperation(op: DataOperation, ctx: HarvestingContext  ): DataOperation =
-- MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
-- MAGIC }
-- MAGIC
-- MAGIC
-- MAGIC
-- MAGIC val myInstance = new CustomFilter()
-- MAGIC
-- MAGIC
-- MAGIC spark.enableLineageTracking(
-- MAGIC   AgentConfig.builder()
-- MAGIC     .postProcessingFilter(myInstance)
-- MAGIC     .build()
-- MAGIC )

-- COMMAND ----------



-- COMMAND ----------

-- MAGIC %scala
-- MAGIC import scala.util.parsing.json.JSON
-- MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
-- MAGIC import za.co.absa.spline.agent.AgentConfig
-- MAGIC import za.co.absa.spline.harvester.postprocessing.AbstractPostProcessingFilter
-- MAGIC import za.co.absa.spline.harvester.postprocessing.PostProcessingFilter
-- MAGIC import org.apache.commons.configuration.Configuration
-- MAGIC import za.co.absa.spline.harvester.conf.StandardSplineConfigurationStack
-- MAGIC import za.co.absa.spline.harvester.HarvestingContext
-- MAGIC import za.co.absa.spline.producer.model.ExecutionPlan
-- MAGIC import za.co.absa.spline.producer.model.ExecutionEvent
-- MAGIC import za.co.absa.spline.producer.model.ReadOperation
-- MAGIC import za.co.absa.spline.producer.model.WriteOperation
-- MAGIC import za.co.absa.spline.producer.model.DataOperation
-- MAGIC import za.co.absa.spline.harvester.ExtraMetadataImplicits._
-- MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
-- MAGIC
-- MAGIC val notebookInformationJson = dbutils.notebook.getContext.toJson
-- MAGIC val outerMap = JSON.parseFull(notebookInformationJson).getOrElse(0).asInstanceOf[Map[String,String]]
-- MAGIC val tagMap = outerMap("tags").asInstanceOf[Map[String,String]]
-- MAGIC val extraContextMap = outerMap("extraContext").asInstanceOf[Map[String,String]]
-- MAGIC val notebookPath = extraContextMap("notebook_path").split("/")
-- MAGIC val workspaceUrl=tagMap("browserHostName")
-- MAGIC
-- MAGIC val workspaceName=dbutils.notebook().getContext().notebookPath.get
-- MAGIC val notebookURL = tagMap("browserHostName")+"/?o="+tagMap("orgId")+tagMap("browserHash")
-- MAGIC val user = tagMap("user")
-- MAGIC val name = notebookPath(notebookPath.size-1)
-- MAGIC val notebookInfo = Map("notebookURL" -> notebookURL,
-- MAGIC "user" -> user,
-- MAGIC "workspaceName" ->workspaceName,
-- MAGIC "workspaceUrl" -> workspaceUrl,
-- MAGIC "name" -> name,
-- MAGIC "mounts" -> dbutils.fs.ls("/FileStore/tables").map(_.path),
-- MAGIC "timestamp" -> System.currentTimeMillis)
-- MAGIC val notebookInfoJson = scala.util.parsing.json.JSONObject(notebookInfo)
-- MAGIC
-- MAGIC
-- MAGIC class CustomFilter extends PostProcessingFilter {
-- MAGIC   def this(conf: Configuration) = this()
-- MAGIC
-- MAGIC   override def processExecutionEvent(event: ExecutionEvent, ctx: HarvestingContext): ExecutionEvent =
-- MAGIC     event.withAddedExtra(Map("foo" -> "bar"))
-- MAGIC
-- MAGIC   override def processExecutionPlan(plan: ExecutionPlan, ctx: HarvestingContext ): ExecutionPlan =
-- MAGIC     plan.withAddedExtra(Map( "notebookInfo" -> notebookInfoJson))
-- MAGIC
-- MAGIC   override def processReadOperation(op: ReadOperation, ctx: HarvestingContext ): ReadOperation =
-- MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
-- MAGIC
-- MAGIC   override def processWriteOperation(op: WriteOperation, ctx: HarvestingContext): WriteOperation =
-- MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
-- MAGIC
-- MAGIC   override def processDataOperation(op: DataOperation, ctx: HarvestingContext  ): DataOperation =
-- MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
-- MAGIC }
-- MAGIC
-- MAGIC
-- MAGIC
-- MAGIC val myInstance = new CustomFilter()
-- MAGIC
-- MAGIC
-- MAGIC spark.enableLineageTracking(
-- MAGIC   AgentConfig.builder()
-- MAGIC     .postProcessingFilter(myInstance)
-- MAGIC     .build()
-- MAGIC )

-- COMMAND ----------



-- COMMAND ----------

-- MAGIC %scala
-- MAGIC import scala.util.parsing.json.JSON
-- MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
-- MAGIC import za.co.absa.spline.agent.AgentConfig
-- MAGIC import za.co.absa.spline.harvester.postprocessing.AbstractPostProcessingFilter
-- MAGIC import za.co.absa.spline.harvester.postprocessing.PostProcessingFilter
-- MAGIC import org.apache.commons.configuration.Configuration
-- MAGIC import za.co.absa.spline.harvester.conf.StandardSplineConfigurationStack
-- MAGIC import za.co.absa.spline.harvester.HarvestingContext
-- MAGIC import za.co.absa.spline.producer.model.ExecutionPlan
-- MAGIC import za.co.absa.spline.producer.model.ExecutionEvent
-- MAGIC import za.co.absa.spline.producer.model.ReadOperation
-- MAGIC import za.co.absa.spline.producer.model.WriteOperation
-- MAGIC import za.co.absa.spline.producer.model.DataOperation
-- MAGIC import za.co.absa.spline.harvester.ExtraMetadataImplicits._
-- MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
-- MAGIC
-- MAGIC val notebookInformationJson = dbutils.notebook.getContext.toJson
-- MAGIC val outerMap = JSON.parseFull(notebookInformationJson).getOrElse(0).asInstanceOf[Map[String,String]]
-- MAGIC val tagMap = outerMap("tags").asInstanceOf[Map[String,String]]
-- MAGIC val extraContextMap = outerMap("extraContext").asInstanceOf[Map[String,String]]
-- MAGIC val notebookPath = extraContextMap("notebook_path").split("/")
-- MAGIC val workspaceUrl=tagMap("browserHostName")
-- MAGIC
-- MAGIC val workspaceName=dbutils.notebook().getContext().notebookPath.get
-- MAGIC val notebookURL = tagMap("browserHostName")+"/?o="+tagMap("orgId")+tagMap("browserHash")
-- MAGIC val user = tagMap("user")
-- MAGIC val name = notebookPath(notebookPath.size-1)
-- MAGIC val notebookInfo = Map("notebookURL" -> notebookURL,
-- MAGIC "user" -> user,
-- MAGIC "workspaceName" ->workspaceName,
-- MAGIC "workspaceUrl" -> workspaceUrl,
-- MAGIC "name" -> name,
-- MAGIC "mounts" -> dbutils.fs.ls("/FileStore/tables").map(_.path),
-- MAGIC "timestamp" -> System.currentTimeMillis)
-- MAGIC val notebookInfoJson = scala.util.parsing.json.JSONObject(notebookInfo)
-- MAGIC
-- MAGIC
-- MAGIC class CustomFilter extends PostProcessingFilter {
-- MAGIC   def this(conf: Configuration) = this()
-- MAGIC
-- MAGIC   override def processExecutionEvent(event: ExecutionEvent, ctx: HarvestingContext): ExecutionEvent =
-- MAGIC     event.withAddedExtra(Map("foo" -> "bar"))
-- MAGIC
-- MAGIC   override def processExecutionPlan(plan: ExecutionPlan, ctx: HarvestingContext ): ExecutionPlan =
-- MAGIC     plan.withAddedExtra(Map( "notebookInfo" -> notebookInfoJson))
-- MAGIC
-- MAGIC   override def processReadOperation(op: ReadOperation, ctx: HarvestingContext ): ReadOperation =
-- MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
-- MAGIC
-- MAGIC   override def processWriteOperation(op: WriteOperation, ctx: HarvestingContext): WriteOperation =
-- MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
-- MAGIC
-- MAGIC   override def processDataOperation(op: DataOperation, ctx: HarvestingContext  ): DataOperation =
-- MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
-- MAGIC }
-- MAGIC
-- MAGIC
-- MAGIC
-- MAGIC val myInstance = new CustomFilter()
-- MAGIC
-- MAGIC
-- MAGIC spark.enableLineageTracking(
-- MAGIC   AgentConfig.builder()
-- MAGIC     .postProcessingFilter(myInstance)
-- MAGIC     .build()
-- MAGIC )

-- COMMAND ----------



-- COMMAND ----------



-- COMMAND ----------

-- MAGIC %scala
-- MAGIC import scala.util.parsing.json.JSON
-- MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
-- MAGIC import za.co.absa.spline.agent.AgentConfig
-- MAGIC import za.co.absa.spline.harvester.postprocessing.AbstractPostProcessingFilter
-- MAGIC import za.co.absa.spline.harvester.postprocessing.PostProcessingFilter
-- MAGIC import org.apache.commons.configuration.Configuration
-- MAGIC import za.co.absa.spline.harvester.conf.StandardSplineConfigurationStack
-- MAGIC import za.co.absa.spline.harvester.HarvestingContext
-- MAGIC import za.co.absa.spline.producer.model.ExecutionPlan
-- MAGIC import za.co.absa.spline.producer.model.ExecutionEvent
-- MAGIC import za.co.absa.spline.producer.model.ReadOperation
-- MAGIC import za.co.absa.spline.producer.model.WriteOperation
-- MAGIC import za.co.absa.spline.producer.model.DataOperation
-- MAGIC import za.co.absa.spline.harvester.ExtraMetadataImplicits._
-- MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
-- MAGIC
-- MAGIC val notebookInformationJson = dbutils.notebook.getContext.toJson
-- MAGIC val outerMap = JSON.parseFull(notebookInformationJson).getOrElse(0).asInstanceOf[Map[String,String]]
-- MAGIC val tagMap = outerMap("tags").asInstanceOf[Map[String,String]]
-- MAGIC val extraContextMap = outerMap("extraContext").asInstanceOf[Map[String,String]]
-- MAGIC val notebookPath = extraContextMap("notebook_path").split("/")
-- MAGIC val workspaceUrl=tagMap("browserHostName")
-- MAGIC
-- MAGIC val workspaceName=dbutils.notebook().getContext().notebookPath.get
-- MAGIC val notebookURL = tagMap("browserHostName")+"/?o="+tagMap("orgId")+tagMap("browserHash")
-- MAGIC val user = tagMap("user")
-- MAGIC val name = notebookPath(notebookPath.size-1)
-- MAGIC val notebookInfo = Map("notebookURL" -> notebookURL,
-- MAGIC "user" -> user,
-- MAGIC "workspaceName" ->workspaceName,
-- MAGIC "workspaceUrl" -> workspaceUrl,
-- MAGIC "name" -> name,
-- MAGIC "mounts" -> dbutils.fs.ls("/FileStore/tables").map(_.path),
-- MAGIC "timestamp" -> System.currentTimeMillis)
-- MAGIC val notebookInfoJson = scala.util.parsing.json.JSONObject(notebookInfo)
-- MAGIC
-- MAGIC
-- MAGIC class CustomFilter extends PostProcessingFilter {
-- MAGIC   def this(conf: Configuration) = this()
-- MAGIC
-- MAGIC   override def processExecutionEvent(event: ExecutionEvent, ctx: HarvestingContext): ExecutionEvent =
-- MAGIC     event.withAddedExtra(Map("foo" -> "bar"))
-- MAGIC
-- MAGIC   override def processExecutionPlan(plan: ExecutionPlan, ctx: HarvestingContext ): ExecutionPlan =
-- MAGIC     plan.withAddedExtra(Map( "notebookInfo" -> notebookInfoJson))
-- MAGIC
-- MAGIC   override def processReadOperation(op: ReadOperation, ctx: HarvestingContext ): ReadOperation =
-- MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
-- MAGIC
-- MAGIC   override def processWriteOperation(op: WriteOperation, ctx: HarvestingContext): WriteOperation =
-- MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
-- MAGIC
-- MAGIC   override def processDataOperation(op: DataOperation, ctx: HarvestingContext  ): DataOperation =
-- MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
-- MAGIC }
-- MAGIC
-- MAGIC
-- MAGIC
-- MAGIC val myInstance = new CustomFilter()
-- MAGIC
-- MAGIC
-- MAGIC spark.enableLineageTracking(
-- MAGIC   AgentConfig.builder()
-- MAGIC     .postProcessingFilter(myInstance)
-- MAGIC     .build()
-- MAGIC )

-- COMMAND ----------

CREATE DATABASE IF NOT EXISTS f1_raw;

-- COMMAND ----------

-- MAGIC %md
-- MAGIC #### Create tables for CSV files

-- COMMAND ----------

-- MAGIC %md
-- MAGIC ##### Create circuits table

-- COMMAND ----------

DROP TABLE IF EXISTS f1_raw.circuits;
CREATE TABLE IF NOT EXISTS f1_raw.circuits(circuitId INT,
circuitRef STRING,
name STRING,
location STRING,
country STRING,
lat DOUBLE,
lng DOUBLE,
alt INT,
url STRING
)
USING csv
OPTIONS (path "/mnt/formula1dl/raw/circuits.csv", header true)

-- COMMAND ----------

SELECT * FROM f1_raw.circuits;

-- COMMAND ----------

-- MAGIC %md
-- MAGIC ##### Create races table

-- COMMAND ----------

DROP TABLE IF EXISTS f1_raw.races;
CREATE TABLE IF NOT EXISTS f1_raw.races(raceId INT,
year INT,
round INT,
circuitId INT,
name STRING,
date DATE,
time STRING,
url STRING)
USING csv
OPTIONS (path "/mnt/formula1dl/raw/races.csv", header true)

-- COMMAND ----------

SELECT * FROM f1_raw.races;

-- COMMAND ----------

-- MAGIC %md
-- MAGIC #### Create tables for JSON files

-- COMMAND ----------

-- MAGIC %md
-- MAGIC ##### Create constructors table
-- MAGIC * Single Line JSON
-- MAGIC * Simple structure

-- COMMAND ----------

DROP TABLE IF EXISTS f1_raw.constructors;
CREATE TABLE IF NOT EXISTS f1_raw.constructors(
constructorId INT,
constructorRef STRING,
name STRING,
nationality STRING,
url STRING)
USING json
OPTIONS(path "/mnt/formula1dl/raw/constructors.json")

-- COMMAND ----------

SELECT * FROM f1_raw.constructors;

-- COMMAND ----------

-- MAGIC %md
-- MAGIC ##### Create drivers table
-- MAGIC * Single Line JSON
-- MAGIC * Complex structure

-- COMMAND ----------

DROP TABLE IF EXISTS f1_raw.drivers;
CREATE TABLE IF NOT EXISTS f1_raw.drivers(
driverId INT,
driverRef STRING,
number INT,
code STRING,
name STRUCT<forename: STRING, surname: STRING>,
dob DATE,
nationality STRING,
url STRING)
USING json
OPTIONS (path "/mnt/formula1dl/raw/drivers.json")

-- COMMAND ----------

-- MAGIC %md ##### Create results table
-- MAGIC * Single Line JSON
-- MAGIC * Simple structure

-- COMMAND ----------

DROP TABLE IF EXISTS f1_raw.results;
CREATE TABLE IF NOT EXISTS f1_raw.results(
resultId INT,
raceId INT,
driverId INT,
constructorId INT,
number INT,grid INT,
position INT,
positionText STRING,
positionOrder INT,
points INT,
laps INT,
time STRING,
milliseconds INT,
fastestLap INT,
rank INT,
fastestLapTime STRING,
fastestLapSpeed FLOAT,
statusId STRING)
USING json
OPTIONS(path "/mnt/formula1dl/raw/results.json")

-- COMMAND ----------

SELECT * FROM f1_raw.results

-- COMMAND ----------

-- MAGIC %md
-- MAGIC ##### Create pit stops table
-- MAGIC * Multi Line JSON
-- MAGIC * Simple structure

-- COMMAND ----------

DROP TABLE IF EXISTS f1_raw.pit_stops;
CREATE TABLE IF NOT EXISTS f1_raw.pit_stops(
driverId INT,
duration STRING,
lap INT,
milliseconds INT,
raceId INT,
stop INT,
time STRING)
USING json
OPTIONS(path "/mnt/formula1dl/raw/pit_stops.json", multiLine true)

-- COMMAND ----------

SELECT * FROM f1_raw.pit_stops;

-- COMMAND ----------

-- MAGIC %md
-- MAGIC #### Create tables for list of files

-- COMMAND ----------

-- MAGIC %md
-- MAGIC ##### Create Lap Times Table
-- MAGIC * CSV file
-- MAGIC * Multiple files

-- COMMAND ----------

DROP TABLE IF EXISTS f1_raw.lap_times;
CREATE TABLE IF NOT EXISTS f1_raw.lap_times(
raceId INT,
driverId INT,
lap INT,
position INT,
time STRING,
milliseconds INT
)
USING csv
OPTIONS (path "/mnt/formula1dl/raw/lap_times")

-- COMMAND ----------

SELECT * FROM f1_raw.lap_times

-- COMMAND ----------

-- MAGIC %md
-- MAGIC ##### Create Qualifying Table
-- MAGIC * JSON file
-- MAGIC * MultiLine JSON
-- MAGIC * Multiple files

-- COMMAND ----------

DROP TABLE IF EXISTS f1_raw.qualifying;
CREATE TABLE IF NOT EXISTS f1_raw.qualifying(
constructorId INT,
driverId INT,
number INT,
position INT,
q1 STRING,
q2 STRING,
q3 STRING,
qualifyId INT,
raceId INT)
USING json
OPTIONS (path "/mnt/formula1dl/raw/qualifying", multiLine true)

-- COMMAND ----------

SELECT * FROM f1_raw.qualifying

-- COMMAND ----------

DESC EXTENDED f1_raw.qualifying;

-- COMMAND ----------


/Formula1-Project-Solutions (1)/Section-16-17-18/raw/1.create_raw_tables
Failed to write to file: [Errno 2] No such file or directory: 'notebook.json'
print("see1e")
/Formula1-Project-Solutions (1)/Section-16-17-18/utils/1.prepare_for_incremental_load
/Formula1-Project-Solutions (1)/Section-16-17-18/utils/1.prepare_for_incremental_load
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/9.create_processed_database
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/0.ingest_all_files
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/7.ingest_lap_times_file
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/8.ingest_qualifying_file
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/6.ingest_pit_stops_file
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/4.ingest_drivers_file
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/1.ingest_circuits_file
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/2.ingest_races_file
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/3.ingest_constructors_file
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/5.ingest_results_file
/Formula1-Project-Solutions (1)/Section-16-17-18/raw/1.create_raw_tables
/Formula1-Project-Solutions (1)/Section-16-17-18/analysis/2.find_dominant_teams
/Formula1-Project-Solutions (1)/Section-16-17-18/analysis/3.viz_dominant_drivers
/Formula1-Project-Solutions (1)/Section-16-17-18/analysis/4.viz_dominant_teams
/Formula1-Project-Solutions (1)/Section-16-17-18/analysis/1.find_dominant_drivers
/Formula1-Project-Solutions (1)/Section-12/ingestion/1.ingest_circuits_file
/Formula1-Project-Solutions (1)/Section-12/ingestion/7.ingest_lap_times_file
/Formula1-Project-Solutions (1)/Section-12/ingestion/4.ingest_drivers_file
/Formula1-Project-Solutions (1)/Section-12/ingestion/5.ingest_results_file
/Formula1-Project-Solutions (1)/Section-12/ingestion/8.ingest_qualifying_file
/Formula1-Project-Solutions (1)/Section-12/ingestion/0.ingest_all_files
/Formula1-Project-Solutions (1)/Section-12/ingestion/2.ingest_races_file
/Formula1-Project-Solutions (1)/Section-12/ingestion/3.ingest_constructors_file
/Formula1-Project-Solutions (1)/Section-12/ingestion/6.ingest_pit_stops_file
/Formula1-Project-Solutions (1)/Section-20/formula1/set-up/mount_adls_storage
/Formula1-Project-Solutions (1)/Section-20/formula1/analysis/4.viz_dominant_teams
/Formula1-Project-Solutions (1)/Section-20/formula1/analysis/3.viz_dominant_drivers
/Formula1-Project-Solutions (1)/Section-20/formula1/analysis/2.find_dominant_teams
/Formula1-Project-Solutions (1)/Section-20/formula1/analysis/1.find_dominant_drivers
/Formula1-Project-Solutions (1)/Section-20/formula1/raw/1.create_raw_tables
/Formula1-Project-Solutions (1)/Section-20/formula1/utils/1.prepare_for_incremental_load
/Formula1-Project-Solutions (1)/Section-20/formula1/demo/4.sql_temp_view_demo
/Formula1-Project-Solutions (1)/Section-20/formula1/demo/9.sql_joins_demo
/Formula1-Project-Solutions (1)/Section-20/formula1/demo/6.sql_objects_demo
/Formula1-Project-Solutions (1)/Section-20/formula1/demo/5.sql_temp_view_demo
/Formula1-Project-Solutions (1)/Section-20/formula1/demo/3.aggregation_demo
/Formula1-Project-Solutions (1)/Section-20/formula1/demo/7.sql_basics_demo
/Formula1-Project-Solutions (1)/Section-20/formula1/demo/2.join_demo
/Formula1-Project-Solutions (1)/Section-20/formula1/demo/8.sql_functions_demo
/Formula1-Project-Solutions (1)/Section-20/formula1/demo/10.delta_lake_demo
/Formula1-Project-Solutions (1)/Section-20/formula1/demo/1.filter_demo
/Formula1-Project-Solutions (1)/Section-20/formula1/includes/common_functions
/Formula1-Project-Solutions (1)/Section-20/formula1/includes/configuration
/Formula1-Project-Solutions (1)/Section-20/formula1/trans/1.race_results
/Formula1-Project-Solutions (1)/Section-20/formula1/trans/4.calculated_race_results
/Formula1-Project-Solutions (1)/Section-20/formula1/trans/3.constructor_standings
/Formula1-Project-Solutions (1)/Section-20/formula1/trans/0.create_presentation_database
/Formula1-Project-Solutions (1)/Section-20/formula1/trans/2.driver_standings
/Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/7.ingest_lap_times_file
/Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/6.ingest_pit_stops_file
/Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/3.ingest_constructors_file
/Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/4.ingest_drivers_file
/Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/1.ingest_circuits_file
/Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/9.create_processed_database
/Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/2.ingest_races_file
/Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/0.ingest_all_files
/Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/5.ingest_results_file
/Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/8.ingest_qualifying_file
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/analysis/3.viz_dominant_drivers
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/analysis/2.find_dominant_teams
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/analysis/4.viz_dominant_teams
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/analysis/1.find_dominant_drivers
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/set-up/mount_adls_storage
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/0.ingest_all_files
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/7.ingest_lap_times_file
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/9.create_processed_database
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/4.ingest_drivers_file
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/5.ingest_results_file
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/8.ingest_qualifying_file
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/3.ingest_constructors_file
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/2.ingest_races_file
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/6.ingest_pit_stops_file
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/1.ingest_circuits_file
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/trans/3.constructor_standings
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/trans/2.driver_standings
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/trans/1.race_results
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/trans/4.calculated_race_results
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/trans/0.create_presentation_database
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/4.sql_temp_view_demo
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/8.sql_functions_demo
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/10.delta_lake_demo
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/9.sql_joins_demo
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/1.filter_demo
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/5.sql_temp_view_demo
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/6.sql_objects_demo
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/2.join_demo
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/3.aggregation_demo
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/7.sql_basics_demo
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/includes/common_functions
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/includes/configuration
# MAGIC %scala
# MAGIC import scala.util.parsing.json.JSON
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC import za.co.absa.spline.agent.AgentConfig
# MAGIC import za.co.absa.spline.harvester.postprocessing.AbstractPostProcessingFilter
# MAGIC import za.co.absa.spline.harvester.postprocessing.PostProcessingFilter
# MAGIC import org.apache.commons.configuration.Configuration
# MAGIC import za.co.absa.spline.harvester.conf.StandardSplineConfigurationStack
# MAGIC import za.co.absa.spline.harvester.HarvestingContext
# MAGIC import za.co.absa.spline.producer.model.ExecutionPlan
# MAGIC import za.co.absa.spline.producer.model.ExecutionEvent
# MAGIC import za.co.absa.spline.producer.model.ReadOperation
# MAGIC import za.co.absa.spline.producer.model.WriteOperation
# MAGIC import za.co.absa.spline.producer.model.DataOperation
# MAGIC import za.co.absa.spline.harvester.ExtraMetadataImplicits._
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC
# MAGIC val notebookInformationJson = dbutils.notebook.getContext.toJson
# MAGIC val outerMap = JSON.parseFull(notebookInformationJson).getOrElse(0).asInstanceOf[Map[String,String]]
# MAGIC val tagMap = outerMap("tags").asInstanceOf[Map[String,String]]
# MAGIC val extraContextMap = outerMap("extraContext").asInstanceOf[Map[String,String]]
# MAGIC val notebookPath = extraContextMap("notebook_path").split("/")
# MAGIC val workspaceUrl=tagMap("browserHostName")
# MAGIC
# MAGIC val workspaceName=dbutils.notebook().getContext().notebookPath.get
# MAGIC val notebookURL = tagMap("browserHostName")+"/?o="+tagMap("orgId")+tagMap("browserHash")
# MAGIC val user = tagMap("user")
# MAGIC val name = notebookPath(notebookPath.size-1)
# MAGIC val notebookInfo = Map("notebookURL" -> notebookURL,
# MAGIC "user" -> user,
# MAGIC "workspaceName" ->workspaceName,
# MAGIC "workspaceUrl" -> workspaceUrl,
# MAGIC "name" -> name,
# MAGIC "mounts" -> dbutils.fs.ls("/FileStore/tables").map(_.path),
# MAGIC "timestamp" -> System.currentTimeMillis)
# MAGIC val notebookInfoJson = scala.util.parsing.json.JSONObject(notebookInfo)
# MAGIC
# MAGIC
# MAGIC class CustomFilter extends PostProcessingFilter {
# MAGIC   def this(conf: Configuration) = this()
# MAGIC
# MAGIC   override def processExecutionEvent(event: ExecutionEvent, ctx: HarvestingContext): ExecutionEvent =
# MAGIC     event.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processExecutionPlan(plan: ExecutionPlan, ctx: HarvestingContext ): ExecutionPlan =
# MAGIC     plan.withAddedExtra(Map( "notebookInfo" -> notebookInfoJson))
# MAGIC
# MAGIC   override def processReadOperation(op: ReadOperation, ctx: HarvestingContext ): ReadOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processWriteOperation(op: WriteOperation, ctx: HarvestingContext): WriteOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processDataOperation(op: DataOperation, ctx: HarvestingContext  ): DataOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC }
# MAGIC
# MAGIC
# MAGIC
# MAGIC val myInstance = new CustomFilter()
# MAGIC
# MAGIC
# MAGIC spark.enableLineageTracking(
# MAGIC   AgentConfig.builder()
# MAGIC     .postProcessingFilter(myInstance)
# MAGIC     .build()
# MAGIC )

# COMMAND ----------

sc._jvm.za.co.absa.spline.harvester.SparkLineageInitializer.enableLineageTracking(spark._jsparkSession)

# COMMAND ----------

print("see1e")
/Formula1-Project-Solutions (1)/Section-16-17-18/utils/1.prepare_for_incremental_load
# MAGIC %scala
# MAGIC import scala.util.parsing.json.JSON
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC import za.co.absa.spline.agent.AgentConfig
# MAGIC import za.co.absa.spline.harvester.postprocessing.AbstractPostProcessingFilter
# MAGIC import za.co.absa.spline.harvester.postprocessing.PostProcessingFilter
# MAGIC import org.apache.commons.configuration.Configuration
# MAGIC import za.co.absa.spline.harvester.conf.StandardSplineConfigurationStack
# MAGIC import za.co.absa.spline.harvester.HarvestingContext
# MAGIC import za.co.absa.spline.producer.model.ExecutionPlan
# MAGIC import za.co.absa.spline.producer.model.ExecutionEvent
# MAGIC import za.co.absa.spline.producer.model.ReadOperation
# MAGIC import za.co.absa.spline.producer.model.WriteOperation
# MAGIC import za.co.absa.spline.producer.model.DataOperation
# MAGIC import za.co.absa.spline.harvester.ExtraMetadataImplicits._
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC
# MAGIC val notebookInformationJson = dbutils.notebook.getContext.toJson
# MAGIC val outerMap = JSON.parseFull(notebookInformationJson).getOrElse(0).asInstanceOf[Map[String,String]]
# MAGIC val tagMap = outerMap("tags").asInstanceOf[Map[String,String]]
# MAGIC val extraContextMap = outerMap("extraContext").asInstanceOf[Map[String,String]]
# MAGIC val notebookPath = extraContextMap("notebook_path").split("/")
# MAGIC val workspaceUrl=tagMap("browserHostName")
# MAGIC
# MAGIC val workspaceName=dbutils.notebook().getContext().notebookPath.get
# MAGIC val notebookURL = tagMap("browserHostName")+"/?o="+tagMap("orgId")+tagMap("browserHash")
# MAGIC val user = tagMap("user")
# MAGIC val name = notebookPath(notebookPath.size-1)
# MAGIC val notebookInfo = Map("notebookURL" -> notebookURL,
# MAGIC "user" -> user,
# MAGIC "workspaceName" ->workspaceName,
# MAGIC "workspaceUrl" -> workspaceUrl,
# MAGIC "name" -> name,
# MAGIC "mounts" -> dbutils.fs.ls("/FileStore/tables").map(_.path),
# MAGIC "timestamp" -> System.currentTimeMillis)
# MAGIC val notebookInfoJson = scala.util.parsing.json.JSONObject(notebookInfo)
# MAGIC
# MAGIC
# MAGIC class CustomFilter extends PostProcessingFilter {
# MAGIC   def this(conf: Configuration) = this()
# MAGIC
# MAGIC   override def processExecutionEvent(event: ExecutionEvent, ctx: HarvestingContext): ExecutionEvent =
# MAGIC     event.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processExecutionPlan(plan: ExecutionPlan, ctx: HarvestingContext ): ExecutionPlan =
# MAGIC     plan.withAddedExtra(Map( "notebookInfo" -> notebookInfoJson))
# MAGIC
# MAGIC   override def processReadOperation(op: ReadOperation, ctx: HarvestingContext ): ReadOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processWriteOperation(op: WriteOperation, ctx: HarvestingContext): WriteOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processDataOperation(op: DataOperation, ctx: HarvestingContext  ): DataOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC }
# MAGIC
# MAGIC
# MAGIC
# MAGIC val myInstance = new CustomFilter()
# MAGIC
# MAGIC
# MAGIC spark.enableLineageTracking(
# MAGIC   AgentConfig.builder()
# MAGIC     .postProcessingFilter(myInstance)
# MAGIC     .build()
# MAGIC )

# COMMAND ----------

sc._jvm.za.co.absa.spline.harvester.SparkLineageInitializer.enableLineageTracking(spark._jsparkSession)

# COMMAND ----------

print("see1e")
/Formula1-Project-Solutions (1)/Section-16-17-18/utils/1.prepare_for_incremental_load
/Formula1-Project-Solutions (1)/Section-16-17-18/utils/1.prepare_for_incremental_load
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/9.create_processed_database
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/0.ingest_all_files
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/7.ingest_lap_times_file
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/8.ingest_qualifying_file
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/6.ingest_pit_stops_file
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/4.ingest_drivers_file
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/1.ingest_circuits_file
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/2.ingest_races_file
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/3.ingest_constructors_file
/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/5.ingest_results_file
/Formula1-Project-Solutions (1)/Section-16-17-18/raw/1.create_raw_tables
/Formula1-Project-Solutions (1)/Section-16-17-18/analysis/2.find_dominant_teams
/Formula1-Project-Solutions (1)/Section-16-17-18/analysis/3.viz_dominant_drivers
/Formula1-Project-Solutions (1)/Section-16-17-18/analysis/4.viz_dominant_teams
/Formula1-Project-Solutions (1)/Section-16-17-18/analysis/1.find_dominant_drivers
/Formula1-Project-Solutions (1)/Section-12/ingestion/1.ingest_circuits_file
/Formula1-Project-Solutions (1)/Section-12/ingestion/7.ingest_lap_times_file
/Formula1-Project-Solutions (1)/Section-12/ingestion/4.ingest_drivers_file
/Formula1-Project-Solutions (1)/Section-12/ingestion/5.ingest_results_file
/Formula1-Project-Solutions (1)/Section-12/ingestion/8.ingest_qualifying_file
/Formula1-Project-Solutions (1)/Section-12/ingestion/0.ingest_all_files
/Formula1-Project-Solutions (1)/Section-12/ingestion/2.ingest_races_file
/Formula1-Project-Solutions (1)/Section-12/ingestion/3.ingest_constructors_file
/Formula1-Project-Solutions (1)/Section-12/ingestion/6.ingest_pit_stops_file
/Formula1-Project-Solutions (1)/Section-20/formula1/set-up/mount_adls_storage
/Formula1-Project-Solutions (1)/Section-20/formula1/analysis/4.viz_dominant_teams
/Formula1-Project-Solutions (1)/Section-20/formula1/analysis/3.viz_dominant_drivers
/Formula1-Project-Solutions (1)/Section-20/formula1/analysis/2.find_dominant_teams
/Formula1-Project-Solutions (1)/Section-20/formula1/analysis/1.find_dominant_drivers
/Formula1-Project-Solutions (1)/Section-20/formula1/raw/1.create_raw_tables
/Formula1-Project-Solutions (1)/Section-20/formula1/utils/1.prepare_for_incremental_load
/Formula1-Project-Solutions (1)/Section-20/formula1/demo/4.sql_temp_view_demo
/Formula1-Project-Solutions (1)/Section-20/formula1/demo/9.sql_joins_demo
/Formula1-Project-Solutions (1)/Section-20/formula1/demo/6.sql_objects_demo
/Formula1-Project-Solutions (1)/Section-20/formula1/demo/5.sql_temp_view_demo
/Formula1-Project-Solutions (1)/Section-20/formula1/demo/3.aggregation_demo
/Formula1-Project-Solutions (1)/Section-20/formula1/demo/7.sql_basics_demo
/Formula1-Project-Solutions (1)/Section-20/formula1/demo/2.join_demo
/Formula1-Project-Solutions (1)/Section-20/formula1/demo/8.sql_functions_demo
/Formula1-Project-Solutions (1)/Section-20/formula1/demo/10.delta_lake_demo
/Formula1-Project-Solutions (1)/Section-20/formula1/demo/1.filter_demo
/Formula1-Project-Solutions (1)/Section-20/formula1/includes/common_functions
/Formula1-Project-Solutions (1)/Section-20/formula1/includes/configuration
/Formula1-Project-Solutions (1)/Section-20/formula1/trans/1.race_results
/Formula1-Project-Solutions (1)/Section-20/formula1/trans/4.calculated_race_results
/Formula1-Project-Solutions (1)/Section-20/formula1/trans/3.constructor_standings
/Formula1-Project-Solutions (1)/Section-20/formula1/trans/0.create_presentation_database
/Formula1-Project-Solutions (1)/Section-20/formula1/trans/2.driver_standings
/Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/7.ingest_lap_times_file
/Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/6.ingest_pit_stops_file
/Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/3.ingest_constructors_file
/Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/4.ingest_drivers_file
/Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/1.ingest_circuits_file
/Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/9.create_processed_database
/Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/2.ingest_races_file
/Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/0.ingest_all_files
/Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/5.ingest_results_file
/Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/8.ingest_qualifying_file
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/analysis/3.viz_dominant_drivers
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/analysis/2.find_dominant_teams
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/analysis/4.viz_dominant_teams
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/analysis/1.find_dominant_drivers
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/set-up/mount_adls_storage
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/0.ingest_all_files
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/7.ingest_lap_times_file
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/9.create_processed_database
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/4.ingest_drivers_file
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/5.ingest_results_file
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/8.ingest_qualifying_file
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/3.ingest_constructors_file
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/2.ingest_races_file
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/6.ingest_pit_stops_file
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/1.ingest_circuits_file
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/trans/3.constructor_standings
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/trans/2.driver_standings
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/trans/1.race_results
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/trans/4.calculated_race_results
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/trans/0.create_presentation_database
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/4.sql_temp_view_demo
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/8.sql_functions_demo
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/10.delta_lake_demo
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/9.sql_joins_demo
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/1.filter_demo
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/5.sql_temp_view_demo
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/6.sql_objects_demo
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/2.join_demo
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/3.aggregation_demo
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/7.sql_basics_demo
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/includes/common_functions
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/includes/configuration
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/utils/1.prepare_for_incremental_load
/Formula1-Project-Solutions (1)/Z-End of Course/formula1/raw/1.create_raw_tables
/Formula1-Project-Solutions (1)/Section-14/trans/2.driver_standings
/Formula1-Project-Solutions (1)/Section-14/trans/1.race_results
/Formula1-Project-Solutions (1)/Section-14/trans/3.constructor_standings
/Formula1-Project-Solutions (1)/Section-19/trans/1.race_results
/Formula1-Project-Solutions (1)/Section-19/trans/4.calculated_race_results
/Formula1-Project-Solutions (1)/Section-19/trans/3.constructor_standings
/Formula1-Project-Solutions (1)/Section-19/trans/0.create_presentation_database
/Formula1-Project-Solutions (1)/Section-19/trans/2.driver_standings
/Formula1-Project-Solutions (1)/Section-19/includes/common_functions
/Formula1-Project-Solutions (1)/Section-19/includes/configuration
/Formula1-Project-Solutions (1)/Section-19/ingestion/9.create_processed_database
/Formula1-Project-Solutions (1)/Section-19/ingestion/3.ingest_constructors_file
/Formula1-Project-Solutions (1)/Section-19/ingestion/4.ingest_drivers_file
/Formula1-Project-Solutions (1)/Section-19/ingestion/6.ingest_pit_stops_file
/Formula1-Project-Solutions (1)/Section-19/ingestion/2.ingest_races_file
/Formula1-Project-Solutions (1)/Section-19/ingestion/8.ingest_qualifying_file
/Formula1-Project-Solutions (1)/Section-19/ingestion/7.ingest_lap_times_file
/Formula1-Project-Solutions (1)/Section-19/ingestion/1.ingest_circuits_file
/Formula1-Project-Solutions (1)/Section-19/ingestion/0.ingest_all_files
/Formula1-Project-Solutions (1)/Section-19/ingestion/5.ingest_results_file
/Formula1-Project-Solutions (1)/Section-06/mount_adls_storage-lesson-6
/Formula1-Project-Solutions (1)/Section-06/mount_adls_storage-lesson-9
/Formula1-Project-Solutions (1)/Section-09-10-11/ingestion/7.ingest_lap_times_file
/Formula1-Project-Solutions (1)/Section-09-10-11/ingestion/5.ingest_results_file
/Formula1-Project-Solutions (1)/Section-09-10-11/ingestion/2.ingest_races_file
/Formula1-Project-Solutions (1)/Section-09-10-11/ingestion/3.ingest_constructors_file
/Formula1-Project-Solutions (1)/Section-09-10-11/ingestion/4.ingest_drivers_file
/Formula1-Project-Solutions (1)/Section-09-10-11/ingestion/1.ingest_circuits_file
/Formula1-Project-Solutions (1)/Section-09-10-11/ingestion/6.ingest_pit_stops_file
/Formula1-Project-Solutions (1)/Section-09-10-11/ingestion/8.ingest_qualifying_file
/Users/dora@octopai.com/Sql_PY (1)
/Users/zacayd@octopai.com/splineScaleExample
/Users/zacayd@octopai.com/ScalaCode
/Users/zacayd@octopai.com/SplineCode
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/utils/1.prepare_for_incremental_load
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/9.create_processed_database
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/0.ingest_all_files
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/7.ingest_lap_times_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/8.ingest_qualifying_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/6.ingest_pit_stops_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/4.ingest_drivers_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/1.ingest_circuits_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/2.ingest_races_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/3.ingest_constructors_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/5.ingest_results_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/raw/1.create_raw_tables
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/analysis/2.find_dominant_teams
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/analysis/3.viz_dominant_drivers
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/analysis/4.viz_dominant_teams
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/analysis/1.find_dominant_drivers
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-12/ingestion/1.ingest_circuits_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-12/ingestion/7.ingest_lap_times_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-12/ingestion/4.ingest_drivers_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-12/ingestion/5.ingest_results_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-12/ingestion/8.ingest_qualifying_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-12/ingestion/0.ingest_all_files
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-12/ingestion/2.ingest_races_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-12/ingestion/3.ingest_constructors_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-12/ingestion/6.ingest_pit_stops_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/set-up/mount_adls_storage
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/analysis/4.viz_dominant_teams
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/analysis/3.viz_dominant_drivers
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/analysis/2.find_dominant_teams
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/analysis/1.find_dominant_drivers
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/raw/1.create_raw_tables
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/utils/1.prepare_for_incremental_load
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/demo/4.sql_temp_view_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/demo/9.sql_joins_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/demo/6.sql_objects_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/demo/5.sql_temp_view_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/demo/3.aggregation_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/demo/7.sql_basics_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/demo/2.join_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/demo/8.sql_functions_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/demo/10.delta_lake_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/demo/1.filter_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/includes/common_functions
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/includes/configuration
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/trans/1.race_results
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/trans/4.calculated_race_results
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/trans/3.constructor_standings
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/trans/0.create_presentation_database
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/trans/2.driver_standings
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/ingestion/7.ingest_lap_times_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/ingestion/6.ingest_pit_stops_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/ingestion/3.ingest_constructors_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/ingestion/4.ingest_drivers_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/ingestion/1.ingest_circuits_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/ingestion/9.create_processed_database
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/ingestion/2.ingest_races_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/ingestion/0.ingest_all_files
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/ingestion/5.ingest_results_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/ingestion/8.ingest_qualifying_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/analysis/3.viz_dominant_drivers
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/analysis/2.find_dominant_teams
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/analysis/4.viz_dominant_teams
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/analysis/1.find_dominant_drivers
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/set-up/mount_adls_storage
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/0.ingest_all_files
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/7.ingest_lap_times_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/9.create_processed_database
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/4.ingest_drivers_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/5.ingest_results_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/8.ingest_qualifying_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/3.ingest_constructors_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/2.ingest_races_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/6.ingest_pit_stops_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/1.ingest_circuits_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/trans/3.constructor_standings
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/trans/2.driver_standings
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/trans/1.race_results
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/trans/4.calculated_race_results
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/trans/0.create_presentation_database
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/demo/4.sql_temp_view_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/demo/8.sql_functions_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/demo/10.delta_lake_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/demo/9.sql_joins_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/demo/1.filter_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/demo/5.sql_temp_view_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/demo/6.sql_objects_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/demo/2.join_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/demo/3.aggregation_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/demo/7.sql_basics_demo
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/includes/common_functions
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/includes/configuration
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/utils/1.prepare_for_incremental_load
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/raw/1.create_raw_tables
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-14/trans/2.driver_standings
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-14/trans/1.race_results
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-14/trans/3.constructor_standings
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/trans/1.race_results
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/trans/4.calculated_race_results
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/trans/3.constructor_standings
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/trans/0.create_presentation_database
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/trans/2.driver_standings
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/includes/common_functions
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/includes/configuration
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/ingestion/9.create_processed_database
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/ingestion/3.ingest_constructors_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/ingestion/4.ingest_drivers_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/ingestion/6.ingest_pit_stops_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/ingestion/2.ingest_races_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/ingestion/8.ingest_qualifying_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/ingestion/7.ingest_lap_times_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/ingestion/1.ingest_circuits_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/ingestion/0.ingest_all_files
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/ingestion/5.ingest_results_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-06/mount_adls_storage-lesson-6
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-06/mount_adls_storage-lesson-9
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-09-10-11/ingestion/7.ingest_lap_times_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-09-10-11/ingestion/5.ingest_results_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-09-10-11/ingestion/2.ingest_races_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-09-10-11/ingestion/3.ingest_constructors_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-09-10-11/ingestion/4.ingest_drivers_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-09-10-11/ingestion/1.ingest_circuits_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-09-10-11/ingestion/6.ingest_pit_stops_file
/Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-09-10-11/ingestion/8.ingest_qualifying_file
/Users/zacayd@octopai.com/pythonz
/Users/zacayd@octopai.com/Sandvine_BillingRecon
/Users/zacayd@octopai.com/SqlExample
/Users/zacayd@octopai.com/Zacay
/Users/zacayd@octopai.com/Scala
/Users/zacayd@octopai.com/Scala2
/Users/zacayd@octopai.com/NoteBookTest
/Users/zacayd@octopai.com/2022-10-31 - DBFS Example
/Users/zacayd@octopai.com/Scala1
/Users/zacayd@octopai.com/pythony
/Users/zacayd@octopai.com/py2
/Users/zacayd@octopai.com/TEST
/Users/zacayd@octopai.com/ScalaHarverster
/Users/zacayd@octopai.com/MyTest
/Users/zacayd@octopai.com/Azure Blob Storage
/Users/zacayd@octopai.com/MySQL
/Users/zacayd@octopai.com/ExampleDLT
/Users/zacayd@octopai.com/ExampleDLT_SQL
/Users/zacayd@octopai.com/Untitled Notebook 2023-06-12 15:44:30
/Users/zacayd@octopai.com/MyLogs
/Users/zacayd@octopai.com/Helper
/Users/zacayd@octopai.com/Digicel_SandvineBilling
/Users/zacayd@octopai.com/Digicel
/Users/zacayd@octopai.com/Scalal
/Users/zacayd@octopai.com/2022-10-25 - DBFS Example
/Users/zacayd@octopai.com/pythonX
/Users/zacayd@octopai.com/Sql_PY
/Users/zacayd@octopai.com/ScalaPython
/Shared/Untitled Notebook 2023-05-23 09:28:27
/Shared/DL_BULKSMS_JAM
/Shared/AAP_CLIENT
/Shared/Sandvine_BillingRecon
/Shared/SELFCARE_USAGE
/Shared/ShakeIT_WonReward
/Shared/ODS_Digicel_App
/Shared/ODS_Digicel_App_User
/Shared/ODS_Selfcare_Incremental
/Shared/ODS_ShakeITAttempt
/Shared/Data-Delivery/EDW/NB_CargaTbContratoVarejo
/Shared/Querying the Delta Live Tables event log
/Shared/DL_BULKSMS_JAM_TEST
/Formula1-Project-Solutions/Section-16-17-18/utils/1.prepare_for_incremental_load
/Formula1-Project-Solutions/Section-16-17-18/analysis/3.viz_dominant_drivers
/Formula1-Project-Solutions/Section-16-17-18/analysis/4.viz_dominant_teams
/Formula1-Project-Solutions/Section-16-17-18/analysis/2.find_dominant_teams
/Formula1-Project-Solutions/Section-16-17-18/analysis/1.find_dominant_drivers
/Formula1-Project-Solutions/Section-16-17-18/ingestion/6.ingest_pit_stops_file
/Formula1-Project-Solutions/Section-16-17-18/ingestion/3.ingest_constructors_file
/Formula1-Project-Solutions/Section-16-17-18/ingestion/2.ingest_races_file
/Formula1-Project-Solutions/Section-16-17-18/ingestion/9.create_processed_database
/Formula1-Project-Solutions/Section-16-17-18/ingestion/8.ingest_qualifying_file
/Formula1-Project-Solutions/Section-16-17-18/ingestion/4.ingest_drivers_file
/Formula1-Project-Solutions/Section-16-17-18/ingestion/5.ingest_results_file
/Formula1-Project-Solutions/Section-16-17-18/ingestion/7.ingest_lap_times_file
/Formula1-Project-Solutions/Section-16-17-18/ingestion/1.ingest_circuits_file
/Formula1-Project-Solutions/Section-16-17-18/ingestion/0.ingest_all_files
/Formula1-Project-Solutions/Section-16-17-18/raw/1.create_raw_tables
/Formula1-Project-Solutions/Section-14/trans/3.constructor_standings
/Formula1-Project-Solutions/Section-14/trans/2.driver_standings
/Formula1-Project-Solutions/Section-14/trans/1.race_results
/Formula1-Project-Solutions/Section-12/ingestion/2.ingest_races_file
/Formula1-Project-Solutions/Section-12/ingestion/5.ingest_results_file
/Formula1-Project-Solutions/Section-12/ingestion/8.ingest_qualifying_file
/Formula1-Project-Solutions/Section-12/ingestion/1.ingest_circuits_file
/Formula1-Project-Solutions/Section-12/ingestion/0.ingest_all_files
/Formula1-Project-Solutions/Section-12/ingestion/6.ingest_pit_stops_file
/Formula1-Project-Solutions/Section-12/ingestion/7.ingest_lap_times_file
/Formula1-Project-Solutions/Section-12/ingestion/3.ingest_constructors_file
/Formula1-Project-Solutions/Section-12/ingestion/4.ingest_drivers_file
/Formula1-Project-Solutions/Section-06/mount_adls_storage-lesson-6
/Formula1-Project-Solutions/Section-06/mount_adls_storage-lesson-9
/Formula1-Project-Solutions/Section-09-10-11/ingestion/3.ingest_constructors_file
/Formula1-Project-Solutions/Section-09-10-11/ingestion/5.ingest_results_file
/Formula1-Project-Solutions/Section-09-10-11/ingestion/4.ingest_drivers_file
/Formula1-Project-Solutions/Section-09-10-11/ingestion/6.ingest_pit_stops_file
/Formula1-Project-Solutions/Section-09-10-11/ingestion/7.ingest_lap_times_file
/Formula1-Project-Solutions/Section-09-10-11/ingestion/2.ingest_races_file
/Formula1-Project-Solutions/Section-09-10-11/ingestion/1.ingest_circuits_file
/Formula1-Project-Solutions/Section-09-10-11/ingestion/8.ingest_qualifying_file
/Formula1-Project-Solutions/Section-19/ingestion/3.ingest_constructors_file
/Formula1-Project-Solutions/Section-19/ingestion/6.ingest_pit_stops_file
/Formula1-Project-Solutions/Section-19/ingestion/5.ingest_results_file
/Formula1-Project-Solutions/Section-19/ingestion/9.create_processed_database
/Formula1-Project-Solutions/Section-19/ingestion/8.ingest_qualifying_file
/Formula1-Project-Solutions/Section-19/ingestion/4.ingest_drivers_file
/Formula1-Project-Solutions/Section-19/ingestion/0.ingest_all_files
/Formula1-Project-Solutions/Section-19/ingestion/7.ingest_lap_times_file
/Formula1-Project-Solutions/Section-19/ingestion/1.ingest_circuits_file
/Formula1-Project-Solutions/Section-19/ingestion/2.ingest_races_file
/Formula1-Project-Solutions/Section-19/trans/4.calculated_race_results
/Formula1-Project-Solutions/Section-19/trans/0.create_presentation_database
/Formula1-Project-Solutions/Section-19/trans/3.constructor_standings
/Formula1-Project-Solutions/Section-19/trans/1.race_results
/Formula1-Project-Solutions/Section-19/trans/2.driver_standings
/Formula1-Project-Solutions/Section-19/includes/common_functions
/Formula1-Project-Solutions/Section-19/includes/configuration
/Formula1-Project-Solutions/Section-20/formula1/set-up/mount_adls_storage
/Formula1-Project-Solutions/Section-20/formula1/ingestion/7.ingest_lap_times_file
/Formula1-Project-Solutions/Section-20/formula1/ingestion/3.ingest_constructors_file
/Formula1-Project-Solutions/Section-20/formula1/ingestion/5.ingest_results_file
/Formula1-Project-Solutions/Section-20/formula1/ingestion/2.ingest_races_file
/Formula1-Project-Solutions/Section-20/formula1/ingestion/1.ingest_circuits_file
/Formula1-Project-Solutions/Section-20/formula1/ingestion/4.ingest_drivers_file
/Formula1-Project-Solutions/Section-20/formula1/ingestion/6.ingest_pit_stops_file
/Formula1-Project-Solutions/Section-20/formula1/ingestion/9.create_processed_database
/Formula1-Project-Solutions/Section-20/formula1/ingestion/0.ingest_all_files
/Formula1-Project-Solutions/Section-20/formula1/ingestion/8.ingest_qualifying_file
/Formula1-Project-Solutions/Section-20/formula1/utils/1.prepare_for_incremental_load
/Formula1-Project-Solutions/Section-20/formula1/trans/3.constructor_standings
/Formula1-Project-Solutions/Section-20/formula1/trans/4.calculated_race_results
/Formula1-Project-Solutions/Section-20/formula1/trans/1.race_results
/Formula1-Project-Solutions/Section-20/formula1/trans/0.create_presentation_database
/Formula1-Project-Solutions/Section-20/formula1/trans/2.driver_standings
/Formula1-Project-Solutions/Section-20/formula1/analysis/3.viz_dominant_drivers
/Formula1-Project-Solutions/Section-20/formula1/analysis/1.find_dominant_drivers
/Formula1-Project-Solutions/Section-20/formula1/analysis/2.find_dominant_teams
/Formula1-Project-Solutions/Section-20/formula1/analysis/4.viz_dominant_teams
/Formula1-Project-Solutions/Section-20/formula1/raw/1.create_raw_tables
/Formula1-Project-Solutions/Section-20/formula1/demo/8.sql_functions_demo
/Formula1-Project-Solutions/Section-20/formula1/demo/5.sql_temp_view_demo
/Formula1-Project-Solutions/Section-20/formula1/demo/6.sql_objects_demo
/Formula1-Project-Solutions/Section-20/formula1/demo/2.join_demo
/Formula1-Project-Solutions/Section-20/formula1/demo/9.sql_joins_demo
/Formula1-Project-Solutions/Section-20/formula1/demo/4.sql_temp_view_demo
/Formula1-Project-Solutions/Section-20/formula1/demo/3.aggregation_demo
/Formula1-Project-Solutions/Section-20/formula1/demo/10.delta_lake_demo
/Formula1-Project-Solutions/Section-20/formula1/demo/7.sql_basics_demo
/Formula1-Project-Solutions/Section-20/formula1/demo/1.filter_demo
/Formula1-Project-Solutions/Section-20/formula1/includes/configuration
/Formula1-Project-Solutions/Section-20/formula1/includes/common_functions
/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/7.ingest_lap_times_file
/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/2.ingest_races_file
/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/5.ingest_results_file
/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/9.create_processed_database
/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/3.ingest_constructors_file
/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/1.ingest_circuits_file
/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/0.ingest_all_files
/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/4.ingest_drivers_file
/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/8.ingest_qualifying_file
/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/6.ingest_pit_stops_file
/Formula1-Project-Solutions/Z-End of Course/formula1/set-up/mount_adls_storage
/Formula1-Project-Solutions/Z-End of Course/formula1/demo/6.sql_objects_demo
/Formula1-Project-Solutions/Z-End of Course/formula1/demo/7.sql_basics_demo
/Formula1-Project-Solutions/Z-End of Course/formula1/demo/8.sql_functions_demo
/Formula1-Project-Solutions/Z-End of Course/formula1/demo/4.sql_temp_view_demo
/Formula1-Project-Solutions/Z-End of Course/formula1/demo/3.aggregation_demo
/Formula1-Project-Solutions/Z-End of Course/formula1/demo/1.filter_demo
/Formula1-Project-Solutions/Z-End of Course/formula1/demo/2.join_demo
/Formula1-Project-Solutions/Z-End of Course/formula1/demo/5.sql_temp_view_demo
/Formula1-Project-Solutions/Z-End of Course/formula1/demo/9.sql_joins_demo
/Formula1-Project-Solutions/Z-End of Course/formula1/demo/10.delta_lake_demo
/Formula1-Project-Solutions/Z-End of Course/formula1/includes/common_functions
/Formula1-Project-Solutions/Z-End of Course/formula1/includes/configuration
/Formula1-Project-Solutions/Z-End of Course/formula1/utils/1.prepare_for_incremental_load
/Formula1-Project-Solutions/Z-End of Course/formula1/raw/1.create_raw_tables
/Formula1-Project-Solutions/Z-End of Course/formula1/trans/0.create_presentation_database
/Formula1-Project-Solutions/Z-End of Course/formula1/trans/2.driver_standings
/Formula1-Project-Solutions/Z-End of Course/formula1/trans/1.race_results
/Formula1-Project-Solutions/Z-End of Course/formula1/trans/3.constructor_standings
/Formula1-Project-Solutions/Z-End of Course/formula1/trans/4.calculated_race_results
/Formula1-Project-Solutions/Z-End of Course/formula1/analysis/3.viz_dominant_drivers
/Formula1-Project-Solutions/Z-End of Course/formula1/analysis/1.find_dominant_drivers
/Formula1-Project-Solutions/Z-End of Course/formula1/analysis/4.viz_dominant_teams
/Formula1-Project-Solutions/Z-End of Course/formula1/analysis/2.find_dominant_teams
/Formula1-Project-Solutions/Querying the Delta Live Tables event log
/AAP_USER
/ShakeIT_Attempt
/ODS_Selfcare_Incremental
/ODS_ShakeITWonReward
/ODS_ShakeITWonReward (1)
Successfully wrote content to notebooks.json.
json file was created:notebooks.json
number of notebooks:420
Failed to write to file: [Errno 2] No such file or directory: 'notebools.json'
# MAGIC %scala
# MAGIC import scala.util.parsing.json.JSON
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC import za.co.absa.spline.agent.AgentConfig
# MAGIC import za.co.absa.spline.harvester.postprocessing.AbstractPostProcessingFilter
# MAGIC import za.co.absa.spline.harvester.postprocessing.PostProcessingFilter
# MAGIC import org.apache.commons.configuration.Configuration
# MAGIC import za.co.absa.spline.harvester.conf.StandardSplineConfigurationStack
# MAGIC import za.co.absa.spline.harvester.HarvestingContext
# MAGIC import za.co.absa.spline.producer.model.ExecutionPlan
# MAGIC import za.co.absa.spline.producer.model.ExecutionEvent
# MAGIC import za.co.absa.spline.producer.model.ReadOperation
# MAGIC import za.co.absa.spline.producer.model.WriteOperation
# MAGIC import za.co.absa.spline.producer.model.DataOperation
# MAGIC import za.co.absa.spline.harvester.ExtraMetadataImplicits._
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC
# MAGIC val notebookInformationJson = dbutils.notebook.getContext.toJson
# MAGIC val outerMap = JSON.parseFull(notebookInformationJson).getOrElse(0).asInstanceOf[Map[String,String]]
# MAGIC val tagMap = outerMap("tags").asInstanceOf[Map[String,String]]
# MAGIC val extraContextMap = outerMap("extraContext").asInstanceOf[Map[String,String]]
# MAGIC val notebookPath = extraContextMap("notebook_path").split("/")
# MAGIC val workspaceUrl=tagMap("browserHostName")
# MAGIC
# MAGIC val workspaceName=dbutils.notebook().getContext().notebookPath.get
# MAGIC val notebookURL = tagMap("browserHostName")+"/?o="+tagMap("orgId")+tagMap("browserHash")
# MAGIC val user = tagMap("user")
# MAGIC val name = notebookPath(notebookPath.size-1)
# MAGIC val notebookInfo = Map("notebookURL" -> notebookURL,
# MAGIC "user" -> user,
# MAGIC "workspaceName" ->workspaceName,
# MAGIC "workspaceUrl" -> workspaceUrl,
# MAGIC "name" -> name,
# MAGIC "mounts" -> dbutils.fs.ls("/FileStore/tables").map(_.path),
# MAGIC "timestamp" -> System.currentTimeMillis)
# MAGIC val notebookInfoJson = scala.util.parsing.json.JSONObject(notebookInfo)
# MAGIC
# MAGIC
# MAGIC class CustomFilter extends PostProcessingFilter {
# MAGIC   def this(conf: Configuration) = this()
# MAGIC
# MAGIC   override def processExecutionEvent(event: ExecutionEvent, ctx: HarvestingContext): ExecutionEvent =
# MAGIC     event.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processExecutionPlan(plan: ExecutionPlan, ctx: HarvestingContext ): ExecutionPlan =
# MAGIC     plan.withAddedExtra(Map( "notebookInfo" -> notebookInfoJson))
# MAGIC
# MAGIC   override def processReadOperation(op: ReadOperation, ctx: HarvestingContext ): ReadOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processWriteOperation(op: WriteOperation, ctx: HarvestingContext): WriteOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processDataOperation(op: DataOperation, ctx: HarvestingContext  ): DataOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC }
# MAGIC
# MAGIC
# MAGIC
# MAGIC val myInstance = new CustomFilter()
# MAGIC
# MAGIC
# MAGIC spark.enableLineageTracking(
# MAGIC   AgentConfig.builder()
# MAGIC     .postProcessingFilter(myInstance)
# MAGIC     .build()
# MAGIC )

# COMMAND ----------

sc._jvm.za.co.absa.spline.harvester.SparkLineageInitializer.enableLineageTracking(spark._jsparkSession)

# COMMAND ----------

print("see1e")
/Formula1-Project-Solutions (1)/Section-16-17-18/utils/1.prepare_for_incremental_load
Ignore notebook /Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/9.create_processed_database
Ignore notebook /Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/0.ingest_all_files
Ignore notebook /Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/7.ingest_lap_times_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/8.ingest_qualifying_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/6.ingest_pit_stops_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/4.ingest_drivers_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/1.ingest_circuits_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/2.ingest_races_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/3.ingest_constructors_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/5.ingest_results_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-16-17-18/raw/1.create_raw_tables
Ignore notebook /Formula1-Project-Solutions (1)/Section-16-17-18/analysis/2.find_dominant_teams
Ignore notebook /Formula1-Project-Solutions (1)/Section-16-17-18/analysis/3.viz_dominant_drivers
Ignore notebook /Formula1-Project-Solutions (1)/Section-16-17-18/analysis/4.viz_dominant_teams
Ignore notebook /Formula1-Project-Solutions (1)/Section-16-17-18/analysis/1.find_dominant_drivers
Ignore notebook /Formula1-Project-Solutions (1)/Section-12/ingestion/1.ingest_circuits_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-12/ingestion/7.ingest_lap_times_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-12/ingestion/4.ingest_drivers_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-12/ingestion/5.ingest_results_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-12/ingestion/8.ingest_qualifying_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-12/ingestion/0.ingest_all_files
Ignore notebook /Formula1-Project-Solutions (1)/Section-12/ingestion/2.ingest_races_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-12/ingestion/3.ingest_constructors_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-12/ingestion/6.ingest_pit_stops_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/set-up/mount_adls_storage
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/analysis/4.viz_dominant_teams
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/analysis/3.viz_dominant_drivers
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/analysis/2.find_dominant_teams
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/analysis/1.find_dominant_drivers
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/raw/1.create_raw_tables
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/utils/1.prepare_for_incremental_load
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/demo/4.sql_temp_view_demo
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/demo/9.sql_joins_demo
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/demo/6.sql_objects_demo
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/demo/5.sql_temp_view_demo
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/demo/3.aggregation_demo
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/demo/7.sql_basics_demo
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/demo/2.join_demo
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/demo/8.sql_functions_demo
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/demo/10.delta_lake_demo
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/demo/1.filter_demo
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/includes/common_functions
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/includes/configuration
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/trans/1.race_results
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/trans/4.calculated_race_results
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/trans/3.constructor_standings
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/trans/0.create_presentation_database
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/trans/2.driver_standings
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/7.ingest_lap_times_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/6.ingest_pit_stops_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/3.ingest_constructors_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/4.ingest_drivers_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/1.ingest_circuits_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/9.create_processed_database
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/2.ingest_races_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/0.ingest_all_files
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/5.ingest_results_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/8.ingest_qualifying_file
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/analysis/3.viz_dominant_drivers
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/analysis/2.find_dominant_teams
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/analysis/4.viz_dominant_teams
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/analysis/1.find_dominant_drivers
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/set-up/mount_adls_storage
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/0.ingest_all_files
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/7.ingest_lap_times_file
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/9.create_processed_database
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/4.ingest_drivers_file
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/5.ingest_results_file
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/8.ingest_qualifying_file
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/3.ingest_constructors_file
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/2.ingest_races_file
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/6.ingest_pit_stops_file
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/1.ingest_circuits_file
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/trans/3.constructor_standings
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/trans/2.driver_standings
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/trans/1.race_results
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/trans/4.calculated_race_results
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/trans/0.create_presentation_database
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/4.sql_temp_view_demo
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/8.sql_functions_demo
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/10.delta_lake_demo
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/9.sql_joins_demo
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/1.filter_demo
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/5.sql_temp_view_demo
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/6.sql_objects_demo
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/2.join_demo
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/3.aggregation_demo
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/7.sql_basics_demo
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/includes/common_functions
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/includes/configuration
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/utils/1.prepare_for_incremental_load
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/raw/1.create_raw_tables
Ignore notebook /Formula1-Project-Solutions (1)/Section-14/trans/2.driver_standings
Ignore notebook /Formula1-Project-Solutions (1)/Section-14/trans/1.race_results
Ignore notebook /Formula1-Project-Solutions (1)/Section-14/trans/3.constructor_standings
Ignore notebook /Formula1-Project-Solutions (1)/Section-19/trans/1.race_results
Ignore notebook /Formula1-Project-Solutions (1)/Section-19/trans/4.calculated_race_results
Ignore notebook /Formula1-Project-Solutions (1)/Section-19/trans/3.constructor_standings
Ignore notebook /Formula1-Project-Solutions (1)/Section-19/trans/0.create_presentation_database
Ignore notebook /Formula1-Project-Solutions (1)/Section-19/trans/2.driver_standings
Ignore notebook /Formula1-Project-Solutions (1)/Section-19/includes/common_functions
Ignore notebook /Formula1-Project-Solutions (1)/Section-19/includes/configuration
Ignore notebook /Formula1-Project-Solutions (1)/Section-19/ingestion/9.create_processed_database
Ignore notebook /Formula1-Project-Solutions (1)/Section-19/ingestion/3.ingest_constructors_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-19/ingestion/4.ingest_drivers_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-19/ingestion/6.ingest_pit_stops_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-19/ingestion/2.ingest_races_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-19/ingestion/8.ingest_qualifying_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-19/ingestion/7.ingest_lap_times_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-19/ingestion/1.ingest_circuits_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-19/ingestion/0.ingest_all_files
Ignore notebook /Formula1-Project-Solutions (1)/Section-19/ingestion/5.ingest_results_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-06/mount_adls_storage-lesson-6
Ignore notebook /Formula1-Project-Solutions (1)/Section-06/mount_adls_storage-lesson-9
Ignore notebook /Formula1-Project-Solutions (1)/Section-09-10-11/ingestion/7.ingest_lap_times_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-09-10-11/ingestion/5.ingest_results_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-09-10-11/ingestion/2.ingest_races_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-09-10-11/ingestion/3.ingest_constructors_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-09-10-11/ingestion/4.ingest_drivers_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-09-10-11/ingestion/1.ingest_circuits_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-09-10-11/ingestion/6.ingest_pit_stops_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-09-10-11/ingestion/8.ingest_qualifying_file
Ignore notebook /Users/dora@octopai.com/Sql_PY (1)
Ignore notebook /Users/zacayd@octopai.com/splineScaleExample
Ignore notebook /Users/zacayd@octopai.com/ScalaCode
Ignore notebook /Users/zacayd@octopai.com/SplineCode
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/utils/1.prepare_for_incremental_load
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/9.create_processed_database
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/0.ingest_all_files
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/7.ingest_lap_times_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/8.ingest_qualifying_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/6.ingest_pit_stops_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/4.ingest_drivers_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/1.ingest_circuits_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/2.ingest_races_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/3.ingest_constructors_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/5.ingest_results_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/raw/1.create_raw_tables
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/analysis/2.find_dominant_teams
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/analysis/3.viz_dominant_drivers
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/analysis/4.viz_dominant_teams
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/analysis/1.find_dominant_drivers
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-12/ingestion/1.ingest_circuits_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-12/ingestion/7.ingest_lap_times_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-12/ingestion/4.ingest_drivers_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-12/ingestion/5.ingest_results_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-12/ingestion/8.ingest_qualifying_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-12/ingestion/0.ingest_all_files
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-12/ingestion/2.ingest_races_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-12/ingestion/3.ingest_constructors_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-12/ingestion/6.ingest_pit_stops_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/set-up/mount_adls_storage
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/analysis/4.viz_dominant_teams
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/analysis/3.viz_dominant_drivers
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/analysis/2.find_dominant_teams
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/analysis/1.find_dominant_drivers
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/raw/1.create_raw_tables
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/utils/1.prepare_for_incremental_load
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/demo/4.sql_temp_view_demo
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/demo/9.sql_joins_demo
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/demo/6.sql_objects_demo
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/demo/5.sql_temp_view_demo
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/demo/3.aggregation_demo
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/demo/7.sql_basics_demo
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/demo/2.join_demo
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/demo/8.sql_functions_demo
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/demo/10.delta_lake_demo
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/demo/1.filter_demo
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/includes/common_functions
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/includes/configuration
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/trans/1.race_results
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/trans/4.calculated_race_results
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/trans/3.constructor_standings
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/trans/0.create_presentation_database
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/trans/2.driver_standings
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/ingestion/7.ingest_lap_times_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/ingestion/6.ingest_pit_stops_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/ingestion/3.ingest_constructors_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/ingestion/4.ingest_drivers_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/ingestion/1.ingest_circuits_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/ingestion/9.create_processed_database
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/ingestion/2.ingest_races_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/ingestion/0.ingest_all_files
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/ingestion/5.ingest_results_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-20/formula1/ingestion/8.ingest_qualifying_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/analysis/3.viz_dominant_drivers
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/analysis/2.find_dominant_teams
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/analysis/4.viz_dominant_teams
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/analysis/1.find_dominant_drivers
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/set-up/mount_adls_storage
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/0.ingest_all_files
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/7.ingest_lap_times_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/9.create_processed_database
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/4.ingest_drivers_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/5.ingest_results_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/8.ingest_qualifying_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/3.ingest_constructors_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/2.ingest_races_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/6.ingest_pit_stops_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/1.ingest_circuits_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/trans/3.constructor_standings
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/trans/2.driver_standings
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/trans/1.race_results
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/trans/4.calculated_race_results
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/trans/0.create_presentation_database
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/demo/4.sql_temp_view_demo
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/demo/8.sql_functions_demo
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/demo/10.delta_lake_demo
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/demo/9.sql_joins_demo
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/demo/1.filter_demo
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/demo/5.sql_temp_view_demo
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/demo/6.sql_objects_demo
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/demo/2.join_demo
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/demo/3.aggregation_demo
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/demo/7.sql_basics_demo
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/includes/common_functions
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/includes/configuration
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/utils/1.prepare_for_incremental_load
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Z-End of Course/formula1/raw/1.create_raw_tables
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-14/trans/2.driver_standings
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-14/trans/1.race_results
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-14/trans/3.constructor_standings
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/trans/1.race_results
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/trans/4.calculated_race_results
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/trans/3.constructor_standings
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/trans/0.create_presentation_database
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/trans/2.driver_standings
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/includes/common_functions
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/includes/configuration
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/ingestion/9.create_processed_database
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/ingestion/3.ingest_constructors_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/ingestion/4.ingest_drivers_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/ingestion/6.ingest_pit_stops_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/ingestion/2.ingest_races_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/ingestion/8.ingest_qualifying_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/ingestion/7.ingest_lap_times_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/ingestion/1.ingest_circuits_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/ingestion/0.ingest_all_files
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-19/ingestion/5.ingest_results_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-06/mount_adls_storage-lesson-6
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-06/mount_adls_storage-lesson-9
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-09-10-11/ingestion/7.ingest_lap_times_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-09-10-11/ingestion/5.ingest_results_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-09-10-11/ingestion/2.ingest_races_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-09-10-11/ingestion/3.ingest_constructors_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-09-10-11/ingestion/4.ingest_drivers_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-09-10-11/ingestion/1.ingest_circuits_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-09-10-11/ingestion/6.ingest_pit_stops_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-09-10-11/ingestion/8.ingest_qualifying_file
Ignore notebook /Users/zacayd@octopai.com/pythonz
Ignore notebook /Users/zacayd@octopai.com/Sandvine_BillingRecon
Ignore notebook /Users/zacayd@octopai.com/SqlExample
Ignore notebook /Users/zacayd@octopai.com/Zacay
Ignore notebook /Users/zacayd@octopai.com/Scala
Ignore notebook /Users/zacayd@octopai.com/Scala2
Ignore notebook /Users/zacayd@octopai.com/NoteBookTest
Ignore notebook /Users/zacayd@octopai.com/2022-10-31 - DBFS Example
Ignore notebook /Users/zacayd@octopai.com/Scala1
Ignore notebook /Users/zacayd@octopai.com/pythony
Ignore notebook /Users/zacayd@octopai.com/py2
Ignore notebook /Users/zacayd@octopai.com/TEST
Ignore notebook /Users/zacayd@octopai.com/ScalaHarverster
Ignore notebook /Users/zacayd@octopai.com/MyTest
Ignore notebook /Users/zacayd@octopai.com/Azure Blob Storage
Ignore notebook /Users/zacayd@octopai.com/MySQL
Ignore notebook /Users/zacayd@octopai.com/ExampleDLT
Ignore notebook /Users/zacayd@octopai.com/ExampleDLT_SQL
Ignore notebook /Users/zacayd@octopai.com/Untitled Notebook 2023-06-12 15:44:30
Ignore notebook /Users/zacayd@octopai.com/MyLogs
Ignore notebook /Users/zacayd@octopai.com/Helper
Ignore notebook /Users/zacayd@octopai.com/Digicel_SandvineBilling
Ignore notebook /Users/zacayd@octopai.com/Digicel
Ignore notebook /Users/zacayd@octopai.com/Scalal
Ignore notebook /Users/zacayd@octopai.com/2022-10-25 - DBFS Example
Ignore notebook /Users/zacayd@octopai.com/pythonX
Ignore notebook /Users/zacayd@octopai.com/Sql_PY
Ignore notebook /Users/zacayd@octopai.com/ScalaPython
Ignore notebook /Shared/Untitled Notebook 2023-05-23 09:28:27
Ignore notebook /Shared/DL_BULKSMS_JAM
Ignore notebook /Shared/AAP_CLIENT
Ignore notebook /Shared/Sandvine_BillingRecon
Ignore notebook /Shared/SELFCARE_USAGE
Ignore notebook /Shared/ShakeIT_WonReward
Ignore notebook /Shared/ODS_Digicel_App
Ignore notebook /Shared/ODS_Digicel_App_User
Ignore notebook /Shared/ODS_Selfcare_Incremental
Ignore notebook /Shared/ODS_ShakeITAttempt
Ignore notebook /Shared/Data-Delivery/EDW/NB_CargaTbContratoVarejo
Ignore notebook /Shared/Querying the Delta Live Tables event log
Ignore notebook /Shared/DL_BULKSMS_JAM_TEST
Ignore notebook /Formula1-Project-Solutions/Section-16-17-18/utils/1.prepare_for_incremental_load
Ignore notebook /Formula1-Project-Solutions/Section-16-17-18/analysis/3.viz_dominant_drivers
Ignore notebook /Formula1-Project-Solutions/Section-16-17-18/analysis/4.viz_dominant_teams
Ignore notebook /Formula1-Project-Solutions/Section-16-17-18/analysis/2.find_dominant_teams
Ignore notebook /Formula1-Project-Solutions/Section-16-17-18/analysis/1.find_dominant_drivers
Ignore notebook /Formula1-Project-Solutions/Section-16-17-18/ingestion/6.ingest_pit_stops_file
Ignore notebook /Formula1-Project-Solutions/Section-16-17-18/ingestion/3.ingest_constructors_file
Ignore notebook /Formula1-Project-Solutions/Section-16-17-18/ingestion/2.ingest_races_file
Ignore notebook /Formula1-Project-Solutions/Section-16-17-18/ingestion/9.create_processed_database
Ignore notebook /Formula1-Project-Solutions/Section-16-17-18/ingestion/8.ingest_qualifying_file
Ignore notebook /Formula1-Project-Solutions/Section-16-17-18/ingestion/4.ingest_drivers_file
Ignore notebook /Formula1-Project-Solutions/Section-16-17-18/ingestion/5.ingest_results_file
Ignore notebook /Formula1-Project-Solutions/Section-16-17-18/ingestion/7.ingest_lap_times_file
Ignore notebook /Formula1-Project-Solutions/Section-16-17-18/ingestion/1.ingest_circuits_file
Ignore notebook /Formula1-Project-Solutions/Section-16-17-18/ingestion/0.ingest_all_files
Ignore notebook /Formula1-Project-Solutions/Section-16-17-18/raw/1.create_raw_tables
Ignore notebook /Formula1-Project-Solutions/Section-14/trans/3.constructor_standings
Ignore notebook /Formula1-Project-Solutions/Section-14/trans/2.driver_standings
Ignore notebook /Formula1-Project-Solutions/Section-14/trans/1.race_results
Ignore notebook /Formula1-Project-Solutions/Section-12/ingestion/2.ingest_races_file
Ignore notebook /Formula1-Project-Solutions/Section-12/ingestion/5.ingest_results_file
Ignore notebook /Formula1-Project-Solutions/Section-12/ingestion/8.ingest_qualifying_file
Ignore notebook /Formula1-Project-Solutions/Section-12/ingestion/1.ingest_circuits_file
Ignore notebook /Formula1-Project-Solutions/Section-12/ingestion/0.ingest_all_files
Ignore notebook /Formula1-Project-Solutions/Section-12/ingestion/6.ingest_pit_stops_file
Ignore notebook /Formula1-Project-Solutions/Section-12/ingestion/7.ingest_lap_times_file
Ignore notebook /Formula1-Project-Solutions/Section-12/ingestion/3.ingest_constructors_file
Ignore notebook /Formula1-Project-Solutions/Section-12/ingestion/4.ingest_drivers_file
Ignore notebook /Formula1-Project-Solutions/Section-06/mount_adls_storage-lesson-6
Ignore notebook /Formula1-Project-Solutions/Section-06/mount_adls_storage-lesson-9
Ignore notebook /Formula1-Project-Solutions/Section-09-10-11/ingestion/3.ingest_constructors_file
Ignore notebook /Formula1-Project-Solutions/Section-09-10-11/ingestion/5.ingest_results_file
Ignore notebook /Formula1-Project-Solutions/Section-09-10-11/ingestion/4.ingest_drivers_file
Ignore notebook /Formula1-Project-Solutions/Section-09-10-11/ingestion/6.ingest_pit_stops_file
Ignore notebook /Formula1-Project-Solutions/Section-09-10-11/ingestion/7.ingest_lap_times_file
Ignore notebook /Formula1-Project-Solutions/Section-09-10-11/ingestion/2.ingest_races_file
Ignore notebook /Formula1-Project-Solutions/Section-09-10-11/ingestion/1.ingest_circuits_file
Ignore notebook /Formula1-Project-Solutions/Section-09-10-11/ingestion/8.ingest_qualifying_file
Ignore notebook /Formula1-Project-Solutions/Section-19/ingestion/3.ingest_constructors_file
Ignore notebook /Formula1-Project-Solutions/Section-19/ingestion/6.ingest_pit_stops_file
Ignore notebook /Formula1-Project-Solutions/Section-19/ingestion/5.ingest_results_file
Ignore notebook /Formula1-Project-Solutions/Section-19/ingestion/9.create_processed_database
Ignore notebook /Formula1-Project-Solutions/Section-19/ingestion/8.ingest_qualifying_file
Ignore notebook /Formula1-Project-Solutions/Section-19/ingestion/4.ingest_drivers_file
Ignore notebook /Formula1-Project-Solutions/Section-19/ingestion/0.ingest_all_files
Ignore notebook /Formula1-Project-Solutions/Section-19/ingestion/7.ingest_lap_times_file
Ignore notebook /Formula1-Project-Solutions/Section-19/ingestion/1.ingest_circuits_file
Ignore notebook /Formula1-Project-Solutions/Section-19/ingestion/2.ingest_races_file
Ignore notebook /Formula1-Project-Solutions/Section-19/trans/4.calculated_race_results
Ignore notebook /Formula1-Project-Solutions/Section-19/trans/0.create_presentation_database
Ignore notebook /Formula1-Project-Solutions/Section-19/trans/3.constructor_standings
Ignore notebook /Formula1-Project-Solutions/Section-19/trans/1.race_results
Ignore notebook /Formula1-Project-Solutions/Section-19/trans/2.driver_standings
Ignore notebook /Formula1-Project-Solutions/Section-19/includes/common_functions
Ignore notebook /Formula1-Project-Solutions/Section-19/includes/configuration
Ignore notebook /Formula1-Project-Solutions/Section-20/formula1/set-up/mount_adls_storage
Ignore notebook /Formula1-Project-Solutions/Section-20/formula1/ingestion/7.ingest_lap_times_file
Ignore notebook /Formula1-Project-Solutions/Section-20/formula1/ingestion/3.ingest_constructors_file
Ignore notebook /Formula1-Project-Solutions/Section-20/formula1/ingestion/5.ingest_results_file
Ignore notebook /Formula1-Project-Solutions/Section-20/formula1/ingestion/2.ingest_races_file
Ignore notebook /Formula1-Project-Solutions/Section-20/formula1/ingestion/1.ingest_circuits_file
Ignore notebook /Formula1-Project-Solutions/Section-20/formula1/ingestion/4.ingest_drivers_file
Ignore notebook /Formula1-Project-Solutions/Section-20/formula1/ingestion/6.ingest_pit_stops_file
Ignore notebook /Formula1-Project-Solutions/Section-20/formula1/ingestion/9.create_processed_database
Ignore notebook /Formula1-Project-Solutions/Section-20/formula1/ingestion/0.ingest_all_files
Ignore notebook /Formula1-Project-Solutions/Section-20/formula1/ingestion/8.ingest_qualifying_file
Ignore notebook /Formula1-Project-Solutions/Section-20/formula1/utils/1.prepare_for_incremental_load
Ignore notebook /Formula1-Project-Solutions/Section-20/formula1/trans/3.constructor_standings
Ignore notebook /Formula1-Project-Solutions/Section-20/formula1/trans/4.calculated_race_results
Ignore notebook /Formula1-Project-Solutions/Section-20/formula1/trans/1.race_results
Ignore notebook /Formula1-Project-Solutions/Section-20/formula1/trans/0.create_presentation_database
Ignore notebook /Formula1-Project-Solutions/Section-20/formula1/trans/2.driver_standings
Ignore notebook /Formula1-Project-Solutions/Section-20/formula1/analysis/3.viz_dominant_drivers
Ignore notebook /Formula1-Project-Solutions/Section-20/formula1/analysis/1.find_dominant_drivers
Ignore notebook /Formula1-Project-Solutions/Section-20/formula1/analysis/2.find_dominant_teams
Ignore notebook /Formula1-Project-Solutions/Section-20/formula1/analysis/4.viz_dominant_teams
Ignore notebook /Formula1-Project-Solutions/Section-20/formula1/raw/1.create_raw_tables
Ignore notebook /Formula1-Project-Solutions/Section-20/formula1/demo/8.sql_functions_demo
Ignore notebook /Formula1-Project-Solutions/Section-20/formula1/demo/5.sql_temp_view_demo
Ignore notebook /Formula1-Project-Solutions/Section-20/formula1/demo/6.sql_objects_demo
Ignore notebook /Formula1-Project-Solutions/Section-20/formula1/demo/2.join_demo
Ignore notebook /Formula1-Project-Solutions/Section-20/formula1/demo/9.sql_joins_demo
Ignore notebook /Formula1-Project-Solutions/Section-20/formula1/demo/4.sql_temp_view_demo
Ignore notebook /Formula1-Project-Solutions/Section-20/formula1/demo/3.aggregation_demo
Ignore notebook /Formula1-Project-Solutions/Section-20/formula1/demo/10.delta_lake_demo
Ignore notebook /Formula1-Project-Solutions/Section-20/formula1/demo/7.sql_basics_demo
Ignore notebook /Formula1-Project-Solutions/Section-20/formula1/demo/1.filter_demo
Ignore notebook /Formula1-Project-Solutions/Section-20/formula1/includes/configuration
Ignore notebook /Formula1-Project-Solutions/Section-20/formula1/includes/common_functions
Ignore notebook /Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/7.ingest_lap_times_file
Ignore notebook /Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/2.ingest_races_file
Ignore notebook /Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/5.ingest_results_file
Ignore notebook /Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/9.create_processed_database
Ignore notebook /Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/3.ingest_constructors_file
Ignore notebook /Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/1.ingest_circuits_file
Ignore notebook /Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/0.ingest_all_files
Ignore notebook /Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/4.ingest_drivers_file
Ignore notebook /Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/8.ingest_qualifying_file
Ignore notebook /Formula1-Project-Solutions/Z-End of Course/formula1/ingestion/6.ingest_pit_stops_file
Ignore notebook /Formula1-Project-Solutions/Z-End of Course/formula1/set-up/mount_adls_storage
Ignore notebook /Formula1-Project-Solutions/Z-End of Course/formula1/demo/6.sql_objects_demo
Ignore notebook /Formula1-Project-Solutions/Z-End of Course/formula1/demo/7.sql_basics_demo
Ignore notebook /Formula1-Project-Solutions/Z-End of Course/formula1/demo/8.sql_functions_demo
Ignore notebook /Formula1-Project-Solutions/Z-End of Course/formula1/demo/4.sql_temp_view_demo
Ignore notebook /Formula1-Project-Solutions/Z-End of Course/formula1/demo/3.aggregation_demo
Ignore notebook /Formula1-Project-Solutions/Z-End of Course/formula1/demo/1.filter_demo
Ignore notebook /Formula1-Project-Solutions/Z-End of Course/formula1/demo/2.join_demo
Ignore notebook /Formula1-Project-Solutions/Z-End of Course/formula1/demo/5.sql_temp_view_demo
Ignore notebook /Formula1-Project-Solutions/Z-End of Course/formula1/demo/9.sql_joins_demo
Ignore notebook /Formula1-Project-Solutions/Z-End of Course/formula1/demo/10.delta_lake_demo
Ignore notebook /Formula1-Project-Solutions/Z-End of Course/formula1/includes/common_functions
Ignore notebook /Formula1-Project-Solutions/Z-End of Course/formula1/includes/configuration
Ignore notebook /Formula1-Project-Solutions/Z-End of Course/formula1/utils/1.prepare_for_incremental_load
Ignore notebook /Formula1-Project-Solutions/Z-End of Course/formula1/raw/1.create_raw_tables
Ignore notebook /Formula1-Project-Solutions/Z-End of Course/formula1/trans/0.create_presentation_database
Ignore notebook /Formula1-Project-Solutions/Z-End of Course/formula1/trans/2.driver_standings
Ignore notebook /Formula1-Project-Solutions/Z-End of Course/formula1/trans/1.race_results
Ignore notebook /Formula1-Project-Solutions/Z-End of Course/formula1/trans/3.constructor_standings
Ignore notebook /Formula1-Project-Solutions/Z-End of Course/formula1/trans/4.calculated_race_results
Ignore notebook /Formula1-Project-Solutions/Z-End of Course/formula1/analysis/3.viz_dominant_drivers
Ignore notebook /Formula1-Project-Solutions/Z-End of Course/formula1/analysis/1.find_dominant_drivers
Ignore notebook /Formula1-Project-Solutions/Z-End of Course/formula1/analysis/4.viz_dominant_teams
Ignore notebook /Formula1-Project-Solutions/Z-End of Course/formula1/analysis/2.find_dominant_teams
Ignore notebook /Formula1-Project-Solutions/Querying the Delta Live Tables event log
Ignore notebook /AAP_USER
Ignore notebook /ShakeIT_Attempt
Ignore notebook /ODS_Selfcare_Incremental
Ignore notebook /ODS_ShakeITWonReward
Ignore notebook /ODS_ShakeITWonReward (1)
Number of notebooks updated:1
number of updated notebooks:1
# MAGIC %scala
# MAGIC import scala.util.parsing.json.JSON
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC import za.co.absa.spline.agent.AgentConfig
# MAGIC import za.co.absa.spline.harvester.postprocessing.AbstractPostProcessingFilter
# MAGIC import za.co.absa.spline.harvester.postprocessing.PostProcessingFilter
# MAGIC import org.apache.commons.configuration.Configuration
# MAGIC import za.co.absa.spline.harvester.conf.StandardSplineConfigurationStack
# MAGIC import za.co.absa.spline.harvester.HarvestingContext
# MAGIC import za.co.absa.spline.producer.model.ExecutionPlan
# MAGIC import za.co.absa.spline.producer.model.ExecutionEvent
# MAGIC import za.co.absa.spline.producer.model.ReadOperation
# MAGIC import za.co.absa.spline.producer.model.WriteOperation
# MAGIC import za.co.absa.spline.producer.model.DataOperation
# MAGIC import za.co.absa.spline.harvester.ExtraMetadataImplicits._
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC
# MAGIC val notebookInformationJson = dbutils.notebook.getContext.toJson
# MAGIC val outerMap = JSON.parseFull(notebookInformationJson).getOrElse(0).asInstanceOf[Map[String,String]]
# MAGIC val tagMap = outerMap("tags").asInstanceOf[Map[String,String]]
# MAGIC val extraContextMap = outerMap("extraContext").asInstanceOf[Map[String,String]]
# MAGIC val notebookPath = extraContextMap("notebook_path").split("/")
# MAGIC val workspaceUrl=tagMap("browserHostName")
# MAGIC
# MAGIC val workspaceName=dbutils.notebook().getContext().notebookPath.get
# MAGIC val notebookURL = tagMap("browserHostName")+"/?o="+tagMap("orgId")+tagMap("browserHash")
# MAGIC val user = tagMap("user")
# MAGIC val name = notebookPath(notebookPath.size-1)
# MAGIC val notebookInfo = Map("notebookURL" -> notebookURL,
# MAGIC "user" -> user,
# MAGIC "workspaceName" ->workspaceName,
# MAGIC "workspaceUrl" -> workspaceUrl,
# MAGIC "name" -> name,
# MAGIC "mounts" -> dbutils.fs.ls("/FileStore/tables").map(_.path),
# MAGIC "timestamp" -> System.currentTimeMillis)
# MAGIC val notebookInfoJson = scala.util.parsing.json.JSONObject(notebookInfo)
# MAGIC
# MAGIC
# MAGIC class CustomFilter extends PostProcessingFilter {
# MAGIC   def this(conf: Configuration) = this()
# MAGIC
# MAGIC   override def processExecutionEvent(event: ExecutionEvent, ctx: HarvestingContext): ExecutionEvent =
# MAGIC     event.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processExecutionPlan(plan: ExecutionPlan, ctx: HarvestingContext ): ExecutionPlan =
# MAGIC     plan.withAddedExtra(Map( "notebookInfo" -> notebookInfoJson))
# MAGIC
# MAGIC   override def processReadOperation(op: ReadOperation, ctx: HarvestingContext ): ReadOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processWriteOperation(op: WriteOperation, ctx: HarvestingContext): WriteOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processDataOperation(op: DataOperation, ctx: HarvestingContext  ): DataOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC }
# MAGIC
# MAGIC
# MAGIC
# MAGIC val myInstance = new CustomFilter()
# MAGIC
# MAGIC
# MAGIC spark.enableLineageTracking(
# MAGIC   AgentConfig.builder()
# MAGIC     .postProcessingFilter(myInstance)
# MAGIC     .build()
# MAGIC )

# COMMAND ----------

sc._jvm.za.co.absa.spline.harvester.SparkLineageInitializer.enableLineageTracking(spark._jsparkSession)

# COMMAND ----------

print("see1e")
/Formula1-Project-Solutions (1)/Section-16-17-18/utils/1.prepare_for_incremental_load
'-- Databricks notebook source
%python
sc._jvm.za.co.absa.spline.harvester.SparkLineageInitializer.enableLineageTracking(spark._jsparkSession)

-- COMMAND ----------

-- MAGIC %scala
-- MAGIC import scala.util.parsing.json.JSON
-- MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
-- MAGIC import za.co.absa.spline.agent.AgentConfig
-- MAGIC import za.co.absa.spline.harvester.postprocessing.AbstractPostProcessingFilter
-- MAGIC import za.co.absa.spline.harvester.postprocessing.PostProcessingFilter
-- MAGIC import org.apache.commons.configuration.Configuration
-- MAGIC import za.co.absa.spline.harvester.conf.StandardSplineConfigurationStack
-- MAGIC import za.co.absa.spline.harvester.HarvestingContext
-- MAGIC import za.co.absa.spline.producer.model.ExecutionPlan
-- MAGIC import za.co.absa.spline.producer.model.ExecutionEvent
-- MAGIC import za.co.absa.spline.producer.model.ReadOperation
-- MAGIC import za.co.absa.spline.producer.model.WriteOperation
-- MAGIC import za.co.absa.spline.producer.model.DataOperation
-- MAGIC import za.co.absa.spline.harvester.ExtraMetadataImplicits._
-- MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
-- MAGIC
-- MAGIC val notebookInformationJson = dbutils.notebook.getContext.toJson
-- MAGIC val outerMap = JSON.parseFull(notebookInformationJson).getOrElse(0).asInstanceOf[Map[String,String]]
-- MAGIC val tagMap = outerMap("tags").asInstanceOf[Map[String,String]]
-- MAGIC val extraContextMap = outerMap("extraContext").asInstanceOf[Map[String,String]]
-- MAGIC val notebookPath = extraContextMap("notebook_path").split("/")
-- MAGIC val workspaceUrl=tagMap("browserHostName")
-- MAGIC
-- MAGIC val workspaceName=dbutils.notebook().getContext().notebookPath.get
-- MAGIC val notebookURL = tagMap("browserHostName")+"/?o="+tagMap("orgId")+tagMap("browserHash")
-- MAGIC val user = tagMap("user")
-- MAGIC val name = notebookPath(notebookPath.size-1)
-- MAGIC val notebookInfo = Map("notebookURL" -> notebookURL,
-- MAGIC "user" -> user,
-- MAGIC "workspaceName" ->workspaceName,
-- MAGIC "workspaceUrl" -> workspaceUrl,
-- MAGIC "name" -> name,
-- MAGIC "mounts" -> dbutils.fs.ls("/FileStore/tables").map(_.path),
-- MAGIC "timestamp" -> System.currentTimeMillis)
-- MAGIC val notebookInfoJson = scala.util.parsing.json.JSONObject(notebookInfo)
-- MAGIC
-- MAGIC
-- MAGIC class CustomFilter extends PostProcessingFilter {
-- MAGIC   def this(conf: Configuration) = this()
-- MAGIC
-- MAGIC   override def processExecutionEvent(event: ExecutionEvent, ctx: HarvestingContext): ExecutionEvent =
-- MAGIC     event.withAddedExtra(Map("foo" -> "bar"))
-- MAGIC
-- MAGIC   override def processExecutionPlan(plan: ExecutionPlan, ctx: HarvestingContext ): ExecutionPlan =
-- MAGIC     plan.withAddedExtra(Map( "notebookInfo" -> notebookInfoJson))
-- MAGIC
-- MAGIC   override def processReadOperation(op: ReadOperation, ctx: HarvestingContext ): ReadOperation =
-- MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
-- MAGIC
-- MAGIC   override def processWriteOperation(op: WriteOperation, ctx: HarvestingContext): WriteOperation =
-- MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
-- MAGIC
-- MAGIC   override def processDataOperation(op: DataOperation, ctx: HarvestingContext  ): DataOperation =
-- MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
-- MAGIC }
-- MAGIC
-- MAGIC
-- MAGIC
-- MAGIC val myInstance = new CustomFilter()
-- MAGIC
-- MAGIC
-- MAGIC spark.enableLineageTracking(
-- MAGIC   AgentConfig.builder()
-- MAGIC     .postProcessingFilter(myInstance)
-- MAGIC     .build()
-- MAGIC )

-- COMMAND ----------

CREATE DATABASE IF NOT EXISTS f1_processed
LOCATION "/mnt/formula1dl/processed"

-- COMMAND ----------

DESC DATABASE f1_processed;

-- COMMAND ----------


/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/9.create_processed_database
Ignore notebook /Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/0.ingest_all_files
Ignore notebook /Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/7.ingest_lap_times_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/8.ingest_qualifying_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/6.ingest_pit_stops_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/4.ingest_drivers_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/1.ingest_circuits_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/2.ingest_races_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/3.ingest_constructors_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/5.ingest_results_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-16-17-18/raw/1.create_raw_tables
Ignore notebook /Formula1-Project-Solutions (1)/Section-16-17-18/analysis/2.find_dominant_teams
Ignore notebook /Formula1-Project-Solutions (1)/Section-16-17-18/analysis/3.viz_dominant_drivers
Ignore notebook /Formula1-Project-Solutions (1)/Section-16-17-18/analysis/4.viz_dominant_teams
Ignore notebook /Formula1-Project-Solutions (1)/Section-16-17-18/analysis/1.find_dominant_drivers
Ignore notebook /Formula1-Project-Solutions (1)/Section-12/ingestion/1.ingest_circuits_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-12/ingestion/7.ingest_lap_times_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-12/ingestion/4.ingest_drivers_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-12/ingestion/5.ingest_results_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-12/ingestion/8.ingest_qualifying_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-12/ingestion/0.ingest_all_files
Ignore notebook /Formula1-Project-Solutions (1)/Section-12/ingestion/2.ingest_races_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-12/ingestion/3.ingest_constructors_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-12/ingestion/6.ingest_pit_stops_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/set-up/mount_adls_storage
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/analysis/4.viz_dominant_teams
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/analysis/3.viz_dominant_drivers
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/analysis/2.find_dominant_teams
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/analysis/1.find_dominant_drivers
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/raw/1.create_raw_tables
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/utils/1.prepare_for_incremental_load
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/demo/4.sql_temp_view_demo
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/demo/9.sql_joins_demo
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/demo/6.sql_objects_demo
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/demo/5.sql_temp_view_demo
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/demo/3.aggregation_demo
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/demo/7.sql_basics_demo
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/demo/2.join_demo
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/demo/8.sql_functions_demo
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/demo/10.delta_lake_demo
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/demo/1.filter_demo
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/includes/common_functions
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/includes/configuration
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/trans/1.race_results
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/trans/4.calculated_race_results
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/trans/3.constructor_standings
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/trans/0.create_presentation_database
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/trans/2.driver_standings
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/7.ingest_lap_times_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/6.ingest_pit_stops_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/3.ingest_constructors_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/4.ingest_drivers_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/1.ingest_circuits_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/9.create_processed_database
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/2.ingest_races_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/0.ingest_all_files
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/5.ingest_results_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-20/formula1/ingestion/8.ingest_qualifying_file
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/analysis/3.viz_dominant_drivers
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/analysis/2.find_dominant_teams
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/analysis/4.viz_dominant_teams
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/analysis/1.find_dominant_drivers
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/set-up/mount_adls_storage
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/0.ingest_all_files
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/7.ingest_lap_times_file
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/9.create_processed_database
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/4.ingest_drivers_file
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/5.ingest_results_file
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/8.ingest_qualifying_file
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/3.ingest_constructors_file
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/2.ingest_races_file
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/6.ingest_pit_stops_file
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/ingestion/1.ingest_circuits_file
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/trans/3.constructor_standings
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/trans/2.driver_standings
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/trans/1.race_results
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/trans/4.calculated_race_results
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/trans/0.create_presentation_database
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/4.sql_temp_view_demo
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/8.sql_functions_demo
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/10.delta_lake_demo
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/9.sql_joins_demo
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/1.filter_demo
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/5.sql_temp_view_demo
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/6.sql_objects_demo
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/2.join_demo
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/3.aggregation_demo
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/demo/7.sql_basics_demo
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/includes/common_functions
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/includes/configuration
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/utils/1.prepare_for_incremental_load
Ignore notebook /Formula1-Project-Solutions (1)/Z-End of Course/formula1/raw/1.create_raw_tables
Ignore notebook /Formula1-Project-Solutions (1)/Section-14/trans/2.driver_standings
Ignore notebook /Formula1-Project-Solutions (1)/Section-14/trans/1.race_results
Ignore notebook /Formula1-Project-Solutions (1)/Section-14/trans/3.constructor_standings
Ignore notebook /Formula1-Project-Solutions (1)/Section-19/trans/1.race_results
Ignore notebook /Formula1-Project-Solutions (1)/Section-19/trans/4.calculated_race_results
Ignore notebook /Formula1-Project-Solutions (1)/Section-19/trans/3.constructor_standings
Ignore notebook /Formula1-Project-Solutions (1)/Section-19/trans/0.create_presentation_database
Ignore notebook /Formula1-Project-Solutions (1)/Section-19/trans/2.driver_standings
Ignore notebook /Formula1-Project-Solutions (1)/Section-19/includes/common_functions
Ignore notebook /Formula1-Project-Solutions (1)/Section-19/includes/configuration
Ignore notebook /Formula1-Project-Solutions (1)/Section-19/ingestion/9.create_processed_database
Ignore notebook /Formula1-Project-Solutions (1)/Section-19/ingestion/3.ingest_constructors_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-19/ingestion/4.ingest_drivers_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-19/ingestion/6.ingest_pit_stops_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-19/ingestion/2.ingest_races_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-19/ingestion/8.ingest_qualifying_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-19/ingestion/7.ingest_lap_times_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-19/ingestion/1.ingest_circuits_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-19/ingestion/0.ingest_all_files
Ignore notebook /Formula1-Project-Solutions (1)/Section-19/ingestion/5.ingest_results_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-06/mount_adls_storage-lesson-6
Ignore notebook /Formula1-Project-Solutions (1)/Section-06/mount_adls_storage-lesson-9
Ignore notebook /Formula1-Project-Solutions (1)/Section-09-10-11/ingestion/7.ingest_lap_times_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-09-10-11/ingestion/5.ingest_results_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-09-10-11/ingestion/2.ingest_races_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-09-10-11/ingestion/3.ingest_constructors_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-09-10-11/ingestion/4.ingest_drivers_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-09-10-11/ingestion/1.ingest_circuits_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-09-10-11/ingestion/6.ingest_pit_stops_file
Ignore notebook /Formula1-Project-Solutions (1)/Section-09-10-11/ingestion/8.ingest_qualifying_file
Ignore notebook /Users/dora@octopai.com/Sql_PY (1)
Ignore notebook /Users/zacayd@octopai.com/splineScaleExample
Ignore notebook /Users/zacayd@octopai.com/ScalaCode
Ignore notebook /Users/zacayd@octopai.com/SplineCode
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/utils/1.prepare_for_incremental_load
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/9.create_processed_database
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/0.ingest_all_files
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/7.ingest_lap_times_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/8.ingest_qualifying_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/6.ingest_pit_stops_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/4.ingest_drivers_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/1.ingest_circuits_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/2.ingest_races_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/3.ingest_constructors_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/ingestion/5.ingest_results_file
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/raw/1.create_raw_tables
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/analysis/2.find_dominant_teams
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/analysis/3.viz_dominant_drivers
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/analysis/4.viz_dominant_teams
Ignore notebook /Users/zacayd@octopai.com/Formula1-Project-Solutions/Section-16-17-18/analysis/1.find_dominant_drivers
# MAGIC %scala
# MAGIC import scala.util.parsing.json.JSON
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC import za.co.absa.spline.agent.AgentConfig
# MAGIC import za.co.absa.spline.harvester.postprocessing.AbstractPostProcessingFilter
# MAGIC import za.co.absa.spline.harvester.postprocessing.PostProcessingFilter
# MAGIC import org.apache.commons.configuration.Configuration
# MAGIC import za.co.absa.spline.harvester.conf.StandardSplineConfigurationStack
# MAGIC import za.co.absa.spline.harvester.HarvestingContext
# MAGIC import za.co.absa.spline.producer.model.ExecutionPlan
# MAGIC import za.co.absa.spline.producer.model.ExecutionEvent
# MAGIC import za.co.absa.spline.producer.model.ReadOperation
# MAGIC import za.co.absa.spline.producer.model.WriteOperation
# MAGIC import za.co.absa.spline.producer.model.DataOperation
# MAGIC import za.co.absa.spline.harvester.ExtraMetadataImplicits._
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC
# MAGIC val notebookInformationJson = dbutils.notebook.getContext.toJson
# MAGIC val outerMap = JSON.parseFull(notebookInformationJson).getOrElse(0).asInstanceOf[Map[String,String]]
# MAGIC val tagMap = outerMap("tags").asInstanceOf[Map[String,String]]
# MAGIC val extraContextMap = outerMap("extraContext").asInstanceOf[Map[String,String]]
# MAGIC val notebookPath = extraContextMap("notebook_path").split("/")
# MAGIC val workspaceUrl=tagMap("browserHostName")
# MAGIC
# MAGIC val workspaceName=dbutils.notebook().getContext().notebookPath.get
# MAGIC val notebookURL = tagMap("browserHostName")+"/?o="+tagMap("orgId")+tagMap("browserHash")
# MAGIC val user = tagMap("user")
# MAGIC val name = notebookPath(notebookPath.size-1)
# MAGIC val notebookInfo = Map("notebookURL" -> notebookURL,
# MAGIC "user" -> user,
# MAGIC "workspaceName" ->workspaceName,
# MAGIC "workspaceUrl" -> workspaceUrl,
# MAGIC "name" -> name,
# MAGIC "mounts" -> dbutils.fs.ls("/FileStore/tables").map(_.path),
# MAGIC "timestamp" -> System.currentTimeMillis)
# MAGIC val notebookInfoJson = scala.util.parsing.json.JSONObject(notebookInfo)
# MAGIC
# MAGIC
# MAGIC class CustomFilter extends PostProcessingFilter {
# MAGIC   def this(conf: Configuration) = this()
# MAGIC
# MAGIC   override def processExecutionEvent(event: ExecutionEvent, ctx: HarvestingContext): ExecutionEvent =
# MAGIC     event.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processExecutionPlan(plan: ExecutionPlan, ctx: HarvestingContext ): ExecutionPlan =
# MAGIC     plan.withAddedExtra(Map( "notebookInfo" -> notebookInfoJson))
# MAGIC
# MAGIC   override def processReadOperation(op: ReadOperation, ctx: HarvestingContext ): ReadOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processWriteOperation(op: WriteOperation, ctx: HarvestingContext): WriteOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processDataOperation(op: DataOperation, ctx: HarvestingContext  ): DataOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC }
# MAGIC
# MAGIC
# MAGIC
# MAGIC val myInstance = new CustomFilter()
# MAGIC
# MAGIC
# MAGIC spark.enableLineageTracking(
# MAGIC   AgentConfig.builder()
# MAGIC     .postProcessingFilter(myInstance)
# MAGIC     .build()
# MAGIC )

# COMMAND ----------

sc._jvm.za.co.absa.spline.harvester.SparkLineageInitializer.enableLineageTracking(spark._jsparkSession)

# COMMAND ----------

print("see1e")
/Formula1-Project-Solutions (1)/Section-16-17-18/utils/1.prepare_for_incremental_load
CREATE DATABASE IF NOT EXISTS f1_processed
LOCATION "/mnt/formula1dl/processed"

-- COMMAND ----------

DESC DATABASE f1_processed;

-- COMMAND ----------


/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/9.create_processed_database
Number of notebooks updated:2
number of updated notebooks:2
# MAGIC %scala
# MAGIC import scala.util.parsing.json.JSON
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC import za.co.absa.spline.agent.AgentConfig
# MAGIC import za.co.absa.spline.harvester.postprocessing.AbstractPostProcessingFilter
# MAGIC import za.co.absa.spline.harvester.postprocessing.PostProcessingFilter
# MAGIC import org.apache.commons.configuration.Configuration
# MAGIC import za.co.absa.spline.harvester.conf.StandardSplineConfigurationStack
# MAGIC import za.co.absa.spline.harvester.HarvestingContext
# MAGIC import za.co.absa.spline.producer.model.ExecutionPlan
# MAGIC import za.co.absa.spline.producer.model.ExecutionEvent
# MAGIC import za.co.absa.spline.producer.model.ReadOperation
# MAGIC import za.co.absa.spline.producer.model.WriteOperation
# MAGIC import za.co.absa.spline.producer.model.DataOperation
# MAGIC import za.co.absa.spline.harvester.ExtraMetadataImplicits._
# MAGIC import za.co.absa.spline.harvester.SparkLineageInitializer._
# MAGIC
# MAGIC val notebookInformationJson = dbutils.notebook.getContext.toJson
# MAGIC val outerMap = JSON.parseFull(notebookInformationJson).getOrElse(0).asInstanceOf[Map[String,String]]
# MAGIC val tagMap = outerMap("tags").asInstanceOf[Map[String,String]]
# MAGIC val extraContextMap = outerMap("extraContext").asInstanceOf[Map[String,String]]
# MAGIC val notebookPath = extraContextMap("notebook_path").split("/")
# MAGIC val workspaceUrl=tagMap("browserHostName")
# MAGIC
# MAGIC val workspaceName=dbutils.notebook().getContext().notebookPath.get
# MAGIC val notebookURL = tagMap("browserHostName")+"/?o="+tagMap("orgId")+tagMap("browserHash")
# MAGIC val user = tagMap("user")
# MAGIC val name = notebookPath(notebookPath.size-1)
# MAGIC val notebookInfo = Map("notebookURL" -> notebookURL,
# MAGIC "user" -> user,
# MAGIC "workspaceName" ->workspaceName,
# MAGIC "workspaceUrl" -> workspaceUrl,
# MAGIC "name" -> name,
# MAGIC "mounts" -> dbutils.fs.ls("/FileStore/tables").map(_.path),
# MAGIC "timestamp" -> System.currentTimeMillis)
# MAGIC val notebookInfoJson = scala.util.parsing.json.JSONObject(notebookInfo)
# MAGIC
# MAGIC
# MAGIC class CustomFilter extends PostProcessingFilter {
# MAGIC   def this(conf: Configuration) = this()
# MAGIC
# MAGIC   override def processExecutionEvent(event: ExecutionEvent, ctx: HarvestingContext): ExecutionEvent =
# MAGIC     event.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processExecutionPlan(plan: ExecutionPlan, ctx: HarvestingContext ): ExecutionPlan =
# MAGIC     plan.withAddedExtra(Map( "notebookInfo" -> notebookInfoJson))
# MAGIC
# MAGIC   override def processReadOperation(op: ReadOperation, ctx: HarvestingContext ): ReadOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processWriteOperation(op: WriteOperation, ctx: HarvestingContext): WriteOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC
# MAGIC   override def processDataOperation(op: DataOperation, ctx: HarvestingContext  ): DataOperation =
# MAGIC     op.withAddedExtra(Map("foo" -> "bar"))
# MAGIC }
# MAGIC
# MAGIC
# MAGIC
# MAGIC val myInstance = new CustomFilter()
# MAGIC
# MAGIC
# MAGIC spark.enableLineageTracking(
# MAGIC   AgentConfig.builder()
# MAGIC     .postProcessingFilter(myInstance)
# MAGIC     .build()
# MAGIC )

# COMMAND ----------

sc._jvm.za.co.absa.spline.harvester.SparkLineageInitializer.enableLineageTracking(spark._jsparkSession)

# COMMAND ----------

print("see1e")
/Formula1-Project-Solutions (1)/Section-16-17-18/utils/1.prepare_for_incremental_load
CREATE DATABASE IF NOT EXISTS f1_processed
LOCATION "/mnt/formula1dl/processed"

-- COMMAND ----------

DESC DATABASE f1_processed;

-- COMMAND ----------


/Formula1-Project-Solutions (1)/Section-16-17-18/ingestion/9.create_processed_database
Number of notebooks updated:2
number of updated notebooks:2
Failed to write to file: [Errno 2] No such file or directory: 'dfdf'
the JSON object must be str, bytes or bytearray, not NoneType
